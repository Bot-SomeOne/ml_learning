[
    {
        "id": "22.main-1",
        "source": "22.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Xây dựng và tối ưu hàm mất mát](#-xay-dung-va-toi-uu-ham-mat-mat) + [2.1. Hàm mất mát](#-ham-mat-mat) + [2.2. Tối ưu hàm mất mát](#-toi-uu-ham-mat-mat) * [3. Lập trình Python](#-lap-trinh-python) + [3.1.`class MF`](#-class-mf) + [3.2. Áp dụng lên MovieLens 100k](#-ap-dung-len-movielens-k) + [3.3. Áp dụng lên MovieLens 1M](#-ap-dung-len-movielens-m) * [4. Thảo luận](#-thao-luan) + [4.1. Khi có bias](#-khi-co-bias) + [4.2. Nonnegative Matrix Factorization](#-nonnegative-matrix-factorization) + [4.3. Incremental Matrix Factorization](#-incremental-matrix-factorization) + [4.4. Others](#-others) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/05/31/matrixfactorization/"
    },
    {
        "id": "22.main-2",
        "source": "22.main.md",
        "section": "1. Giới thiệu",
        "content": "Trong [Bài 24](/2017/05/24/collaborativefiltering/), chúng ta đã làm quen với một hướng tiếp cận trong Collaborative Filtering dựa trên hành vi của các *users* hoặc *items* lân cận có tên là Neighborhood-based Collaborative Filtering. Trong bài viết này, chúng ta sẽ làm quen với một hướng tiếp cận khác cho Collaborative Filtering dựa trên *Matrix Factorization* (hoặc *Matrix Decomposition*), tức *Phân tích ma trận thành nhân tử*. Nhắc lại rằng trong [Content-based Recommendation Systems](/2017/05/17/contentbasedrecommendersys/), mỗi *item* được mô tả bằng một vector \\(\\mathbf{x}\\) được gọi là *item profile*. Trong phương pháp này, ta cần tìm một vector hệ số \\(\\mathbf{w}\\) tương ứng với mỗi *user* sao cho *rating* đã biết mà *user* đó cho *item* xấp xỉ với: \\[ y \\approx \\mathbf{xw} \\] Với cách làm trên, [*Utility Matrix*](/2017/05/17/contentbasedrecommendersys/#-utility-matrix) \\(\\mathbf{Y}\\), giả sử đã được điền hết, sẽ xấp xỉ với: \\[ \\mathbf{Y} \\approx \\left[ \\begin{matrix} \\mathbf{x}\\_1\\mathbf{w}\\_1 & \\mathbf{x}\\_1\\mathbf{w}\\_2 & \\dots & \\mathbf{x}\\_1 \\mathbf{w}\\_N \\newline \\mathbf{x}\\_2\\mathbf{w}\\_1 & \\mathbf{x}\\_2\\mathbf{w}\\_2 & \\dots & \\mathbf{x}\\_2 \\mathbf{w}\\_N \\newline \\dots & \\dots & \\ddots & \\dots \\newline \\mathbf{x}\\_M\\mathbf{w}\\_1 & \\mathbf{x}\\_M\\mathbf{w}\\_2 & \\dots & \\mathbf{x}\\_M \\mathbf{w}\\_N \\newline \\end{matrix} \\right] = \\left[ \\begin{matrix} \\mathbf{x}\\_1 \\newline \\mathbf{x}\\_2 \\newline \\dots \\newline \\mathbf{x}\\_M \\newline \\end{matrix} \\right] \\left[ \\begin{matrix} \\mathbf{w}\\_1 & \\mathbf{w}\\_2 & \\dots & \\mathbf{w}\\_N \\end{matrix} \\right] = \\mathbf{XW} \\] với \\(M, N\\) lần lượt l à số *items* và số *users*. Chú ý rằng, \\(\\mathbf{x}\\) được xây dựng dựa trên thông tin mô tả của *item* và quá trình xây dựng này độc lập với quá trịnh đi tìm hệ số phù hợp cho mỗi *user*. Như vậy, việc xây dựng *item profile* đóng vai trò rất quan trọng và có ảnh hưởng trực tiếp lên hiệu năng của mô hình. Thêm nữa, việc xây dựng từng mô hình riêng lẻ cho mỗi *user* dẫn đến kết quả chưa thực sự tốt vì không khai thác được đặc điểm của những *users* gần giống nhau. Bây giờ, giả sử rằng ta không cần xây dựng từ trước các *item profile* \\(\\mathbf{x}\\) mà vector đặc trưng cho mỗi *item* này có thể được huấn luyện đồng thời với mô hình của mỗi *user* (ở đây là 1 vector hệ số). Điều này nghĩa là, biến số trong bài toán tối ưu là cả \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\); trong đó, \\(\\mathbf{X}\\) là ma trận của toàn bộ *item profiles*, mỗi **hàng** tương ứng với 1 *item*, \\(\\mathbf{W}\\) là ma trận của toàn bộ *user models*, mỗi **cột** tương ứng với 1 *user*. Với cách làm này, chúng ta đang cố gắng xấp xỉ *Utility Matrix* \\(\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}\\) bằng tích của hai ma trận \\(\\mathbf{X}\\in \\mathbb{R}^{M\\times K}\\) và \\(\\mathbf{W} \\in \\mathbb{R}^{K \\times N}\\). Thông thường, \\(K\\) được chọn là một số nhỏ hơn rất nhiều so với \\(M, N\\). Khi đó, cả hai ma trận \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\) đều có rank không vượt quá \\(K\\). Chính vì vậy, phương pháp này còn được gọi là *Low-Rank Matrix Factorization* (xem Hình 1). --- ![](/assets/25_mf/mf1.png) Hình 1: Matrix Factorization. Utility matrix \\(\\mathbf{Y}\\) được phân tích thành tích của hai ma trận low-rank \\(\\mathbf{X}\\) và \\\\(\\mathbf{W}\\) ---",
        "url": "https://machinelearningcoban.com/2017/05/31/matrixfactorization/"
    },
    {
        "id": "32.main-1",
        "source": "32.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Validation](#-validation) + [2.1. Validation](#-validation-1) + [2.2. Cross-validation](#-cross-validation) * [3. Regularization](#-regularization) + [3.1. Early Stopping](#-early-stopping) + [3.2. Thêm số hạng vào hàm mất mát](#-them-so-hang-vao-ham-mat-mat) + [3.3. \\(l\\_2\\) regularization](#-%5C%5Cl%5C%5C-regularization) - [Ví dụ về Weight Decay với MLP](#vi-du-ve-weight-decay-voi-mlp) + [3.4. Tikhonov regularization](#-tikhonov-regularization) + [3.5. Regularizers for sparsity](#-regularizers-for-sparsity) + [3.6. Regularization trong sklearn](#-regularization-trong-sklearn) * [4. Các phương pháp khác](#-cac-phuong-phap-khac) * [5. Tóm tắt nội dung](#-tom-tat-noi-dung) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao) Overfitting không phải là một thuật toán trong Machine Learning. Nó là một hiện tượng không mong muốn thường gặp, người xây dựng mô hình Machine Learning cần nắm được các kỹ thuật để tránh hiện tượng này.",
        "url": "https://machinelearningcoban.com/2017/03/04/overfitting/"
    },
    {
        "id": "32.main-2",
        "source": "32.main.md",
        "section": "1. Giới thiệu",
        "content": "Đây là một câu chuyện của chính tôi khi lần đầu biết đến Machine Learning. Năm thứ ba đại học, một thầy giáo có giới thiệu với lớp tôi về Neural Networks. Lần đầu tiên nghe thấy khái niệm này, chúng tôi hỏi thầy mục đích của nó là gì. Thầy nói, về cơ bản, từ dữ liệu cho trước, chúng ta cần tìm một hàm số để biến các các điểm đầu vào thành các điểm đầu ra tương ứng, không cần chính xác, chỉ cần xấp xỉ thôi. Lúc đó, vốn là một học sinh chuyên toán, làm việc nhiều với đa thức ngày cấp ba, tôi đã quá tự tin trả lời ngay rằng [Đa thức Nội suy Lagrange](https://vuontoanblog.blogspot.com/2012/10/polynomial-interpolation-lagrange.html) có thể làm được điều đó, miễn là các điểm đầu vào khác nhau đôi một! Thầy nói rằng “những gì ta biết chỉ là nhỏ xíu so với những gì ta chưa biết”. Và đó là những gì tôi muốn bắt đầu trong bài viết này. Nhắc lại một chút về Đa thức nội suy Lagrange: Với \\(N\\) cặp điểm dữ liệu \\((x\\_1, y\\_1), (x\\_2, y\\_2), \\dots, (x\\_N, y\\_N)\\) với các \\(x\\_i\\) kháu nhau đôi một, luôn tìm được một đa thức \\(P(.)\\) bậc không vượt quá \\(N-1\\) sao cho \\(P(x\\_i) = y\\_i, ~\\forall i = 1, 2, \\dots, N\\). Chẳng phải điều này giống với việc ta đi tìm một mô hình phù hợp (fit) với dữ liệu trong bài toán [Supervised Learning](/2016/12/27/categories/#supervised-learning-hoc-co-giam-sat) hay sao? Thậm chí điều này còn tốt hơn vì trong Supervised Learning ta chỉ cần xấp xỉ thôi. Sự thật là nếu một mô hình *quá fit* với dữ liệu thì nó sẽ gây phản tác dụng! Hiện tượng *quá fit* này trong Machine Learning được gọi là *overfitting*, là điều mà khi xây dựng mô hình, chúng ta luôn cần tránh. Để có cái nhìn đầu tiên về overfitting, chúng ta cùng xem Hình dưới đây. Có 50 điểm dữ liệu được tạo bằng một đa thức bậc ba cộng thêm nhiễu. Tập dữ liệu này được chia làm hai, 30 điểm dữ liệu màu đỏ cho training data, 20 điểm dữ liệu màu vàng cho test data. Đồ thị của đa thức bậc ba này được cho bởi đường màu xanh lục. Bài toán của chúng ta là giả sử ta không biết mô hình ban đầu mà chỉ biết các điểm dữ liệu, hãy tìm một mô hình “tốt” để mô tả dữ liệu đã cho. --- |  |  | | --- | --- | |  |  | |  |  | Underfitting và Overfitting với Polynomial Regression ([Source code](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/15_overfitting/LinReg.ipynb)). ---",
        "url": "https://machinelearningcoban.com/2017/03/04/overfitting/"
    },
    {
        "id": "40.main-1",
        "source": "40.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#1-gi%e1%bb%9bi-thi%e1%bb%87u) + [Gradient Descent](#gradient-descent) * [2. Gradient Descent cho hàm 1 biến](#2-gradient-descent-cho-h%c3%a0m-1-bi%e1%ba%bfn) + [Ví dụ đơn giản với Python](#v%c3%ad-d%e1%bb%a5-%c4%91%c6%a1n-gi%e1%ba%a3n-v%e1%bb%9bi-python) - [Điểm khởi tạo khác nhau](#%c4%90i%e1%bb%83m-kh%e1%bb%9fi-t%e1%ba%a1o-kh%c3%a1c-nhau) - [Learning rate khác nhau](#learning-rate-kh%c3%a1c-nhau) * [3. Gradient Descent cho hàm nhiều biến](#3-gradient-descent-cho-h%c3%a0m-nhi%e1%bb%81u-bi%e1%ba%bfn) + [Quay lại với bài toán Linear Regression](#quay-l%e1%ba%a1i-v%e1%bb%9bi-b%c3%a0i-to%c3%a1n-linear-regression) + [Sau đây là ví dụ trên Python và một vài lưu ý khi lập trình](#sau-%c4%91%c3%a2y-l%c3%a0-v%c3%ad-d%e1%bb%a5-tr%c3%aan-python-v%c3%a0-m%e1%bb%99t-v%c3%a0i-l%c6%b0u-%c3%bd-khi-l%e1%ba%adp-tr%c3%acnh) - [Kiểm tra đạo hàm](#ki%e1%bb%83m-tra-%c4%91%e1%ba%a1o-h%c3%a0m) * [Giải thích bằng hình học](#gi%e1%ba%a3i-th%c3%adch-b%e1%ba%b1ng-h%c3%acnh-h%e1%bb%8dc) * [Giải thích bằng giải tích](#gi%e1%ba%a3i-th%c3%adch-b%e1%ba%b1ng-gi%e1%ba%a3i-t%c3%adch) * [Với hàm nhiều biến](#v%e1%bb%9bi-h%c3%a0m-nhi%e1%bb%81u-bi%e1%ba%bfn) - [Đường đồng mức (level sets)](#%c4%90%c6%b0%e1%bb%9dng-%c4%91%e1%bb%93ng-m%e1%bb%a9c-level-sets) * [4. Một ví dụ khác](#4-m%e1%bb%99t-v%c3%ad-d%e1%bb%a5-kh%c3%a1c) * [5. Thảo luận](#5-th%e1%ba%a3o-lu%e1%ba%adn) * [6. Tài liệu tham khảo](#6-t%c3%a0i-li%e1%bb%87u-tham-kh%e1%ba%a3o)",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-2",
        "source": "40.main.md",
        "section": "1. Giới thiệu",
        "content": "Các bạn hẳn thấy hình vẽ dưới đây quen thuộc: ![](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/GD/gradient_descent.png?raw=true) Điểm màu xanh lục là điểm local minimum (cực tiểu), và cũng là điểm làm cho hàm số đạt giá trị nhỏ nhất. Từ đây trở đi, tôi sẽ dùng *local minimum* để thay cho *điểm cực tiểu*, *global minimum* để thay cho *điểm mà tại đó hàm số đạt giá trị nhỏ nhất*. Global minimum là một trường hợp đặc biệt của local minimum. Giả sử chúng ta đang quan tâm đến một hàm số một biến có đạo hàm mọi nơi. Xin cho tôi được nhắc lại vài điều đã quá quen thuộc: 1. Điểm local minimum \\(x^\\*\\) của hàm số là điểm có đạo hàm \\(f’(x^\\*)\\) bằng 0. Hơn thế nữa, trong lân cận của nó, đạo hàm của các điểm phía bên trái \\(x^\\*\\) là không dương, đạo hàm của các điểm phía bên phải \\(x^\\*\\) là không âm. 2. Đường tiếp tuyến với đồ thị hàm số đó tại 1 điểm bất kỳ có hệ số góc chính bằng đạo hàm của hàm số tại điểm đó. Trong hình phía trên, các điểm bên trái của điểm local minimum màu xanh lục có đạo hàm âm, các điểm bên phải có đạo hàm dương. Và đối với hàm số này, càng xa về phía trái của điểm local minimum thì đạo hàm càng âm, càng xa về phía phải thì đạo hàm càng dương.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-3",
        "source": "40.main.md",
        "section": "Gradient Descent",
        "content": "Trong Machine Learning nói riêng và Toán Tối Ưu nói chung, chúng ta thường xuyên phải tìm giá trị nhỏ nhất (hoặc đôi khi là lớn nhất) của một hàm số nào đó. Ví dụ như các hàm mất mát trong hai bài [Linear Regression](/2016/12/28/linearregression/) và [K-means Clustering](/2017/01/01/kmeans/). Nhìn chung, việc tìm global minimum của các hàm mất mát trong Machine Learning là rất phức tạp, thậm chí là bất khả thi. Thay vào đó, người ta thường cố gắng tìm các điểm local minimum, và ở một mức độ nào đó, coi đó là nghiệm cần tìm của bài toán. Các điểm local minimum là nghiệm của phương trình đạo hàm bằng 0. Nếu bằng một cách nào đó có thể tìm được toàn bộ (hữu hạn) các điểm cực tiểu, ta chỉ cần thay từng điểm local minimum đó vào hàm số rồi tìm điểm làm cho hàm có giá trị nhỏ nhất (*đoạn này nghe rất quen thuộc, đúng không?*). Tuy nhiên, trong hầu hết các trường hợp, việc giải phương trình đạo hàm bằng 0 là bất khả thi. Nguyên nhân có thể đến từ sự phức tạp của dạng của đạo hàm, từ việc các điểm dữ liệu có số chiều lớn, hoặc từ việc có quá nhiều điểm dữ liệu. Hướng tiếp cận phổ biến nhất là xuất phát từ một điểm mà chúng ta coi là *gần* với nghiệm của bài toán, sau đó dùng một phép toán lặp để *tiến dần* đến điểm cần tìm, tức đến khi đạo hàm gần với 0. Gradient Descent (viết gọn là GD) và các biến thể của nó là một trong những phương pháp được dùng nhiều nhất. Vì kiến thức về GD khá rộng nên tôi xin phép được chia thành hai phần. Phần 1 này giới thiệu ý tưởng phía sau thuật toán GD và một vài ví dụ đơn giản giúp các bạn làm quen với thuật toán này và vài khái niệm mới. Phần 2 sẽ nói về các phương pháp cải tiến GD và các biến thể của GD trong các bài toán mà số chiều và số điểm dữ liệu lớn. Những bài toán như vậy được gọi là *large-scale*.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-4",
        "source": "40.main.md",
        "section": "2. Gradient Descent cho hàm 1 biến",
        "content": "Quay trở lại hình vẽ ban đầu và một vài quan sát tôi đã nêu. Giả sử \\(x\\_{t}\\) là điểm ta tìm được sau vòng lặp thứ \\(t\\). Ta cần tìm một thuật toán để đưa \\(x\\_{t}\\) về càng gần \\(x^\\*\\) càng tốt. Trong hình đầu tiên, chúng ta lại có thêm hai quan sát nữa: 1. Nếu đạo hàm của hàm số tại \\(x\\_{t}\\): \\(f’(x\\_{t}) > 0\\) thì \\(x\\_{t}\\) nằm về bên phải so với \\(x^\\*\\) (và ngược lại). Để điểm tiếp theo \\(x\\_{t+1}\\) gần với \\(x^\\*\\) hơn, chúng ta cần di chuyển \\(x\\_{t}\\) về phía bên trái, tức về phía *âm*. Nói các khác, **chúng ta cần di chuyển ngược dấu với đạo hàm**: \\[ x\\_{t+1} = x\\_{t} + \\Delta \\] Trong đó \\(\\Delta\\) là một đại lượng ngược dấu với đạo hàm \\(f’(x\\_{t})\\). 2. \\(x\\_{t}\\) càng xa \\(x^\\*\\) về phía bên phải thì \\(f’(x\\_{t})\\) càng lớn hơn 0 (và ngược lại). Vậy, lượng di chuyển \\(\\Delta\\), một cách trực quan nhất, là tỉ lệ thuận với \\(-f’(x\\_{t})\\). Hai nhận xét phía trên cho chúng ta một cách cập nhật đơn giản là: \\[ x\\_{t+1} = x\\_{t} - \\eta f’(x\\_{t}) \\] Trong đó \\(\\eta\\) (đọc là *eta*) là một số dương được gọi là *learning rate* (tốc độ học). Dấu trừ thể hiện việc chúng ta phải *đi ngược* với đạo hàm (Đây cũng chính là lý do phương pháp này được gọi là Gradient Descent - *descent* nghĩa là *đi ngược*). Các quan sát đơn giản phía trên, mặc dù không phải đúng cho tất cả các bài toán, là nền tảng cho rất nhiều phương pháp tối ưu nói chung và thuật toán Machine Learning nói riêng.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-5",
        "source": "40.main.md",
        "section": "Ví dụ đơn giản với Python",
        "content": "Xét hàm số \\(f(x) = x^2 + 5\\sin(x)\\) với đạo hàm \\(f’(x) = 2x + 5\\cos(x)\\) (một lý do tôi chọn hàm này vì nó không dễ tìm nghiệm của đạo hàm bằng 0 như hàm phía trên). Giả sử bắt đầu từ một điểm \\(x\\_{0}\\) nào đó, tại vòng lặp thứ \\(t\\), chúng ta sẽ cập nhật như sau: \\[ x\\_{t+1} = x\\_{t} - \\eta(2x\\_{t} + 5\\cos(x\\_{t})) \\] Như thường lệ, tôi khai báo vài thư viện quen thuộc ```",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-6",
        "source": "40.main.md",
        "section": "To support both python 2 and python 3",
        "content": "from __future__ import division, print_function, unicode_literals import math import numpy as np import matplotlib.pyplot as plt ``` Tiếp theo, tôi viết các hàm số : 1. `grad` để tính đạo hàm 2. `cost` để tính giá trị của hàm số. Hàm này không sử dụng trong thuật toán nhưng thường được dùng để kiểm tra việc tính đạo hàm của đúng không hoặc để xem giá trị của hàm số có giảm theo mỗi vòng lặp hay không. 3. `myGD1` là phần chính thực hiện thuật toán Gradient Desent nêu phía trên. Đầu vào của hàm số này là learning rate và điểm bắt đầu. Thuật toán dừng lại khi đạo hàm có độ lớn đủ nhỏ. ``` def grad(x): return 2*x+ 5*np.cos(x) def cost(x): return x**2 + 5*np.sin(x) def myGD1(eta, x0): x = [x0] for it in range(100): x_new = x[-1] - eta*grad(x[-1]) if abs(grad(x_new)) < 1e-3: break x.append(x_new) return (x, it) ```",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-7",
        "source": "40.main.md",
        "section": "Điểm khởi tạo khác nhau",
        "content": "Sau khi có các hàm cần thiết, tôi thử tìm nghiệm với các điểm khởi tạo khác nhau là \\(x\\_{0} = -5\\) và \\(x\\_{0} = 5\\). ``` (x1, it1) = myGD1(.1, -5) (x2, it2) = myGD1(.1, 5) print('Solution x1 = %f, cost = %f, obtained after %d iterations'%(x1[-1], cost(x1[-1]), it1)) print('Solution x2 = %f, cost = %f, obtained after %d iterations'%(x2[-1], cost(x2[-1]), it2)) ``` ``` Solution x1 = -1.110667, cost = -3.246394, obtained after 11 iterations Solution x2 = -1.110341, cost = -3.246394, obtained after 29 iterations ``` Vậy là với các điểm ban đầu khác nhau, thuật toán của chúng ta tìm được nghiệm gần giống nhau, mặc dù với tốc độ hội tụ khác nhau. Dưới đây là hình ảnh minh họa thuật toán GD cho bài toán này (*xem tốt trên Desktop ở chế độ full màn hình*). |  |  | | --- | --- | |  |  | Từ hình minh họa trên ta thấy rằng ở hình bên trái, tương ứng với \\(x\\_{0} = -5\\), nghiệm hội tụ nhanh hơn, vì điểm ban đầu \\(x\\_0\\) gần với nghiệm \\( x^\\* \\approx -1\\) hơn. Hơn nữa, với \\(x\\_{0} = 5 \\) ở hình bên phải, *đường đi* của nghiệm có chứa một khu vực có đạo hàm khá nhỏ gần điểm có hoành độ bằng 2. Điều này khiến cho thuật toán *la cà* ở đây khá lâu. Khi vượt qua được điểm này thì mọi việc diễn ra rất tốt đẹp.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-8",
        "source": "40.main.md",
        "section": "Learning rate khác nhau",
        "content": "Tốc độ hội tụ của GD không những phụ thuộc vào điểm khởi tạo ban đầu mà còn phụ thuộc vào *learning rate*. Dưới đây là một ví dụ với cùng điểm khởi tạo \\(x\\_{0} = -5\\) nhưng learning rate khác nhau: |  |  | | --- | --- | |  |  | Ta quan sát thấy hai điều: 1. Với *learning rate* nhỏ \\(\\eta = 0.01\\), tốc độ hội tụ rất chậm. Trong ví dụ này tôi chọn tối đa 100 vòng lặp nên thuật toán dừng lại trước khi tới *đích*, mặc dù đã rất gần. Trong thực tế, khi việc tính toán trở nên phức tạp, *learning rate* quá thấp sẽ ảnh hưởng tới tốc độ của thuật toán rất nhiều, thậm chí không bao giờ tới được đích. 2. Với *learning rate* lớn \\(\\eta = 0.5\\), thuật toán tiến rất nhanh tới *gần đích* sau vài vòng lặp. Tuy nhiên, thuật toán không hội tụ được vì *bước nhảy* quá lớn, khiến nó cứ *quẩn quanh* ở đích. Việc lựa chọn *learning rate* rất quan trọng trong các bài toán thực tế. Việc lựa chọn giá trị này phụ thuộc nhiều vào từng bài toán và phải làm một vài thí nghiệm để chọn ra giá trị tốt nhất. Ngoài ra, tùy vào một số bài toán, GD có thể làm việc hiệu quả hơn bằng cách chọn ra *learning rate* phù hợp hoặc chọn *learning rate* khác nhau ở mỗi vòng lặp. Tôi sẽ quay lại vấn đề này ở phần 2.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-9",
        "source": "40.main.md",
        "section": "3. Gradient Descent cho hàm nhiều biến",
        "content": "Giả sử ta cần tìm global minimum cho hàm \\(f(\\mathbf{\\theta})\\) trong đó \\(\\mathbf{\\theta}\\) (*theta*) là một vector, thường được dùng để ký hiệu tập hợp các tham số của một mô hình cần tối ưu (trong Linear Regression thì các tham số chính là hệ số \\(\\mathbf{w}\\)). Đạo hàm của hàm số đó tại một điểm \\(\\theta\\) bất kỳ được ký hiệu là \\(\\nabla\\_{\\theta}f(\\theta)\\) (hình tam giác ngược đọc là *nabla*). Tương tự như hàm 1 biến, thuật toán GD cho hàm nhiều biến cũng bắt đầu bằng một điểm dự đoán \\(\\theta\\_{0}\\), sau đó, ở vòng lặp thứ \\(t\\), quy tắc cập nhật là: \\[ \\theta\\_{t+1} = \\theta\\_{t} - \\eta \\nabla\\_{\\theta} f(\\theta\\_{t}) \\] Hoặc viết dưới dạng đơn giản hơn: \\(\\theta = \\theta - \\eta \\nabla\\_{\\theta} f(\\theta)\\). Quy tắc cần nhớ: **luôn luôn đi ngược hướng với đạo hàm**. Việc tính toán đạo hàm của các hàm nhiều biến là một kỹ năng cần thiết. Một vài đạo hàm đơn giản có thể được [tìm thấy ở đây](/math/#bang-cac-dao-ham-co-ban).",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-10",
        "source": "40.main.md",
        "section": "Quay lại với bài toán Linear Regression",
        "content": "Trong mục này, chúng ta quay lại với bài toán [Linear Regression](/2016/12/28/linearregression/) và thử tối ưu hàm mất mát của nó bằng thuật toán GD. Hàm mất mát của Linear Regression là: \\[ \\mathcal{L}(\\mathbf{w}) = \\frac{1}{2N}||\\mathbf{y - \\bar{X}w}||\\_2^2 \\] **Chú ý**: hàm này có khác một chút so với hàm tôi nêu trong bài [Linear Regression](/2016/12/28/linearregression/). Mẫu số có thêm \\(N\\) là số lượng dữ liệu trong training set. Việc lấy trung bình cộng của lỗi này nhằm giúp tránh trường hợp hàm mất mát và đạo hàm có giá trị là một số rất lớn, ảnh hưởng tới độ chính xác của các phép toán khi thực hiện trên máy tính. Về mặt toán học, nghiệm của hai bài toán là như nhau. Đạo hàm của hàm mất mát là: \\[ \\nabla\\_{\\mathbf{w}}\\mathcal{L}(\\mathbf{w}) = \\frac{1}{N}\\mathbf{\\bar{X}}^T \\mathbf{(\\bar{X}w - y)} ~~~~~(1) \\]",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-11",
        "source": "40.main.md",
        "section": "Sau đây là ví dụ trên Python và một vài lưu ý khi lập trình",
        "content": "Load thư viện ```",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-12",
        "source": "40.main.md",
        "section": "To support both python 2 and python 3",
        "content": "from __future__ import division, print_function, unicode_literals import numpy as np import matplotlib import matplotlib.pyplot as plt np.random.seed(2) ``` Tiếp theo, chúng ta tạo 1000 điểm dữ liệu được chọn *gần* với đường thẳng \\(y = 4 + 3x\\), hiển thị chúng và tìm nghiệm theo công thức: ``` X = np.random.rand(1000, 1) y = 4 + 3 * X + .2*np.random.randn(1000, 1) # noise added",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-13",
        "source": "40.main.md",
        "section": "Building Xbar",
        "content": "one = np.ones((X.shape[0],1)) Xbar = np.concatenate((one, X), axis = 1) A = np.dot(Xbar.T, Xbar) b = np.dot(Xbar.T, y) w_lr = np.dot(np.linalg.pinv(A), b) print('Solution found by formula: w = ',w_lr.T)",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-14",
        "source": "40.main.md",
        "section": "Display result",
        "content": "w = w_lr w_0 = w[0][0] w_1 = w[1][0] x0 = np.linspace(0, 1, 2, endpoint=True) y0 = w_0 + w_1*x0",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-15",
        "source": "40.main.md",
        "section": "Draw the fitting line",
        "content": "plt.plot(X.T, y.T, 'b.')     # data plt.plot(x0, y0, 'y', linewidth = 2)   # the fitting line plt.axis([0, 1, 0, 10]) plt.show() ``` ``` Solution found by formula: w =  [[ 4.00305242  2.99862665]] ``` ![](/assets/GD/output_11_1.png) Đường thẳng tìm được là đường có màu vàng có phương trình \\(y \\approx 4 + 2.998x\\). Tiếp theo ta viết đạo hàm và hàm mất mát: ``` def grad(w): N = Xbar.shape[0] return 1/N * Xbar.T.dot(Xbar.dot(w) - y) def cost(w): N = Xbar.shape[0] return .5/N*np.linalg.norm(y - Xbar.dot(w), 2)**2; ```",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-16",
        "source": "40.main.md",
        "section": "Kiểm tra đạo hàm",
        "content": "Việc tính đạo hàm của hàm nhiều biến thông thường khá phức tạp và rất dễ mắc lỗi, nếu chúng ta tính sai đạo hàm thì thuật toán GD không thể chạy đúng được. Trong thực nghiệm, có một cách để kiểm tra liệu đạo hàm tính được có chính xác không. Cách này dựa trên định nghĩa của đạo hàm (cho hàm 1 biến): \\[ f’(x) = \\lim\\_{\\varepsilon \\rightarrow 0}\\frac{f(x + \\varepsilon) - f(x)}{\\varepsilon} \\] Một cách thường được sử dụng là lấy một giá trị \\(\\varepsilon \\) rất nhỏ, ví dụ \\(10^{-6}\\), và sử dụng công thức: \\[ f’(x) \\approx \\frac{f(x + \\varepsilon) - f(x - \\varepsilon)}{2\\varepsilon} ~~~~ (2) \\] Cách tính này được gọi là *numerical gradient*. **Câu hỏi: Tại sao công thức xấp xỉ hai phía trên đây lại được sử dụng rộng rãi, sao không sử dụng công thức xấp xỉ đạo hàm bên phải hoặc bên trái?** Có hai các giải thích cho vấn đề này, một bằng hình học, một bằng giải tích.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-17",
        "source": "40.main.md",
        "section": "Giải thích bằng hình học",
        "content": "Quan sát hình dưới đây: ![](/assets/GD/check_grad.png) Trong hình, vector màu đỏ là đạo hàm *chính xác* của hàm số tại điểm có hoành độ bằng \\(x\\_0\\). Vector màu xanh lam (có vẻ là hơi tím sau khi convert từ .pdf sang .png) thể hiện cách xấp xỉ đạo hàm phía phải. Vector màu xanh lục thể hiện cách xấp xỉ đạo hàm phía trái. Vector màu nâu thể hiện cách xấp xỉ đạo hàm hai phía. Trong ba vector xấp xỉ đó, vector xấp xỉ hai phía màu nâu là gần với vector đỏ nhất nếu xét theo hướng. Sự khác biệt giữa các cách xấp xỉ còn lớn hơn nữa nếu tại điểm x, hàm số bị *bẻ cong* mạnh hơn. Khi đó, xấp xỉ trái và phải sẽ khác nhau rất nhiều. Xấp xỉ hai bên sẽ *ổn định* hơn.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-18",
        "source": "40.main.md",
        "section": "Giải thích bằng giải tích",
        "content": "Chúng ta cùng quay lại một chút với Giải tích I năm thứ nhất đại học: [Khai triển Taylor](http://mathworld.wolfram.com/TaylorSeries.html). Với \\(\\varepsilon\\) rất nhỏ, ta có hai xấp xỉ sau: \\[ f(x + \\varepsilon) \\approx f(x) + f’(x)\\varepsilon + \\frac{f”(x)}{2} \\varepsilon^2 + \\dots \\] và: \\[ f(x - \\varepsilon) \\approx f(x) - f’(x)\\varepsilon + \\frac{f”(x)}{2} \\varepsilon^2 - \\dots \\] Từ đó ta có: \\[ \\frac{f(x + \\varepsilon) - f(x)}{\\varepsilon} \\approx f’(x) + \\frac{f”(x)}{2}\\varepsilon + \\dots = f’(x) + O(\\varepsilon) ~~ (3) \\] \\[ \\frac{f(x + \\varepsilon) - f(x - \\varepsilon)}{2\\varepsilon} \\approx f’(x) + \\frac{f^{(3)}(x)}{6}\\varepsilon^2 + \\dots = f’(x) + O(\\varepsilon^2) ~~(4) \\] Từ đó, nếu xấp xỉ đạo hàm bằng công thức \\((3)\\) (xấp xỉ đạo hàm phải), sai số sẽ là \\(O(\\varepsilon)\\). Trong khi đó, nếu xấp xỉ đạo hàm bằng công thức \\((4)\\) (xấp xỉ đạo hàm hai phía), sai số sẽ là \\(O(\\varepsilon^2) \\ll O(\\varepsilon)\\) nếu \\(\\varepsilon\\) nhỏ. Cả hai cách giải thích trên đây đều cho chúng ta thấy rằng, xấp xỉ đạo hàm hai phía là xấp xỉ tốt hơn.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-19",
        "source": "40.main.md",
        "section": "Với hàm nhiều biến",
        "content": "Với hàm nhiều biến, công thức \\((2)\\) được áp dụng cho từng biến khi các biến khác cố định. Cách tính này thường cho giá trị khá chính xác. Tuy nhiên, cách này không được sử dụng để tính đạo hàm vì độ phức tạp quá cao so với cách tính trực tiếp. Khi so sánh đạo hàm này với đạo hàm chính xác tính theo công thức, người ta thường giảm số chiều dữ liệu và giảm số điểm dữ liệu để thuận tiện cho tính toán. Một khi đạo hàm tính được rất gần với *numerical gradient*, chúng ta có thể tự tin rằng đạo hàm tính được là chính xác. Dưới đây là một đoạn code đơn giản để kiểm tra đạo hàm và có thể áp dụng với một hàm số (của một vector) bất kỳ với `cost` và `grad` đã tính ở phía trên. ``` def numerical_grad(w, cost): eps = 1e-4 g = np.zeros_like(w) for i in range(len(w)): w_p = w.copy() w_n = w.copy() w_p[i] += eps w_n[i] -= eps g[i] = (cost(w_p) - cost(w_n))/(2*eps) return g def check_grad(w, cost, grad): w = np.random.rand(w.shape[0], w.shape[1]) grad1 = grad(w) grad2 = numerical_grad(w, cost) return True if np.linalg.norm(grad1 - grad2) < 1e-6 else False print( 'Checking gradient...', check_grad(np.random.rand(2, 1), cost, grad)) ``` ``` Checking gradient... True ``` (*Với các hàm số khác, bạn đọc chỉ cần viết lại hàm `grad` và `cost` ở phần trên rồi áp dụng đoạn code này để kiểm tra đạo hàm. Nếu hàm số là hàm của một ma trận thì chúng ta thay đổi một chút trong hàm `numerical_grad`, tôi hy vọng không quá phức tạp*). Với bài toán Linear Regression, cách tính đạo hàm như trong \\((1)\\) phía trên được coi là đúng vì sai số giữa hai cách tính là rất nhỏ (nhỏ hơn \\(10^{-6}\\)). Sau khi có được đạo hàm chính xác, chúng ta viết hàm cho GD: ``` def myGD(w_init, grad, eta): w = [w_init] for it in range(100): w_new = w[-1] - eta*grad(w[-1]) if np.linalg.norm(grad(w_new))/len(w_new) < 1e-3: break w.append(w_new) return (w, it) w_init = np.array([[2], [1]]) (w1, it1) = myGD(w_init, grad, 1) print('Solution found by GD: w = ', w1[-1].T, ',\\nafter %d iterations.' %(it1+1)) ``` ``` Solution found by GD: w =  [[ 4.01780793  2.97133693]] , after 49 iterations. ``` Sau 49 vòng lặp, thuật toán đã hội tụ với một nghiệm khá gần với nghiệm tìm được theo công thức. Dưới đây là hình động minh họa thuật toán GD. |  |  | | --- | --- | |  |  | Trong hình bên trái, các đường thẳng màu đỏ là nghiệm tìm được sau mỗi vòng lặp. Trong hình bên phải, tôi xin giới thiệu một thuật ngữ mới: *đường đồng mức*.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-20",
        "source": "40.main.md",
        "section": "Đường đồng mức (level sets)",
        "content": "Với đồ thị của một hàm số với hai biến đầu vào cần được vẽ trong không gian ba chiều, nhều khi chúng ta khó nhìn được nghiệm có khoảng tọa độ bao nhiêu. Trong toán tối ưu, người ta thường dùng một cách vẽ sử dụng khái niệm *đường đồng mức* (level sets). Nếu các bạn để ý trong các bản độ tự nhiên, để miêu tả độ cao của các dãy núi, người ta dùng nhiều đường cong kín bao quanh nhau như sau: ![](http://files.vforum.vn/2016/T06/img/vforum.vn-324944-hinh-44-lc6b0e1bba3c-c491e1bb93-c491e1bb8ba-hc3acnh-te1bb89-le1bb87-le1bb9bn.png) Ví dụ về đường đồng mức trong các bản đồ tự nhiên. (Nguồn: [Địa lý 6: Đường đồng mức là những đường như thế nào?](http://vforum.vn/diendan/showthread.php?90166-Dia-ly-6-Duong-dong-muc-la-nhung-duong-nhu-the-nao-)) Các vòng nhỏ màu đỏ hơn thể hiện các điểm ở trên cao hơn. Trong toán tối ưu, người ta cũng dùng phương pháp này để thể hiện các bề mặt trong không gian hai chiều. Quay trở lại với hình minh họa thuật toán GD cho bài toán Liner Regression bên trên, hình bên phải là hình biểu diễn các level sets. Tức là tại các điểm trên cùng một vòng, hàm mất mát có giá trị như nhau. Trong ví dụ này, tôi hiển thị giá trị của hàm số tại một số vòng. Các vòng màu xanh có giá trị thấp, các vòng tròn màu đỏ phía ngoài có giá trị cao hơn. Điểm này khác một chút so với đường đồng mức trong tự nhiên là các vòng bên trong thường thể hiện một thung lũng hơn là một đỉnh núi (vì chúng ta đang đi tìm giá trị nhỏ nhất). Tôi thử với *learning rate* nhỏ hơn, kết quả như sau: |  |  | | --- | --- | |  |  | Tốc độ hội tụ đã chậm đi nhiều, thậm chí sau 99 vòng lặp, GD vẫn chưa tới gần được nghiệm tốt nhất. Trong các bài toán thực tế, chúng ta cần nhiều vòng lặp hơn 99 rất nhiều, vì số chiều và số điểm dữ liệu thường là rất lớn.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-21",
        "source": "40.main.md",
        "section": "4. Một ví dụ khác",
        "content": "Để kết thúc phần 1 của Gradient Descent, tôi xin nêu thêm một ví dụ khác. ![](/assets/GD/img3_0.015.gif) Hàm số \\(f(x, y) = (x^2 + y - 7)^2 + (x - y + 1)^2\\) có hai điểm local minimum màu xanh lục tại \\((2, 3)\\) và \\((-3, -2)\\), và chúng cũng là hai điểm global minimum. Trong ví dụ này, tùy vào điểm khởi tạo mà chúng ta thu được các nghiệm cuối cùng khác nhau.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-22",
        "source": "40.main.md",
        "section": "5. Thảo luận",
        "content": "Dựa trên GD, có rất nhiều thuật toán phức tạp và hiệu quả hơn được thiết kế cho những loại bài toán khác nhau. Vì bài này đã đủ dài, tôi xin phép dừng lại ở đây. Mời các bạn đón đọc bài Gradient Descent phần 2 với nhiều kỹ thuật nâng cao hơn.",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "40.main-23",
        "source": "40.main.md",
        "section": "6. Tài liệu tham khảo",
        "content": "1. [An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/) 2. [An Interactive Tutorial on Numerical Optimization](http://www.benfrederickson.com/numerical-optimization/) 3. [Gradient Descent by Andrew NG](https://www.youtube.com/watch?v=eikJboPQDT0)",
        "url": "https://machinelearningcoban.com/2017/01/12/gradientdescent/"
    },
    {
        "id": "7.main-1",
        "source": "7.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Accuracy](#-accuracy) * [3. Confusion matrix](#-confusion-matrix) * [4. True/False Positive/Negative](#-truefalse-positivenegative) + [4.1. True/False Positive/Negative](#-truefalse-positivenegative-1) + [4.2. Receiver Operating Characteristic curve](#-receiver-operating-characteristic-curve) + [4.3. Area Under the Curve](#-area-under-the-curve) * [5. Precision và Recall](#-precision-va-recall) + [5.1 Định nghĩa](#-dinh-nghia) + [5.2. Precision-Recall curve và Average precision](#-precision-recall-curve-va-average-precision) + [5.3. F1-score](#-f-score) + [5.4. Precision-recall cho bài toán phân lớp nhiều lớp](#-precision-recall-cho-bai-toan-phan-lop-nhieu-lop) - [5.4.1. Micro-average](#-micro-average) - [5.4.2. Macro-average](#-macro-average) * [6. Tóm tắt](#-tom-tat) * [7. Tài liệu tham khảo](#-tai-lieu-tham-khao) Bạn có thể download toàn bộ source code dưới dạng Jupyter Notebook [tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/33_evaluation/python/Evaluation%20methods.ipynb).",
        "url": "https://machinelearningcoban.com/2017/08/31/evaluation/"
    },
    {
        "id": "7.main-2",
        "source": "7.main.md",
        "section": "1. Giới thiệu",
        "content": "Khi xây dựng một mô hình Machine Learning, chúng ta cần một phép đánh giá để xem mô hình sử dụng có hiệu quả không và để so sánh khả năng của các mô hình. Trong bài viết này, tôi sẽ giới thiệu các phương pháp đánh giá các mô hình classification. Hiệu năng của một mô hình thường được đánh giá dựa trên tập dữ liệu kiểm thử (test data). Cụ thể, giả sử đầu ra của mô hình khi đầu vào là tập kiểm thử được mô tả bởi vector `y_pred` - là vector dự đoán đầu ra với mỗi phần tử là class được dự đoán của một điểm dữ liệu trong tập kiểm thử. Ta cần so sánh giữa vector dự đoán `y_pred` này với vector class *thật* của dữ liệu, được mô tả bởi vector `y_true`. Ví dụ với bài toán có 3 lớp dữ liệu được gán nhãn là `0, 1, 2`. Trong bài toán thực tế, các class có thể có nhãn bất kỳ, không nhất thiết là số, và không nhất thiết bắt đầu từ `0`. Chúng ta hãy tạm giả sử các class được đánh số từ `0` đến `C-1` trong trường hợp có `C` lớp dữ liệu. Có 10 điểm dữ liệu trong tập kiểm thử với các nhãn thực sự được mô tả bởi `y_true = [0, 0, 0, 0, 1, 1, 1, 2, 2, 2]`. Giả sử bộ phân lớp chúng ta đang cần đánh giá dự đoán nhãn cho các điểm này là `y_pred = [0, 1, 0, 2, 1, 1, 0, 2, 1, 2]`. Có rất nhiều cách đánh giá một mô hình phân lớp. Tuỳ vào những bài toán khác nhau mà chúng ta sử dụng các phương pháp khác nhau. Các phương pháp thường được sử dụng là: accuracy score, confusion matrix, ROC curve, Area Under the Curve, Precision and Recall, F1 score, Top R error, etc. Trong Phần 1 này, tôi sẽ trình bày về accuracy score, confusion matrix, ROC curve, và Area Under the Curve. Các phương pháp còn lại sẽ được trình bày trong Phần 2.",
        "url": "https://machinelearningcoban.com/2017/08/31/evaluation/"
    },
    {
        "id": "7.main-3",
        "source": "7.main.md",
        "section": "2. Accuracy",
        "content": "Cách đơn giản và hay được sử dụng nhất là *accuracy* (độ chính xác). Cách đánh giá này đơn giản tính tỉ lệ giữa số điểm được dự đoán đúng và tổng số điểm trong tập dữ liệu kiểm thử. Trong ví dụ này, ta có thể đếm được có 6 điểm dữ liệu được dự đoán đúng trên tổng số 10 điểm. Vậy ta kết luận độ chính xác của mô hình là 0.6 (hay 60%). Để ý rằng đây là bài toán với chỉ 3 class, nên độ chính xác nhỏ nhất đã là khoảng 1/3, khi tất cả các điểm được dự đoán là thuộc vào một class nào đó. ``` from __future__ import print_function import numpy as np def acc(y_true, y_pred): correct = np.sum(y_true == y_pred) return float(correct)/y_true.shape[0] y_true = np.array([0, 0, 0, 0, 1, 1, 1, 2, 2, 2]) y_pred = np.array([0, 1, 0, 2, 1, 1, 0, 2, 1, 2]) print('accuracy = ', acc(y_true, y_pred)) ``` ``` accuracy =  0.6 ``` Và đây là [cách tính bằng thư viên](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html): ``` from sklearn.metrics import accuracy_score print('accuracy = ',accuracy_score(y_true, y_pred)) ``` ``` accuracy =  0.6 ```",
        "url": "https://machinelearningcoban.com/2017/08/31/evaluation/"
    },
    {
        "id": "7.main-4",
        "source": "7.main.md",
        "section": "3. Confusion matrix",
        "content": "Cách tính sử dụng accuracy như ở trên chỉ cho chúng ta biết được bao nhiêu phần trăm lượng dữ liệu được phân loại đúng mà không chỉ ra được cụ thể mỗi loại được phân loại như thế nào, lớp nào được phân loại đúng nhiều nhất, và dữ liệu thuộc lớp nào thường bị phân loại nhầm vào lớp khác. Để có thể đánh giá được các giá trị này, chúng ta sử dụng một ma trận được gọi là *confusion matrix*. Về cơ bản, confusion matrix thể hiện có bao nhiêu điểm dữ liệu *thực sự* thuộc vào một class, và được *dự đoán* là rơi vào một class. Để hiểu rõ hơn, hãy xem bảng dưới đây: ``` Total: 10 | Predicted | Predicted | Predicted | |    as: 0  |    as: 1  |    as: 2  | -----------|-----------|-----------|-----------|--- True: 0   |     2     |     1     |     1     | 4 -----------|-----------|-----------|-----------|--- True: 1   |     1     |     2     |     0     | 3 -----------|-----------|-----------|-----------|--- True: 2   |     0     |     1     |     2     | 3 -----------|-----------|-----------|-----------|--- ``` Có tổng cộng 10 điểm dữ liệu. Chúng ta xét ma trận tạo bởi các giá trị tại vùng 3x3 trung tâm của bảng. Ma trận thu được được gọi là *confusion matrix*. Nó là một ma trận vuông với kích thước mỗi chiều bằng số lượng lớp dữ liệu. Giá trị tại hàng thứ `i`, cột thứ `j` là số lượng điểm **lẽ ra thuộc vào class `i` nhưng lại được dự đoán là thuộc vào class `j`**. Như vậy, nhìn vào hàng thứ nhất (`0`), ta có thể thấy được rằng trong số bốn điểm thực sự thuộc lớp `0`, chỉ có hai điểm được phân loại đúng, hai điểm còn lại bị phân loại nhầm vào lớp `1` và lớp `2`. ***Chú ý:** Có một số tài liệu định nghĩa ngược lại, tức giá trị tại **cột** thứ `i`, **hàng** thứ `j` là số lượng điểm lẽ ra thuộc vào class `i` nhưng lại được dự đoán là thuộc vào class `j`. Khi đó ta sẽ được confusion matrix là ma trận chuyển vị của confusion matrix như cách tôi đang làm. Tôi chọn cách này vì đây chính là cách thư viện sklearn sử dụng.* Chúng ta có thể suy ra ngay rằng tổng các phần tử trong toàn ma trận này chính là số điểm trong tập kiểm thử. Các phần tử trên đường chéo của ma trận là số điểm được phân loại đúng của mỗi lớp dữ liệu. Từ đây có thể suy ra *accuracy* chính bằng tổng các phần tử trên đường chéo chia cho tổng các phần tử của toàn ma trận. Đoạn code dưới đây mô tả cách tính confusion matrix: ``` def my_confusion_matrix(y_true, y_pred): N = np.unique(y_true).shape[0] # number of classes cm = np.zeros((N, N)) for n in range(y_true.shape[0]): cm[y_true[n], y_pred[n]] += 1 return cm cnf_matrix = my_confusion_matrix(y_true, y_pred) print('Confusion matrix:') print(cnf_matrix) print('\\nAccuracy:', np.diagonal(cnf_matrix).sum()/cnf_matrix.sum()) ``` ``` Confusion matrix: [[ 2.  1.  1.] [ 1.  2.  0.] [ 0.  1.  2.]] Accuracy: 0.6 ``` Cách biểu diễn trên đây của confusion matrix còn được gọi là *unnormalized confusion matrix*, tức ma *confusion matrix* chưa chuẩn hoá. Để có cái nhìn rõ hơn, ta có thể dùng *normalized confuion matrix*, tức *confusion matrix* được chuẩn hoá. Để có *normalized confusion matrix*, ta lấy mỗi hàng của *unnormalized confusion matrix* sẽ được chia cho tổng các phần tử trên hàng đó. Như vậy, ta có nhận xét rằng tổng các phần tử trên một hàng của *normalized confusion matrix* luôn bằng 1. Điều này thường không đúng trên mỗi cột. Dưới đây là cách tính *normalized confusion matrix*: ``` normalized_confusion_matrix = cnf_matrix/cnf_matrix.sum(axis = 1, keepdims = True) print('\\nConfusion matrix (with normalizatrion:)') print(normalized_confusion_matrix) ``` ``` Confusion matrix (with normalizatrion:) [[ 0.5         0.25        0.25      ] [ 0.33333333  0.66666667  0.        ] [ 0.          0.33333333  0.66666667]] ``` Và cách tính [sử dụng thư viện](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html): ``` from sklearn.metrics import confusion_matrix cnf_matrix = confusion_matrix(y_true, y_pred) print('Confusion matrix:') print(cnf_matrix) ``` ``` Confusion matrix: [[2 1 1] [1 2 0] [0 1 2]] ``` Confusion matrix thường được minh hoạ bằng màu sắc để có cái nhìn rõ ràng hơn. Đoạn code dưới đây giúp hiển thị confusion matrix ở cả hai dạng (Nguồn: [Confusion matrix](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)): ``` import matplotlib.pyplot as plt import itertools def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues): \"\"\" This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. \"\"\" if normalize: cm = cm.astype('float') / cm.sum(axis=1, keepdims = True) plt.imshow(cm, interpolation='nearest', cmap=cmap) plt.title(title) plt.colorbar() tick_marks = np.arange(len(classes)) plt.xticks(tick_marks, classes, rotation=45) plt.yticks(tick_marks, classes) fmt = '.2f' if normalize else 'd' thresh = cm.max() / 2. for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\") plt.tight_layout() plt.ylabel('True label') plt.xlabel('Predicted label')",
        "url": "https://machinelearningcoban.com/2017/08/31/evaluation/"
    },
    {
        "id": "7.main-5",
        "source": "7.main.md",
        "section": "Plot non-normalized confusion matrix",
        "content": "class_names = [0, 1, 2] plt.figure() plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')",
        "url": "https://machinelearningcoban.com/2017/08/31/evaluation/"
    },
    {
        "id": "7.main-6",
        "source": "7.main.md",
        "section": "Plot normalized confusion matrix",
        "content": "plt.figure() plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix') plt.show() ``` --- |  |  | | --- | --- | |  |  | Hình 1: Minh hoạ  *unnormalized confusion matrix*  và  *normalized confusion matrix* . ---",
        "url": "https://machinelearningcoban.com/2017/08/31/evaluation/"
    },
    {
        "id": "14.main-1",
        "source": "14.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Maximum Likelihood Estimation](#-maximum-likelihood-estimation) + [2.1. Ý tưởng](#-y-tuong) + [2.2. Independence Assumption và log-likelihood](#-independence-assumption-va-log-likelihood) + [2.3. Ví dụ](#-vi-du) - [2.3.1. Ví dụ 1: Bernoulli distribution](#-vi-du--bernoulli-distribution) - [2.3.2. Ví dụ 2: Categorical distribution](#-vi-du--categorical-distribution) - [2.3.3. Ví dụ 3: Univariate normal distribution](#-vi-du--univariate-normal-distribution) - [2.3.4. Ví dụ 4: Multivariate normal distribution](#-vi-du--multivariate-normal-distribution) * [3. Maximum a Posteriori](#-maximum-a-posteriori) + [3.1. Ý tưởng](#-y-tuong-1) + [3.2. Conjugate prior](#-conjugate-prior) + [3.3. Hyperparameters](#-hyperparameters) + [3.4. MAP giúp tránh overfitting](#-map-giup-tranh-overfitting) * [4. Tóm tắt](#-tom-tat) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/07/17/mlemap/"
    },
    {
        "id": "14.main-2",
        "source": "14.main.md",
        "section": "1. Giới thiệu",
        "content": "**Những sự kiện có xác suất cao là những sự kiện có khả năng xảy ra hơn.** Câu nói *nói cũng như không này* là khơi nguồn cho rất nhiều các thuật toán Machine Learning có liên quan đến xác suất. Cách giải quyết bài toán Machine Learning có thể viết gọn lại thành 3 bước chính: **Modeling, Learning** và **Inference**. (Xem [Computer Vision: Models, Learning, and Inference](http://www.computervisionmodels.com/)) **Modeling là việc đi tìm môt mô hình thích hợp cho bài toán cần giải quyết.** Với bài toán [Linear Regression](/2016/12/28/linearregression/), modeling chính là việc mô hình dữ liệu đầu ra (output) như là tổ hợp tuyến tính của dữ liệu đầu vào (input). Với bài toán [k-means clustering](/2017/01/01/kmeans/), modeling chính là việc quan sát ra rằng các clusters thường được mô tả bởi các *centroids* (hoặc *centers*) và mỗi điểm được xếp vào cluster tương ứng với centroid gần nó nhất. Trong bài toán [Support Vector Machine](/2017/04/09/smv/) cho dữ liệu linearly separable, modeling chính là bước quan sát thấy rằng đường thẳng phân chia hai classes phải là đường làm cho margin đạt giá trị lớn nhất. Việc đi tìm ra mô hình nào phù hợp cho bài toán chính là bước **Modeling**. **Learning là bước tiến hành tối ưu các tham số của mô hình.** Mỗi model được mô hình bởi một bộ các tham số (parameters). Với Linear Regression, tham số mô hình là bộ vector hệ số và bias \\((\\mathbf{w}, b)\\). Với K-means clustering, tham số mô hình có thể được coi là các clusters. Với Support Vector Machine, tham số mô hình có thể là vector hệ số và bias mô tả đường thằng \\((\\mathbf{w}, b)\\). Việc đi tìm các tham số cho mô hình thường được thực hiện bằng việc giải một bài toán tối ưu. Quá trình giải bài toán tối ưu, hay chính là quá trình đi tìm tham số của mô hình, chính là quá trình **Learning**. Sau bước Learning này, chúng ta thu được các *trained parameters*. **Inference là bước dự đoán ouput của mô hình dựa trên các trained parameters.** Với Linear Regression, Inference chính là việc tính \\(y = \\mathbf{w}^T\\mathbf{x} + b\\) dựa trên bộ các tham số đã được huấn luyện \\((\\mathbf{w}, b)\\). Với K-means clustering, việc Inference chính là việc đi tìm centroid gần nhất. Với Support Vector Machine, Inference chính là việc xác định class của một dữ liệu mới dựa vào công thức \\(y = \\text{sgn}(\\mathbf{w}^T\\mathbf{x} + b)\\). So với hai bước Modeling và Learning, Inference thường đơn giản hơn. Như đã đề cập, ở nửa sau của blog, tôi sẽ giới thiệu rất nhiều các mô hình thống kê. Trong các mô hình này, việc *Modeling* là việc đi tìm một mô hình thống kê (statistical model) phù hợp với từng loại dữ liệu và bài toán. Việc *Learning* là việc đi tìm các tham số cho mô hình thống kê đó. Việc *Inference* có thể coi là việc tính xác suất để xảy ra mỗi giá trị ở đầu ra khi biết các giá trị ở đầu vào và model được mô tả bởi các trained parameters. Các Mô Hình Thống Kê (Statistical Models) thường là sự kết hợp của các [phân phối xác suất đơn giản](/2017/07/09/prob/#-mot-vai-xac-suat-thuong-gap.). Với [Bernoulli distribution](/2017/07/09/prob/#-bernouli-distribution), tham số là biến \\(\\lambda\\). Với [Multivariate Normal Distribution](/2017/07/09/prob/#-multivariate-normal-distribution), tham số là mean vector \\(\\mu\\) và ma trận hiệp phương sai \\(\\Sigma\\). Với một mô hình thông kê bất kỳ, ký hiệu \\(\\theta\\) là tập hợp tất cả các tham số của mô hình đó. Learning chính là quá trình đánh giá (estimate) bộ tham số \\(\\theta\\) sao cho dữ liệu sẵn có và mô hình *khớp* với nhau nhất. Quá trình đó còn được gọi là *parameter estimation*. Có hai cách đánh giá tham số thường được dùng trong Statistical Machine Learning. Cách thứ nhất chỉ dựa trên dữ liệu đã biết trong tập traing (training data), được gọi là *Maximum Likelihood Estimation* hay *ML Estimation* hoặc *MLE*. Cách thứ hai không những dựa trên training data mà còn dựa trên những thông tin đã biết của các tham số. Những thông tin này có thể có được bằng *cảm quan* của người xây dựng mô hình. *Cảm quan* càng rõ ràng, càng hợp lý thì khả năng thu được bộ tham số tốt là càng cao. Chẳng hạn, thông tin biết trước của \\(\\lambda\\) trong Bernoulli distribution là việc nó là một số trong đoạn \\([0, 1]\\). Với bài toán tung đồng xu, với \\(\\lambda\\) là xác suất có được mặt *head*, ta dự đoán được rằng giá trị này nên là một số gần với \\(0.5\\). Cách đánh giá tham số thứ hai này được gọi là *Maximum A Posteriori Estimation* hay *MAP Estimation*. Trong bài viết này, tôi sẽ trình bày về ý tưởng và cách giải quyết bài toán đánh giá tham số mô hình theo *MLE* hoặc *MAP Estimation*. Và như thường lệ, chúng ta sẽ cùng thực hiện mộ vài ví dụ đơn giản.",
        "url": "https://machinelearningcoban.com/2017/07/17/mlemap/"
    },
    {
        "id": "14.main-3",
        "source": "14.main.md",
        "section": "2.1. Ý tưởng",
        "content": "Giả sử có các điểm dữ liệu \\(\\mathbf{x}\\_1, \\mathbf{x}\\_2, \\dots, \\mathbf{x}\\_N\\). Giả sử thêm rằng ta đã biết các điểm dữ liệu này tuân theo một phân phối nào đó được mô tả bởi bộ tham số \\(\\theta\\). Maximum Likelihood Estimation là việc đi tìm bộ tham số \\(\\theta\\) sao cho xác suất sau đây đạt giá trị lớn nhất: \\[ \\theta = \\max\\_{\\theta} p(\\mathbf{x}\\_1, \\dots, \\mathbf{x}\\_N | \\theta) ~~~~ (1) \\] Biểu thức \\((1)\\) có ý nghĩa như thế nào và vì sao việc này có lý? Giả sử rằng ta đã biết mô hình rồi, và mô hình này được mô tả bởi bộ tham số \\(\\theta\\). Thế thì, \\(p(\\mathbf{x}\\_1 | \\theta)\\) chính là xác suất xảy ra *sự kiện* \\(\\mathbf{x}\\_1\\) biết rằng mô hình là (được mô tả bởi) \\(\\theta\\) (đây là một [conditional probability](/2017/07/09/prob/#-conditional-probability)). Và \\(p(\\mathbf{x}\\_1, \\dots, \\mathbf{x}\\_N | \\theta)\\) chính là xác suất để toàn bộ các *sự kiện* \\(\\mathbf{x}\\_1, \\mathbf{x}\\_2, \\dots, \\mathbf{x}\\_N\\) xảy ra đồng thời (nó là một [joint probability](/2017/07/09/prob/#-joint-probability)), xác suất đồng thời này còn được gọi là *likelihood*. Ở đây, *likelihood* chính là hàm mục tiêu. Bởi vì *sự đã rồi*, tức dữ liệu training bản thân nó đã là như thế rồi, xác suất đồng thời này cần phải càng cao càng tốt. Việc này cũng giống như việc đã biết *kết quả*, và ta cần đi tìm *nguyên nhân* sao cho xác suất xảy ra kết quả này càng cao càng tốt. Maximum Likelihood chính là việc đi tìm bộ tham số \\(\\theta\\) sao cho Likelihood là lớn nhất.",
        "url": "https://machinelearningcoban.com/2017/07/17/mlemap/"
    },
    {
        "id": "14.main-4",
        "source": "14.main.md",
        "section": "2.2. Independence Assumption và log-likelihood",
        "content": "Việc giải trực tiếp bài toán \\((1)\\) thường là phức tạp vì việc đi tìm mô hình xác suất đồng thời cho toàn bộ dữ liệu là ít khi khả thi. Một cách tiếp cận phổ biến là giả sử đơn giản rằng các điểm dữ liệu \\(\\mathbf{x}\\_n\\) là [độc lập](/2017/07/09/prob/#-independence) với nhau, nếu biết tham số mô hình \\(\\theta\\) (độc lập có điều kiện). Nói cách khác, ta xấp xỉ likelihood trong \\((1)\\) bởi: \\[ p(\\mathbf{x}\\_1, \\dots, \\mathbf{x}\\_N | \\theta) \\approx \\prod\\_{n = 1}^N p(\\mathbf{x}\\_n |\\theta) ~~~~ (2) \\] (Nhắc lại rằng hai sự kiện \\(x, y\\) là độc lập nếu xác suất đồng thời của chúng bằng tích xác suất của từng sự kiện: \\(p(x, y) = p(x)p(y)\\). Và khi là xác suất có điều kiện: \\(p(x, y | z) = p(x|z)p(y|z)\\)) Lúc đó, bài toán \\((1)\\) có thể được giải quyết bằng cách giải bài toán tối ưu sau: \\[ \\theta = \\max\\_{\\theta} \\prod\\_{n=1}^N p(\\mathbf{x}\\_n| \\theta) ~~~~ (3) \\] Việc tối ưu hoá một tích thường phức tạp hơn việc tối ưu một tổng, vì vậy việc tối đa hàm mục tiêu thường được chuyển về việc tối đa \\(\\log\\) của hàm mục tiêu. Ôn lại một chút: * \\(\\log\\) của một tích bằng tổng của các \\(\\log\\). * vì rằng \\(\\log\\) là một hàm đồng biến, một biểu thức sẽ là lớn nhất nếu \\(\\log\\) của nó là lớn nhất, và ngược lại. Bài toán Maximum Likelihood được đưa về bài toán Maximum Log-likelihood: \\[ \\theta = \\max\\_{\\theta} \\sum\\_{n = 1}^N \\log\\left(p(\\mathbf{x}\\_n | \\theta)\\right) ~~~~ (4) \\] Bạn vẫn chưa hiểu? Không lo, bây giờ chúng ta sẽ làm một vài ví dụ.",
        "url": "https://machinelearningcoban.com/2017/07/17/mlemap/"
    },
    {
        "id": "14.main-5",
        "source": "14.main.md",
        "section": "2.3.1. Ví dụ 1: Bernoulli distribution",
        "content": "--- **Bài toán**: giả sử tung một đồng xu \\(N\\) lần và nhận được \\(n\\) mặt *head*. Tính xác suất có một mặt *head* khi tung đồng xu đó ở lần tiếp theo. ---",
        "url": "https://machinelearningcoban.com/2017/07/17/mlemap/"
    },
    {
        "id": "6.main-1",
        "source": "6.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. ID3](#-id) + [2.1. Ý tưởng](#-y-tuong) + [2.2. Hàm số entropy](#-ham-so-entropy) + [2.3. Thuật toán ID3](#-thuat-toan-id) + [2.4. Ví dụ](#-vi-du) + [2.5. Điều kiện dừng](#-dieu-kien-dung) + [2.6. Pruning](#-pruning) * [3. Lập trình Python cho ID3](#-lap-trinh-python-cho-id) * [4. Thảo luận](#-thao-luan) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2018/01/14/id3/"
    },
    {
        "id": "6.main-2",
        "source": "6.main.md",
        "section": "1. Giới thiệu",
        "content": "Sắp đến kỳ thi, một cậu sinh viên tự đặt ra quy tắc *học* hay *chơi* của mình như sau. Nếu còn nhiều hơn hai ngày tới ngày thi, cậu ra sẽ đi chơi. Nếu còn không quá hai ngày và đêm hôm đó có một trận bóng đá, cậu sẽ sang nhà bạn chơi và cùng xem bóng đêm đó. Cậu sẽ chỉ học trong các trường hợp còn lại. Việc ra quyết định của cậu sinh viên này có thể được mô tả trên sơ đồ trong Hình 1. Hình ellipse nền vàng thể hiện quyết định cần được đưa ra. Quyết định này phụ thuộc vào các câu trả lời của các câu hỏi trong các ô hình chữ nhật màu xám. Dựa trên các câu trả lời, quyết định cuối cùng được cho trong các hình tròn màu lục (*chơi*) và đỏ (*học*). Sơ đồ trong Hình 1 còn được gọi là một *cây quyết định*. --- |  |  | | --- | --- | |  | Hình 1: Ví dụ về việc ra quyết định dựa trên các câu hỏi. | ---",
        "url": "https://machinelearningcoban.com/2018/01/14/id3/"
    },
    {
        "id": "15.main-1",
        "source": "15.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Xác Suất](#-xac-suat) + [2.1. Random variables](#-random-variables) + [2.2. Joint probability](#-joint-probability) + [2.3. Marginalization](#-marginalization) + [2.4. Conditional probability](#-conditional-probability) + [2.5. Quy tắc Bayes](#-quy-tac-bayes) + [2.6. Independence](#-independence) + [2.7. Kỳ vọng](#-ky-vong) * [3. Một vài phân phối thường gặp](#-mot-vai-xac-suat-thuong-gap) + [3.1. Bernoulli distribution](#-bernouli-distribution) + [3.2. Categorical distribution](#-categorical-distribution) + [3.3. Univariate normal distribution (Phân phối chuẩn một biến)](#-univariate-normal-distribution-phan-phoi-chuan-mot-bien) + [3.4. Multivariate normal distribution](#-multivariate-normal-distribution) + [3.5. Beta distribution](#-beta-distribution) + [3.6. Dirichlet distribution](#-dirichlet-distribution) * [4. Thảo luận](#-thao-luan) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/07/09/prob/"
    },
    {
        "id": "15.main-2",
        "source": "15.main.md",
        "section": "1. Giới thiệu",
        "content": "Cho tới thời điểm này, kế hoạch viết về phần Machine Learning cơ bản của tôi đã thực hiện được 1 nửa. Trong nửa đầu của blog, các bạn đã làm quen (lại) rất nhiều với Đại số tuyến tính và Tối ưu. Nhìn chung, tôi đều viết các thuật toán Machine Learning dưới dạng các bài toán tối ưu và cách giải mỗi bài toán đó. Các bài viết trong nửa đầu có thể chia thành các Phần: 1. Bài 1-6: Làm quen với Machine Learning. Một vài thuật toán Machine Learning cơ bản chưa cần nhiều tới tối ưu. 2. Bài 7-8: Gradient Descent. Thuật toán tối ưu đơn giản mà hiệu quả cho các bài toán tối ưu không ràng buộc. 3. Bài 9-15: Neural Networks. Phần này giúp các bạn nắm được các thành phần cơ bản của một Neural Network và các Networks cơ bản nhất, chủ yếu cho các bài toán classification. Các bài toán tối ưu đều là không ràng buộc, các hàm mất mát hầu hết là không lồi, nghiệm tìm được là các local optimal. 4. Bài 16-18: Convex Optimization. Phần này bắt đầu sâu hơn một chút về Tối ưu. Định nghĩa về tập lồi, hàm lồi, bài toán tối ưu lồi và bài toán đối ngẫu. Đây là nền tảng cho rất nhiều thuật toán cơ bản Machine Learning sau này. 5. Bài 19-22: Support Vector Machine. Đây là một trong những thuật toán đẹp nhất và ‘intuitive’ nhất trong Machine Learning. Nếu bạn vào wiki tìm ‘Machine Learning’ thì sẽ thấy hình đại diện chính là SVM và Kernel SVM. Một trong những điều lý thú của SVM là bài toán tối ưu là lồi và nghiệm tìm được là duy nhất, cũng là global optimal. 6. Bài 23-25: Recommendation Systems. Đây là một lớp các bài toán thực tế và quan trọng của Machine Learning. Tôi chủ động thêm phần này vào vì làm giảm lượng toán đã đề cập quá nhiều trong Phần 4 và 5. Các thuật toán và bài toán trong phần này khá đơn giản nhưng kết quả khá tốt. 7. Bài 26-29: Dimensionality Reduction. Phần này cũng rất quan trọng trong Machine Learning. PCA gần như được dùng trong hầu hết các bài toán ML, trong khi LDA hiệu quả trong các bài toán classification. SVD, sau này các bạn sẽ thấy, được dùng rất nhiều vì những tính chất đẹp của nó. Trong nửa còn lại, tôi sẽ đi vào một mảng lớn khác của ML trong đó các kiến thức về xác suất thống kê được áp dụng rất nhiều, tôi tạm gọi phần này là Bayesian Machine Learning. Các bạn sẽ từ từ được ôn lại kiến thức về Xác Suất Thống Kê và làm quen với các thuật toán Machine Learning cơ bản khác. Trong bài viết này, tôi sẽ ôn tập lại những kiến thức về Xác Suất thường được sử dụng trong Machine Learning. Mục 2 sẽ nhắc lại về biến ngẫu nhiên, xác suất đồng thời, xác suất biên, xác suất có điều kiện, và quy tắc Bayes. Mục 3 sẽ nhác lại một vài phân bố xác suất thường dùng. *Phần này được viết dựa trên Chương 2 và 3 của cuốn [Computer Vision: Models, Learning, and Inference - Simon J.D. Prince](http://www.computervisionmodels.com).*",
        "url": "https://machinelearningcoban.com/2017/07/09/prob/"
    },
    {
        "id": "15.main-3",
        "source": "15.main.md",
        "section": "2.1. Random variables",
        "content": "Một *biến ngẫu nhiên* (random variable) \\(x\\) là một đại lượng dùng để đo những đại lượng không xác định. Biến này có thể ký hiệu kết quả/đầu ra (outcome) của một thí nghiệm (ví dụ như tung đồng xu) hoặc một đại lượng biến đổi trong tự nhiên (ví dụ như nhiệt độ trong ngày). Nếu chúng ta quan sát rất nhiều đầu ra \\( \\{x\\_i\\}\\_{i=1}^I\\) của các thí nghiệm này, ta có thể nhận được những giá trị khác nhau ở mỗi thí nghiệm. Tuy nhiên, sẽ có những giá trị xảy ra nhiều lần hơn những giá trị khác. Thông tin về đầu ra được đo bởi *phân phối xác suất* (probability distribution) \\(p(x)\\) của biến ngẫu nhiên. Một biến ngẫu nhiên có thể là *rời rạc* (discrete) hoặc *liên tục* (continuous). Một biến ngẫu nhiên rời rạc sẽ lấy giá trị trong một tập hợp cho trước. Ví dụ tung đồng xu thì có hai khả năng là *head* và *tail* (tên gọi này bắt nguồn từ đồng xu Mỹ, một mặt có hình mặt người, được gọi là *head*, trái ngược với mặt này được gọi là mặt *tail*, cách gọi này hay hơn cách gọi *xấp ngửa* vì ta không có quy định rõ ràng thế nào là xấp ngay ngửa).Tập các giá trị này có thể là *có thứ tự* (khi tung xúc xắc) hoặc *không có thứ tự* (unorderd), ví dụ khi đầu ra là các giá trị *nắng*, *mưa*, *bão*, etc. Mỗi đầu ra có một giá trị xác suất tương ứng với nó. Các giá trị xác suất này không âm và có tổng bằng một: \\[ \\text{if}~ x ~\\text{is discrete:}\\quad \\sum\\_{x} p(x) = 1 ~~~~ (1) \\] Biến ngẫu nhiên liên tục lấy các giá trị là tập con của các số thực. Những giá trị này có thể là hữu hạn, ví dụ thời gian làm bài của mỗi thí sinh trong một bài thi 180 phút, hoặc vô hạn, ví dụ thời gian để chiếc xe bus tiếp theo tới. Không như biến ngẫu nhiên rời rạc, xác suất để đầu ra bằng *chính xác* một giá trị nào đó, theo lý thuyết, là bằng 0. Thay vào đó, ta có thể hình dung xác suất để đầu ra nằm trong một khoảng giá trị nào đó; và việc này được mô tả bởi *hàm mật đô xác suất* (probability density function - pdf). Hàm mật độ xác suất luôn cho giá trị dương, và tích phân của nó trên toàn miền *possible outcome* phải bằng 1. \\[ \\text{if}~ x ~\\text{is continuous:}\\quad \\int p(x)dx = 1 ~~~~ (2) \\] Để giảm thiểu ký hiệu, hàm mật độ xác suất của một biến ngẫu nhiên liên tục \\(x\\) cũng được ký hiệu là \\(p(x)\\). **Chú ý: Nếu \\(x\\) là biến ngẫu nhiên rời rạc, \\(p(x)\\) luôn luôn nhỏ hơn hoặc bằng 1. Trong khi đó, nếu \\(x\\) là biến ngẫu nhiên liên tục, \\(p(x)\\) có thể nhận giá trị dương bất kỳ, điều này vẫn đảm bảo là tích phân của hàm mật độ xác suất theo toàn bộ giá trị có thể có của \\(x\\) bằng 1. Với biến ngẫu nhiên rời rạc, \\(p(x)\\) được hiểu là *mật độ xác suất* tại \\(x\\).**",
        "url": "https://machinelearningcoban.com/2017/07/09/prob/"
    },
    {
        "id": "15.main-4",
        "source": "15.main.md",
        "section": "2.2. Joint probability",
        "content": "Xét hai biến ngẫu nhiên \\(x\\) và \\(y\\). Nếu ta quan sát rất nhiều cặp đầu ra của \\(x\\) và \\(y\\), thì có những tổ hợp hai đầu ra xảy ra thường xuyên hơn những tổ hợp khác. Thông tin này được biểu diễn bằng một phân phối được gọi là *joint probability* của \\(x\\) và \\(y\\), và được viết là \\(p(x, y)\\). Dấu phẩy trong \\(p(x, y)\\) có thể đọc là *và*, vậy \\(p(x, y)\\) là xác suất của \\(x\\) *và* \\(y\\). \\(x\\) và \\(y\\) có thể là hai biến ngẫu nhiên rời rạc, liên tục, hoặc một rời rạc, một liên tục. Luôn nhớ rằng tổng các xác suất trên mọi cặp giá trị có thể xảy ra \\((x, y)\\) bằng 1. \\[ \\begin{eqnarray} \\text{both are discrete} \\quad \\quad & \\sum\\_{x, y} p(x, y) &=& 1 \\newline \\text{both are continuous} & \\int p(x, y) dx dy &=& 1\\newline x ~\\text{is discrete}, ~ y ~\\text{is continuous} & \\sum\\_{x} \\int p(x, y) dy = \\int \\left(\\sum\\_{x} p(x, y) \\right)dy &=& 1 \\end{eqnarray} \\] Xét ví dụ trong Hình 1, phần có nền màu lục nhạt. \\(x\\) là biến ngẫu nhiên chỉ điểm thi môn Toán của học sinh trong một trường trong kỳ thi Quốc gia, \\(y\\) là biến ngẫu nhiên chỉ điểm thi môn Vật Lý cũng trong kỳ thi đó. \\(p(x = x^\\*, y = y^\\*)\\) là tỉ lệ giữa tần suất số học sinh được \\(x^\\*\\) điểm trong môn Toán và \\(y^\\*\\) điểm trong môn Vật Lý và toàn bộ số học sinh. Tỉ lệ này có thể coi là xác suất khi số học sinh trong trường là lớn. Ở đây \\(x^\\*\\) và \\(y^\\*\\) là các số xác định. Thông thường, xác suất này được viết gọn lại thành \\(p(x^\\*, y^\\*)\\), và \\(p(x, y)\\) được dùng như một hàm tổng quát để mô tả các xác suất. Giả sử thêm rằng điểm các môn là các số tự nhiên từ 1 đến 10. Các ô vuông màu lam thể hiện xác suất \\(p(x, y)\\) với diện tích ô vuông càng to thể hiện xác suất đó càng lớn. Chú ý rằng tổng các xác suất này bằng 1. *Các bạn có thể thấy rằng xác suất để một học sinh được 10 điểm một Toán và 1 điểm môn Lý rất thấp, điều tương tự xảy ra với 10 điểm môn Lý và 1 điểm môn Toán. Ngược lại, xác suất để một học sinh được khoảng 7 điểm cả hai môn là cao nhất.* --- ![](/assets/30_prob/joint.png) Hình 1: Joint probability (phần trung tâm có nền mùa lục nhạt), Marginalization (phía trên và bên trái) và Conditional probability (phía dưới và bên phải). ---",
        "url": "https://machinelearningcoban.com/2017/07/09/prob/"
    },
    {
        "id": "33.main-1",
        "source": "33.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) + [1.1. PLA cho các hàm logic cơ bản](#-pla-cho-cac-ham-logic-co-ban) + [1.2. Biểu diễn hàm XOR với Neural Network.](#-bieu-dien-ham-xor-voi-neural-network) * [2. Các ký hiệu và khái niệm](#-cac-ky-hieu-va-khai-niem) + [2.1. Layers](#-layers) + [2.2. Units](#-units) + [2.3. Weights và Biases](#-weights-va-biases) + [2.4. Activation functions](#-activation-functions) - [2.4.1. Hàm *sgn* không được sử dụng trong MLP](#-ham-sgn-khong-duoc-su-dung-trong-mlp) - [2.4.1 Sigmoid và tanh](#-sigmoid-va-tanh) - [2.4.3. ReLU](#-relu) - [2.4.4. Một vài lưu ý](#-mot-vai-luu-y) * [3. Backpropagation](#-backpropagation) + [3.1. Backpropagation cho Stochastic Gradient Descent](#-backpropagation-cho-stochastic-gradient-descent) - [3.1.1. Đạo hàm theo từng hệ số \\(w\\_{ij}^{(l)}, b\\_{i}^{(l)}\\)](#-dao-ham-theo-tung-he-so-\\\\wij^l-bi^l\\\\) - [3.1.2. Đạo hàm theo ma trận \\(\\mathbf{W}^{(l)}, \\mathbf{b}^{(l)}\\)](#-dao-ham-theo-ma-tran-\\\\\\mathbfw^l-\\mathbfb^l\\\\) + [3.2. Backpropagation cho Batch (mini-batch) Gradient Descent](#-backpropagation-cho-batch-mini-batch-gradient-descent) * [4. Ví dụ trên Python](#-vi-du-tren-python) + [4.1. Tạo dữ liệu giả](#-tao-du-lieu-gia) + [4.2. Tính toán Feedforward](#-tinh-toan-feedforward) + [4.3. Tính toán Backpropagation](#-tinh-toan-backpropagation) + [4.4. Một số hàm phụ trợ](#-mot-so-ham-phu-tro) + [4.4. Phần chương trình chính](#-phan-chuong-trinh-chinh) + [4.5. Kết quả](#-ket-qua) * [5. Thảo luận](#-thao-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao) Vì bài này sử dụng khá nhiều công thức toán, bạn đọc được khuyến khích đọc [Lưu ý về ký hiệu toán học](/math/#luu-y-ve-ky-hieu).",
        "url": "https://machinelearningcoban.com/2017/02/24/mlp/"
    },
    {
        "id": "33.main-2",
        "source": "33.main.md",
        "section": "1. Giới thiệu",
        "content": "Bài toán [Supervised Learning](/2016/12/27/categories/#supervised-learning-hoc-co-giam-sat), nói một cách ngắn gọn, là việc đi tìm một hàm số để với mỗi *input*, ta sử dụng hàm số đó để dự đoán *output*. Hàm số này được xây dựng dựa trên các cặp dữ liệu \\((\\mathbf{x} \\_i, \\mathbf{y}\\_i)\\) trong *training set*. Nếu *đầu ra dự đoán* (predicted output) gần với *đầu ra thực sự* ([ground truth](/2017/01/08/knn/#ground-truth)) thì đó được gọi là một thuật toán tốt (nhưng khi *đầu ra dự đoán quá giống với đầu ra thực sự* thì không hẳn đã tốt, tôi sẽ đề cập kỹ về hiện tượng trong bài tiếp theo).",
        "url": "https://machinelearningcoban.com/2017/02/24/mlp/"
    },
    {
        "id": "33.main-3",
        "source": "33.main.md",
        "section": "1.1. PLA cho các hàm logic cơ bản",
        "content": "Chúng ta cùng xét khả năng biểu diễn (representation) của [Perceptron Learning Algorithm (PLA)](/2017/01/21/perceptron/) cho các bài toán binary vô cùng đơn giản: biểu diễn các hàm số logic NOT, AND, OR, và [XOR](https://en.wikipedia.org/wiki/Exclusive_or) (output bằng 1 nếu và chỉ nếu hai input khác nhau). Để có thể sử dụng PLA (output là 1 hoặc -1), chúng ta sẽ thay các giá trị bằng 0 của output của các hàm này bởi -1. Trong hàng trên của Hình 1 dưới đây, các điểm hình vuông màu xanh là các điểm có label bằng 1, các điểm hình tròn màu đỏ là các điểm có label bằng -1. Hàng dưới của Hình 1 là các mô hình perceptron với các hệ số tương ứng. --- ![](/assets/14_mlp/logic_nn.png) Hình 1: PLA biểu diễn các hàm logic đơn giản. ---",
        "url": "https://machinelearningcoban.com/2017/02/24/mlp/"
    },
    {
        "id": "23.main-1",
        "source": "23.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. User-user Collaborative Filtering](#-user-user-collaborative-filtering) + [2.1. Similarity functions](#-similarity-functions) + [2.2. Rating prediction](#-rating-prediction) * [3. Item-item Collaborative Filtering](#-item-item-collaborative-filtering) * [4. Lập trình Collaborative Filtering trên Python](#-lap-trinh-collaborative-filtering-tren-python) + [4.1. `class CF`](#-class-cf) + [4.2. Áp dụng vào ví dụ](#-ap-dung-vao-vi-du) + [4.3. Áp dụng lên MovieLens 100k](#-ap-dung-len-movielens-k) * [5. Thảo luận](#-thao-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/05/24/collaborativefiltering/"
    },
    {
        "id": "23.main-2",
        "source": "23.main.md",
        "section": "1. Giới thiệu",
        "content": "Trong [Content-based Recommendation Systems](/2017/05/17/contentbasedrecommendersys/), chúng ta đã làm quen với một Hệ thống gợi ý sản phẩm đơn giản dựa trên đặc trưng của mỗi *item*. Đặc điểm của Content-based Recommendation Systems là việc xây dựng mô hình cho mỗi *user* không phụ thuộc vào các *users* khác mà phụ thuộc vào *profile* của mỗi *items*. Việc làm này có lợi thế là tiết kiệm bộ nhớ và thời gian tính toán. Đồng thời, hệ thống có khả năng *tận dụng* các thông tin đặc trưng của mỗi *item* như được mô tả trong *bản mô tả* (description) của mỗi *item*. *Bản mô tả* này có thể được xây dựng bởi nhà cung cấp hoặc được thu thập bằng cách yêu cầu *users* gắn *tags* cho *items*. Việc xây dựng *feature vector* cho mỗi *item* thường bao gồm các kỹ thuật Xử lý ngôn ngữ tự nhiên (Natural Language Processing - NLP). Cách làm trên có hai nhược điểm cơ bản. *Thứ nhất*, khi xây dựng mô hình cho một user, các hệ thống Content-based không tận dụng được thông tin từ các *users* khác. Những thông tin này thường rất hữu ích vì hành vi mua hàng của các *users* thường được nhóm thành một vài nhóm đơn giản; nếu biết hành vi mua hàng của một vài *users* trong nhóm, hệ thống nên *suy luận* ra hành vi của những *users* còn lại. *Thứ hai*, không phải lúc nào chúng ta cũng có *bản mô tả* cho mỗi *item*. Việc yêu cầu *users* gắn *tags* còn khó khăn hơn vì không phải ai cũng sẵn sàng làm việc đó; hoặc có làm nhưng sẽ mang xu hướng cá nhân. Các thuật toán NLP cũng phức tạp hơn ở việc phải xử lý các từ gần nghĩa, viết tắt, sai chính tả, hoặc được viết ở các ngôn ngữ khác nhau. Những nhược điểm phía trên có thể được giải quyết bằng *Collaborative Filtering* (CF). Trong bài viết này, tôi sẽ trình bày tới các bạn một phương pháp CF có tên là *Neighborhood-based Collaborative Filtering (NBCF)*. Bài tiếp theo sẽ trình bày về một phương pháp CF khác có tên *Matrix Factorization Collaborative Filtering*. Khi chỉ nói Collaborative Filtering, chúng ta sẽ ngầm hiểu rằng phương pháp được sử dụng là *Neighborhood-based*. Ý tưởng cơ bản của NBCF là xác định *mức độ quan tâm* của một *user* tới một *item* dựa trên các *users* khác *gần giống* với *user* này. Việc *gần giống nhau* giữa các *users* có thể được xác định thông qua *mức độ quan tâm* của các *users* này tới các *items* khác mà hệ thống đã biết. Ví dụ, *A, B* đều thích phim *Cảnh sát hình sự*, tức đều *rate* bộ phim này 5 sao. Ta đã biết *A* cũng thích *Người phán xử*, vậy nhiều khả năng *B* cũng thích bộ phim này. Các bạn có thể đã hình dung ra, hai câu hỏi quan trọng nhất trong một hệ thống Neighborhood-based Collaborative Filtering là: * Làm thế nào xác định được *sự giống nhau* giữa hai *users*? * Khi đã xác định được các *users* *gần giống nhau* (*similar users*) rồi, làm thế nào dự đoán được *mức độ quan tâm* của một *user* lên một *item*? Việc xác định mức độ quan tâm của mỗi *user* tới một *item* dựa trên mức độ quan tâm của *similar users* tới *item* đó còn được gọi là *User-user collaborative filtering*. Có một hướng tiếp cận khác được cho là làm việc hiệu quả hơn là *Item-item collaborative filtering*. Trong hướng tiếp cận này, thay vì xác định *user similarities*, hệ thống sẽ xác định *item similarities*. Từ đó, hệ thống gợi ý những *items* *gần giống với* những *items* mà user có mức độ quan tâm cao. Cấu trúc của bài viết như sau: Mục 2 sẽ trình bày *User-user Collaborative Filtering*. Mục 3 sẽ nêu một số hạn chế của *User-user Collaborative Filtering* và cách khắc phục bằng *Item-item Collaborative Filtering*. Kết quả của hai phương pháp này sẽ được trình bày qua ví dụ trên cơ sở dữ liệu [MovieLens 100k](/2017/05/17/contentbasedrecommendersys/#-co-so-du-lieu-movielens-k) trong Mục 4. Một vài thảo luận và Tài liệu tham khảo được cho trong Mục 5 và 6.",
        "url": "https://machinelearningcoban.com/2017/05/24/collaborativefiltering/"
    },
    {
        "id": "23.main-3",
        "source": "23.main.md",
        "section": "2.1. Similarity functions",
        "content": "Công việc quan trọng nhất phải làm trước tiên trong User-user Collaborative Filtering là phải xác định được *sự giống nhau* (*similarity*) giữa hai *users*. Dữ liệu duy nhất chúng ta có là *Utility matrix* \\(\\mathbf{Y}\\), vậy nên *sự giống nhau* này phải được xác định dựa trên các cột tương ứng với hai *users* trong ma trận này. Xét ví dụ trong Hình 1. --- |  |  | | --- | --- | |  | Hình 1: Ví dụ về utility matrix dựa trên số sao một *user rate* cho một *item*. Một cách trực quan, *hành vi* của \\(u\\_0\\) giống với \\(u\\_1\\) hơn là \\(u\\_2, u\\_3, u\\_4, u\\_5, u\\_6\\). Từ đó có thể dự đoán rằng \\(u\\_0\\) sẽ quan tâm tới \\(i\\_2\\) vì \\(u\\_1\\) cũng quan tâm tới *item* này. | ---",
        "url": "https://machinelearningcoban.com/2017/05/24/collaborativefiltering/"
    },
    {
        "id": "41.main-1",
        "source": "41.main.md",
        "section": "Introduction",
        "content": "Nếu như con người có kiểu học “nước đến chân mới nhảy”, thì trong Machine Learning cũng có một thuật toán như vậy. **Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) + [Một câu chuyện vui](#mot-cau-chuyen-vui) + [K-nearest neighbor](#k-nearest-neighbor) + [Khoảng cách trong không gian vector](#khoang-cach-trong-khong-gian-vector) * [2. Phân tích toán học](#-phan-tich-toan-hoc) * [3. Ví dụ trên Python](#-vi-du-tren-python) + [Bộ cơ sở dữ liệu Iris (Iris flower dataset).](#bo-co-so-du-lieu-iris-iris-flower-dataset) + [Thí nghiệm](#thi-nghiem) - [Tách training và test sets](#tach-training-va-test-sets) - [Phương pháp đánh giá (evaluation method)](#phuong-phap-danh-gia-evaluation-method) - [Đánh trọng số cho các điểm lân cận](#danh-trong-so-cho-cac-diem-lan-can) * [4. Thảo luận](#-thao-luan) + [KNN cho Regression](#knn-cho-regression) + [Chuẩn hóa dữ liệu](#chuan-hoa-du-lieu) + [Sử dụng các phép đo khoảng cách khác nhau](#su-dung-cac-phep-do-khoang-cach-khac-nhau) + [Ưu điểm của KNN](#uu-diem-cua-knn) + [Nhược điểm của KNN](#nhuoc-diem-cua-knn) + [Tăng tốc cho KNN](#tang-toc-cho-knn) + [Try this yourself](#try-this-yourself) + [Source code](#source-code) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-2",
        "source": "41.main.md",
        "section": "Một câu chuyện vui",
        "content": "Có một anh bạn chuẩn bị đến ngày thi cuối kỳ. Vì môn này được mở tài liệu khi thi nên anh ta không chịu ôn tập để hiểu ý nghĩa của từng bài học và mối liên hệ giữa các bài. Thay vào đó, anh thu thập tất cả các tài liệu trên lớp, bao gồm ghi chép bài giảng (lecture notes), các slides và bài tập về nhà + lời giải. Để cho chắc, anh ta ra thư viện và các quán Photocopy quanh trường mua hết tất cả các loại tài liệu liên quan (*khá khen cho cậu này chịu khó tìm kiếm tài liệu*). Cuối cùng, anh bạn của chúng ta thu thập được một chồng cao tài liệu để mang vào phòng thi. Vào ngày thi, anh tự tin mang chồng tài liệu vào phòng thi. Aha, đề này ít nhất mình phải được 8 điểm. Câu 1 giống hệt bài giảng trên lớp. Câu 2 giống hệt đề thi năm ngoái mà lời giải có trong tập tài liệu mua ở quán Photocopy. Câu 3 gần giống với bài tập về nhà. Câu 4 trắc nghiệm thậm chí cậu nhớ chính xác ba tài liệu có ghi đáp án. Câu cuối cùng, 1 câu khó nhưng anh đã từng nhìn thấy, chỉ là không nhớ ở đâu thôi. Kết quả cuối cùng, cậu ta được 4 điểm, vừa đủ điểm qua môn. Cậu làm chính xác câu 1 vì tìm được ngay trong tập ghi chú bài giảng. Câu 2 cũng tìm được đáp án nhưng lời giải của quán Photocopy sai! Câu ba thấy gần giống bài về nhà, chỉ khác mỗi một số thôi, cậu cho kết quả giống như thế luôn, vậy mà không được điểm nào. Câu 4 thì tìm được cả 3 tài liệu nhưng có hai trong đó cho đáp án A, cái còn lại cho B. Cậu chọn A và được điểm. Câu 5 thì không làm được dù còn tới 20 phút, vì tìm mãi chẳng thấy đáp án đâu - nhiều tài liệu quá cũng mệt!! Không phải ngẫu nhiên mà tôi dành ra ba đoạn văn để kể về chuyện học hành của anh chàng kia. Hôm nay tôi xin trình bày về một phương pháp trong Machine Learning, được gọi là K-nearest neighbor (hay KNN), một thuật toán được xếp vào loại lazy (machine) learning (máy lười học). Thuật toán này khá giống với cách học/thi của anh bạn kém may mắn kia.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-3",
        "source": "41.main.md",
        "section": "K-nearest neighbor",
        "content": "K-nearest neighbor là một trong những thuật toán supervised-learning đơn giản nhất (mà hiệu quả trong một vài trường hợp) trong Machine Learning. Khi training, thuật toán này *không học* một điều gì từ dữ liệu training (đây cũng là lý do thuật toán này được xếp vào loại [lazy learning](https://en.wikipedia.org/wiki/Lazy_learning)), mọi tính toán được thực hiện khi nó cần dự đoán kết quả của dữ liệu mới. K-nearest neighbor có thể áp dụng được vào cả hai loại của bài toán Supervised learning là [Classification](/2016/12/27/categories/#classification-phan-loai) và [Regression](/2016/12/27/categories/#regression-hoi-quy). KNN còn được gọi là một thuật toán [Instance-based hay Memory-based learning](https://en.wikipedia.org/wiki/Instance-based_learning). Có một vài khái niệm tương ứng người-máy như sau: | Ngôn ngữ người | Ngôn ngữ Máy Học | in Machine Learning | | --- | --- | --- | | Câu hỏi | Điểm dữ liệu | Data point | | Đáp án | Đầu ra, nhãn | Output, Label | | Ôn thi | Huấn luyện | Training | | Tập tài liệu mang vào phòng thi | Tập dữ liệu tập huấn | Training set | | Đề thi | Tập dữ liểu kiểm thử | Test set | | Câu hỏi trong dề thi | Dữ liệu kiểm thử | Test data point | | Câu hỏi có đáp án sai | Nhiễu | Noise, Outlier | | Câu hỏi gần giống | Điểm dữ liệu gần nhất | Nearest Neighbor | Với KNN, trong bài toán Classification, label của một điểm dữ liệu mới (hay kết quả của câu hỏi trong bài thi) được suy ra trực tiếp từ K điểm dữ liệu gần nhất trong training set. Label của một test data có thể được quyết định bằng major voting (bầu chọn theo số phiếu) giữa các điểm gần nhất, hoặc nó có thể được suy ra bằng cách đánh trọng số khác nhau cho mỗi trong các điểm gần nhất đó rồi suy ra label. Chi tiết sẽ được nêu trong phần tiếp theo. Trong bài toán Regresssion, đầu ra của một điểm dữ liệu sẽ bằng chính đầu ra của điểm dữ liệu đã biết gần nhất (trong trường hợp K=1), hoặc là trung bình có trọng số của đầu ra của những điểm gần nhất, hoặc bằng một mối quan hệ dựa trên khoảng cách tới các điểm gần nhất đó. Một cách ngắn gọn, KNN là thuật toán đi tìm đầu ra của một điểm dữ liệu mới bằng cách *chỉ* dựa trên thông tin của K điểm dữ liệu trong training set gần nó nhất (K-lân cận), *không quan tâm đến việc có một vài điểm dữ liệu trong những điểm gần nhất này là nhiễu*. Hình dưới đây là một ví dụ về KNN trong classification với K = 1. ![](https://upload.wikimedia.org/wikipedia/commons/5/52/Map1NN.png) Bản đồ của 1NN (Nguồn: [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)) Ví dụ trên đây là bài toán Classification với 3 classes: Đỏ, Lam, Lục. Mỗi điểm dữ liệu mới (test data point) sẽ được gán label theo màu của điểm mà nó thuộc về. Trong hình này, có một vài vùng nhỏ xem lẫn vào các vùng lớn hơn khác màu. Ví dụ có một điểm màu Lục ở gần góc 11 giờ nằm giữa hai vùng lớn với nhiều dữ liệu màu Đỏ và Lam. Điểm này rất có thể là nhiễu. Dẫn đến nếu dữ liệu test rơi vào vùng này sẽ có nhiều khả năng cho kết quả không chính xác.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-4",
        "source": "41.main.md",
        "section": "Khoảng cách trong không gian vector",
        "content": "Trong không gian một chiều, khoảng cách giữa hai điểm là trị tuyệt đối giữa hiệu giá trị của hai điểm đó. Trong không gian nhiều chiều, khoảng cách giữa hai điểm có thể được định nghĩa bằng nhiều hàm số khác nhau, trong đó độ dài đường thằng nổi hai điểm chỉ là một trường hợp đặc biệt trong đó. Nhiều thông tin bổ ích (cho Machine Learning) có thể được tìm thấy tại [Norms (chuẩn) của vector](/math/#-norms-chuan) trong tab [Math](/math/).",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-5",
        "source": "41.main.md",
        "section": "2. Phân tích toán học",
        "content": "Thuật toán KNN rất dễ hiểu nên sẽ phần “Phân tích toán học” này sẽ chỉ có 3 câu. Tôi trực tiếp đi vào các ví dụ. Có một điều đáng lưu ý là KNN phải *nhớ* tất cả các điểm dữ liệu training, việc này không được lợi về cả bộ nhớ và thời gian tính toán - giống như khi cậu bạn của chúng ta không tìm được câu trả lời cho câu hỏi cuối cùng.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-6",
        "source": "41.main.md",
        "section": "Bộ cơ sở dữ liệu Iris (Iris flower dataset).",
        "content": "[Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) là một bộ dữ liệu nhỏ (nhỏ hơn rất nhiều so với [MNIST](/2017/01/04/kmeans2/#bo-co-so-du-lieu-mnist). Bộ dữ liệu này bao gồm thông tin của ba loại hoa Iris (một loài hoa lan) khác nhau: Iris setosa, Iris virginica và Iris versicolor. Mỗi loại có 50 bông hoa được đo với dữ liệu là 4 thông tin: chiều dài, chiều rộng đài hoa (sepal), và chiều dài, chiều rộng cánh hoa (petal). Dưới đây là ví dụ về hình ảnh của ba loại hoa. (Chú ý, đây không phải là bộ cơ sở dữ liệu ảnh như MNIST, mỗi điểm dữ liệu trong tập này chỉ là một vector 4 chiều). ![](/assets/knn/iris.png) Ví dụ về Iris flower dataset (Nguồn: [Wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set)) Bộ dữ liệu nhỏ này thường được sử dụng trong nhiều thuật toán Machine Learning trong các lớp học. Tôi sẽ giải thích lý do không chọn MNIST vào phần sau.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-7",
        "source": "41.main.md",
        "section": "Thí nghiệm",
        "content": "Trong phần này, chúng ta sẽ tách 150 dữ liệu trong Iris flower dataset ra thành 2 phần, gọi là *training set* và *test set*. Thuật toán KNN sẽ dựa vào trông tin ở *training set* để dự đoán xem mỗi dữ liệu trong *test set* tương ứng với loại hoa nào. Dữ liệu được dự đoán này sẽ được đối chiếu với loại hoa thật của mỗi dữ liệu trong *test set* để đánh giá hiệu quả của KNN. **Trước tiên, chúng ta cần khai báo vài thư viện**. Iris flower dataset có sẵn trong thư viện [scikit-learn](http://scikit-learn.org/). ``` import numpy as np import matplotlib.pyplot as plt from sklearn import neighbors, datasets ``` **Tiếp theo, chúng ta load dữ liệu và hiện thị vài dữ liệu mẫu**. Các class được gán nhãn là 0, 1, và 2. ``` iris = datasets.load_iris() iris_X = iris.data iris_y = iris.target print 'Number of classes: %d' %len(np.unique(iris_y)) print 'Number of data points: %d' %len(iris_y) X0 = iris_X[iris_y == 0,:] print '\\nSamples from class 0:\\n', X0[:5,:] X1 = iris_X[iris_y == 1,:] print '\\nSamples from class 1:\\n', X1[:5,:] X2 = iris_X[iris_y == 2,:] print '\\nSamples from class 2:\\n', X2[:5,:] ``` ``` Number of classes: 3 Number of data points: 150 Samples from class 0: [[ 5.1  3.5  1.4  0.2] [ 4.9  3.   1.4  0.2] [ 4.7  3.2  1.3  0.2] [ 4.6  3.1  1.5  0.2] [ 5.   3.6  1.4  0.2]] Samples from class 1: [[ 7.   3.2  4.7  1.4] [ 6.4  3.2  4.5  1.5] [ 6.9  3.1  4.9  1.5] [ 5.5  2.3  4.   1.3] [ 6.5  2.8  4.6  1.5]] Samples from class 2: [[ 6.3  3.3  6.   2.5] [ 5.8  2.7  5.1  1.9] [ 7.1  3.   5.9  2.1] [ 6.3  2.9  5.6  1.8] [ 6.5  3.   5.8  2.2]] ``` Nếu nhìn vào vài dữ liệu mẫu, chúng ta thấy rằng hai cột cuối mang khá nhiều thông tin giúp chúng ta có thể phân biệt được chúng. Chúng ta dự đoán rằng kết quả classification cho cơ sở dữ liệu này sẽ tương đối cao.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-8",
        "source": "41.main.md",
        "section": "Tách training và test sets",
        "content": "Giả sử chúng ta muốn dùng 50 điểm dữ liệu cho test set, 100 điểm còn lại cho training set. Scikit-learn có một hàm số cho phép chúng ta ngẫu nhiên lựa chọn các điểm này, như sau: ``` from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split( iris_X, iris_y, test_size=50) print \"Training size: %d\" %len(y_train) print \"Test size    : %d\" %len(y_test) ``` ``` Training size: 100 Test size    : 50 ``` Sau đây, tôi trước hết xét trường hợp đơn giản K = 1, tức là với mỗi điểm test data, ta chỉ xét 1 điểm training data gần nhất và lấy label của điểm đó để dự đoán cho điểm test này. ``` clf = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) print \"Print results for 20 test data points:\" print \"Predicted labels: \", y_pred[20:40] print \"Ground truth    : \", y_test[20:40] ``` ``` Print results for first 20 test data points: Predicted labels:  [2 1 2 2 1 2 2 0 2 0 2 0 1 0 0 2 2 0 2 0] Ground truth    :  [2 1 2 2 1 2 2 0 2 0 1 0 1 0 0 2 1 0 2 0] ``` Kết quả cho thấy label dự đoán gần giống với label thật của test data, chỉ có 2 điểm trong số 20 điểm được hiển thị có kết quả sai lệch. Ở đây chúng ta làm quen với khái niệm mới: *ground truth*. Một cách đơn giản, *ground truth* chính là nhãn/label/đầu ra *thực sự* của các điểm trong test data. Khái niệm này được dùng nhiều trong Machine Learning, hy vọng lần tới các bạn gặp thì sẽ nhớ ngay nó là gì.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-9",
        "source": "41.main.md",
        "section": "Phương pháp đánh giá (evaluation method)",
        "content": "Để đánh giá độ chính xác của thuật toán KNN classifier này, chúng ta xem xem có bao nhiêu điểm trong test data được dự đoán đúng. Lấy số lượng này chia cho tổng số lượng trong tập test data sẽ ra độ chính xác. Scikit-learn cung cấp hàm số [`accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) để thực hiện công việc này. ``` from sklearn.metrics import accuracy_score print \"Accuracy of 1NN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)) ``` ``` Accuracy of 1NN: 94.00 % ``` 1NN đã cho chúng ta kết quả là 94%, không tệ! Chú ý rằng đây là một cơ sở dữ liệu dễ vì chỉ với dữ liệu ở hai cột cuối cùng, chúng ta đã có thể suy ra quy luật. Trong ví dụ này, tôi sử dụng `p = 2` nghĩa là khoảng cách ở đây được tính là khoảng cách theo [norm 2](/math/#norm2). Các bạn cũng có thể thử bằng cách thay `p = 1` cho [norm 1](/math/#norm0), hoặc các gía trị `p` khác cho norm khác. (Xem thêm [sklearn.neighbors.KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) Nhận thấy rằng chỉ xét 1 điểm gần nhất có thể dẫn đến kết quả sai nếu điểm đó là nhiễu. Một cách có thể làm tăng độ chính xác là tăng số lượng điểm lân cận lên, ví dụ 10 điểm, và xem xem trong 10 điểm gần nhất, class nào chiếm đa số thì dự đoán kết quả là class đó. Kỹ thuật dựa vào đa số này được gọi là major voting. ``` clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) print \"Accuracy of 10NN with major voting: %.2f %%\" %(100*accuracy_score(y_test, y_pred)) ``` ``` Accuracy of 10NN with major voting: 98.00 % ``` Kết quả đã tăng lên 98%, rất tốt!",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-10",
        "source": "41.main.md",
        "section": "Đánh trọng số cho các điểm lân cận",
        "content": "Là một kẻ tham lam, tôi chưa muốn dừng kết quả ở đây vì thấy rằng mình vẫn có thể cải thiện được. Trong kỹ thuật major voting bên trên, mỗi trong 10 điểm gần nhất được coi là có vai trò như nhau và giá trị *lá phiếu* của mỗi điểm này là như nhau. Tôi cho rằng như thế là không công bằng, vì rõ ràng rằng những điểm gần hơn nên có trọng số cao hơn (*càng thân cận thì càng tin tưởng*). Vậy nên tôi sẽ đánh trọng số khác nhau cho mỗi trong 10 điểm gần nhất này. Cách đánh trọng số phải thoải mãn điều kiện là một điểm càng gần điểm test data thì phải được đánh trọng số càng cao (tin tưởng hơn). Cách đơn giản nhất là lấy nghịch đảo của khoảng cách này. (Trong trường hợp test data trùng với 1 điểm dữ liệu trong training data, tức khoảng cách bằng 0, ta lấy luôn label của điểm training data). Scikit-learn giúp chúng ta đơn giản hóa việc này bằng cách gán gía trị `weights = 'distance'`. (Giá trị mặc định của `weights` là `'uniform'`, tương ứng với việc coi tất cả các điểm lân cận có giá trị như nhau như ở trên). ``` clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = 'distance') clf.fit(X_train, y_train) y_pred = clf.predict(X_test) print \"Accuracy of 10NN (1/distance weights): %.2f %%\" %(100*accuracy_score(y_test, y_pred)) ``` ``` Accuracy of 10NN (1/distance weights): 100.00 % ``` Aha, 100%. **Chú ý:** Ngoài 2 phương pháp đánh trọng số `weights = 'uniform'` và `weights = 'distance'` ở trên, scikit-learn còn cung cấp cho chúng ta một cách để đánh trọng số một cách tùy chọn. Ví dụ, một cách đánh trọng số phổ biến khác trong Machine Learning là: \\[ w\\_i = \\exp \\left( \\frac{-||\\mathbf{x} - \\mathbf{x}\\_i||\\_2^2}{\\sigma^2} \\right) \\] trong đó \\(\\mathbf{x}\\) là test data, \\(\\mathbf{x}\\_i\\) là một điểm trong K-lân cận của \\(\\mathbf{x}\\), \\(w\\_i\\) là trọng số của điểm đó (ứng với điểm dữ liệu đang xét \\(\\mathbf{x}\\)), \\(\\sigma\\) là một số dương. Nhận thấy rằng hàm số này cũng thỏa mãn điều kiện: điểm càng gần \\(\\mathbf{x}\\) thì trọng số càng cao (cao nhất bằng 1). Với hàm số này, chúng ta có thể lập trình như sau: ``` def myweight(distances): sigma2 = .5 # we can change this number return np.exp(-distances**2/sigma2) clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = myweight) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) print \"Accuracy of 10NN (customized weights): %.2f %%\" %(100*accuracy_score(y_test, y_pred)) ``` ``` Accuracy of 10NN (customized weights): 98.00 % ``` Trong trường hợp này, kết quả tương đương với kỹ thuật major voting. Để đánh giá chính xác hơn kết quả của KNN với K khác nhau, cách định nghĩa khoảng cách khác nhau và cách đánh trọng số khác nhau, chúng ta cần thực hiện quá trình trên với nhiều cách chia dữ liệu *training* và *test* khác nhau rồi lấy kết quả trung bình, vì rất có thể dữ liệu phân chia trong 1 trường hợp cụ thể là rất tốt hoặc rất xấu (bias). Đây cũng là cách thường được dùng khi đánh giá hiệu năng của một thuật toán cụ thể nào đó.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-11",
        "source": "41.main.md",
        "section": "KNN cho Regression",
        "content": "Với bài toán Regression, chúng ta cũng hoàn toàn có thể sử dụng phương pháp tương tự: ước lượng đầu ra dựa trên đầu ra và khoảng cách của các điểm trong K-lân cận. Việc ước lượng như thế nào các bạn có thể tự định nghĩa tùy vào từng bài toán. ![](http://scikit-learn.org/stable/_images/sphx_glr_plot_regression_001.png) KNN cho bài toán Regression (Nguồn: [Nearest Neighbors regression](http://scikit-learn.org/stable/auto_examples/neighbors/plot_regression.html#sphx-glr-auto-examples-neighbors-plot-regression-py))",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-12",
        "source": "41.main.md",
        "section": "Chuẩn hóa dữ liệu",
        "content": "Khi có một thuộc tính trong dữ liệu (hay phần tử trong vector) lớn hơn các thuộc tính khác rất nhiều (ví dụ thay vì đo bằng cm thì một kết quả lại tính bằng mm), khoảng cách giữa các điểm sẽ phụ thuộc vào thuộc tính này rất nhiều. Để có được kết quả chính xác hơn, một kỹ thuật thường được dùng là *Data Normalization* (chuẩn hóa dữ liệu) để đưa các thuộc tính có đơn vị đo khác nhau về cùng một khoảng giá trị, thường là từ 0 đến 1, trước khi thực hiện KNN. Có nhiều kỹ thuật chuẩn hóa khác nhau, các bạn sẽ được thấy khi tiếp tục theo dõi Blog này. Các kỹ thuật chuẩn hóa được áp dụng với không chỉ KNN mà còn với hầu hết các thuật toán khác.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-13",
        "source": "41.main.md",
        "section": "Sử dụng các phép đo khoảng cách khác nhau",
        "content": "Ngoài norm 1 và norm 2 tôi giới thiệu trong bài này, còn rất nhiều các khoảng cách khác nhau có thể được dùng. Một ví dụ đơn giản là đếm số lượng thuộc tính khác nhau giữa hai điểm dữ liệu. Số này càng nhỏ thì hai điểm càng gần nhau. Đây chính là [giả chuẩn 0](/math/#norm0) mà tôi đã giới thiệu trong Tab [Math](/math/).",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-14",
        "source": "41.main.md",
        "section": "Ưu điểm của KNN",
        "content": "1. Độ phức tạp tính toán của quá trình training là bằng 0. 2. Việc dự đoán kết quả của dữ liệu mới rất đơn giản. 3. Không cần giả sử gì về phân phối của các class.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-15",
        "source": "41.main.md",
        "section": "Nhược điểm của KNN",
        "content": "1. KNN rất nhạy cảm với nhiễu khi K nhỏ. 2. Như đã nói, KNN là một thuật toán mà mọi tính toán đều nằm ở khâu test. Trong đó việc tính khoảng cách tới *từng* điểm dữ liệu trong training set sẽ tốn rất nhiều thời gian, đặc biệt là với các cơ sở dữ liệu có số chiều lớn và có nhiều điểm dữ liệu. Với K càng lớn thì độ phức tạp cũng sẽ tăng lên. Ngoài ra, việc lưu toàn bộ dữ liệu trong bộ nhớ cũng ảnh hưởng tới hiệu năng của KNN.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-16",
        "source": "41.main.md",
        "section": "Tăng tốc cho KNN",
        "content": "Ngoài việc tính toán khoảng cách từ một điểm test data đến tất cả các điểm trong traing set (Brute Force), có một số thuật toán khác giúp tăng tốc việc tìm kiếm này. Bạn đọc có thẻ tìm kiếm thêm với hai từ khóa: [K-D Tree](http://pointclouds.org/documentation/tutorials/kdtree_search.php) và [Ball Tree](https://en.wikipedia.org/wiki/Ball_tree). Tôi xin dành phần này cho độc giả tự tìm hiểu, và sẽ quay lại nếu có dịp. Chúng ta vẫn còn những thuật toán quan trọng hơn khác cần nhiều sự quan tâm hơn.",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-17",
        "source": "41.main.md",
        "section": "Try this yourself",
        "content": "Tôi có viết một đoạn code ngắn để thực hiện việc Classification cho cơ sở dữ liệu [MNIST](/2017/01/04/kmeans2/#bo-co-so-du-lieu-mnist). Các bạn hãy download toàn bộ bộ dữ liệu này về vì sau này chúng ta còn dùng nhiều, chạy thử, comment kết quả và nhận xét của các bạn vào phần comment bên dưới. Để trả lời cho câu hỏi vì sao tôi không chọn cơ sở dữ liệu này làm ví dụ, bạn đọc có thể tự tìm ra đáp án khi chạy xong đoạn code này. Enjoy! ```",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-18",
        "source": "41.main.md",
        "section": "%reset",
        "content": "import numpy as np from mnist import MNIST # require `pip install python-mnist`",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-19",
        "source": "41.main.md",
        "section": "https://pypi.python.org/pypi/python-mnist/",
        "content": "import matplotlib.pyplot as plt from sklearn import neighbors from sklearn.metrics import accuracy_score import time",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-20",
        "source": "41.main.md",
        "section": "at: http://yann.lecun.com/exdb/mnist/",
        "content": "mndata = MNIST('../MNIST/') # path to your MNIST folder mndata.load_testing() mndata.load_training() X_test = mndata.test_images X_train = mndata.train_images y_test = np.asarray(mndata.test_labels) y_train = np.asarray(mndata.train_labels) start_time = time.time() clf = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2) clf.fit(X_train, y_train) y_pred = clf.predict(X_test) end_time = time.time() print \"Accuracy of 1NN for MNIST: %.2f %%\" %(100*accuracy_score(y_test, y_pred)) print \"Running time: %.2f (s)\" % (end_time - start_time) ```",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-21",
        "source": "41.main.md",
        "section": "Source code",
        "content": "iPython Notebook cho bài này có thể [download tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/tree/master/assets/knn/KNN.ipynb).",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "41.main-22",
        "source": "41.main.md",
        "section": "5. Tài liệu tham khảo",
        "content": "1. [sklearn.neighbors.NearestNeighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors) 2. [sklearn.model\\_selection.train\\_test\\_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 3. [Tutorial To Implement k-Nearest Neighbors in Python From Scratch](http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/)",
        "url": "https://machinelearningcoban.com/2017/01/08/knn/"
    },
    {
        "id": "17.main-1",
        "source": "17.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Linear Discriminant Analysis cho bài toán với 2 classes](#-linear-discriminant-analysis-cho-bai-toan-voi--classes) + [2.1. Ý tưởng cơ bản](#-y-tuong-co-ban) + [2.2. Xây dựng hàm mục tiêu](#-xay-dung-ham-muc-tieu) + [2.3. Nghiệm của bài toán tối ưu](#-nghiem-cua-bai-toan-toi-uu) * [3. Linear Discriminant Analysis cho multi-class classification problems](#-linear-discriminant-analysis-cho-multi-class-classification-problems) + [3.1. Xây dựng hàm mất mát](#-xay-dung-ham-mat-mat) - [3.1.1. Within-class nhỏ](#-within-class-nho) - [3.1.2. Between-class lớn](#-between-class-lon) + [3.2. Hàm mất mát cho multi-class LDA](#-ham-mat-mat-cho-multi-class-lda) * [4. Ví dụ trên Python](#-vi-du-tren-python) + [4.1. LDA với 2 classes](#-lda-voi--classes) * [5.Thảo luận](#thao-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/06/30/lda/"
    },
    {
        "id": "17.main-2",
        "source": "17.main.md",
        "section": "1. Giới thiệu",
        "content": "Trong hai bài viết trước, tôi đã giới thiệu về thuật toán giảm chiều dữ liệu được sử dụng rộng rãi nhất - Principle Component Analysis (PCA). Như đã đề cập, PCA là một phương pháp thuộc loại [unsupervised learning](/2016/12/27/categories/#unsupervised-learning-hoc-khong-giam-sat), tức là nó chỉ sử dụng các vector mô tả dữ liệu mà không dùng tới labels, nếu có, của dữ liệu. Trong bài toán classification, dạng điển hình nhất của [supervised learning](/2016/12/27/categories/#supervised-learning-hoc-co-giam-sat), việc sử dụng labels sẽ mang lại kết quả phân loại tốt hơn. Nhắc lại một lần nữa, [PCA là phương pháp giảm chiều dữ liệu sao cho lượng thông tin về dữ liệu, thể hiện ở tổng phương sai, được giữ lại là nhiều nhất](https://machinelearningcoban.com/2017/06/15/pca/#-principal-component-analysis). Tuy nhiên, trong nhiều trường hợp, ta không cần giữ lại lượng thông tin lớn nhất mà chỉ cần giữ lại thông tin cần thiết cho riêng bài toán. Xét ví dụ về bài toán phân lớp với 2 classes được mô tả trong Hình 1. --- ![](/assets/29_lda/lda.png) Hình 1: Chiếu dữ liệu lên các đường thẳng khác nhau. Có hai lớp dữ liệu minh hoạ bởi các điểm màu xanh và đỏ. Dữ liệu được giảm số chiều về 1 bằng cách chiếu chúng lên các đường thẳng khác nhau \\(d\\_1\\) và \\(d\\_2\\). Trong hai cách chiều này, phương của \\(d\\_1\\) gần giống với phương của thành phần chính thứ nhất của dữ liệu, phương của \\(d\\_2\\) gần với thành phần phụ của dữ liệu nếu dùng PCA. Khi chiếu lên \\(d\\_1\\), các điểm màu đỏ và xanh bị chồng lấn lên nhau, khiến cho việc phân loại dữ liệu là không khả thi trên đường thẳng này. Ngược lại, khi được chiếu lên \\(d\\_2\\), dữ liệu của hai class được chia thành các cụm tương ứng tách biệt nhau, khiến cho việc classification trở nên đơn giản hơn và hiệu quả hơn. Các đường cong hình chuông thể hiện xấp xỉ phân bố xác suất của dữ liệu hình chiếu trong mỗi class. ---",
        "url": "https://machinelearningcoban.com/2017/06/30/lda/"
    },
    {
        "id": "4.main-1",
        "source": "4.main.md",
        "section": "Introduction",
        "content": "*Tôi xin tạm dừng các bài viết về Decision Tree để chuyển sang Deep Learning. Tôi sẽ quay lại với các thuật toán Machine Learning cổ điển khi có dịp* Trong trang này: * [Giới thiệu](#gioi-thieu) * [Những dấu mốc quan trọng của deep learning](#nhung-dau-moc-quan-trong-cua-deep-learning) + [Perceptron (60s)](#perceptron-s) + [MLP và Backpropagation ra đời (80s)](#mlp-va-backpropagation-ra-doi-s) + [Mùa đông AI thứ hai (90s - đầu 2000s)](#mua-dong-ai-thu-hai-s---dau-s) + [Cái tên được làm mới – Deep Learning (2006)](#cai-ten-duoc-lam-moi----deep-learning-) + [Đột phá (2012)](#dot-pha-) * [Điều gì mang đến sự thành công của deep learning?](#dieu-gi-mang-den-su-thanh-cong-cua-deep-learning) * [Kết luận](#ket-luan) * [Tài liệu tham khảo](#tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2018/06/22/deeplearning/"
    },
    {
        "id": "4.main-2",
        "source": "4.main.md",
        "section": "Giới thiệu",
        "content": "Như đã một lần nhắc đến trong [bài đầu tiên của blog](/2016/12/26/introduce/), trí tuệ nhân tạo đang len lỏi vào trong cuộc sống và ảnh hưởng sâu rộng tới mỗi chúng ta. Kể từ khi tôi viết bài đầu tiên, tần suất chúng ta nghe thấy các cụm từ ‘artificial intelligence’, ‘machine learning’, ‘deep learning’ cũng ngày một tăng lên. Nguyên nhân chính dẫn đến việc này (và việc ra đời blog này) là sự xuất hiện của deep learning trong 5-6 năm gần đây. Một lần nữa xin được dùng lại hình vẽ mô tả mối quan hệ giữa artificial intelligence, machine learning, và deep learning: --- ![](/assets/introduce/aimldl.png) Mối quan hệ giữa AI, Machine Learning và Deep Learning. (Nguồn: [What’s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)) ---",
        "url": "https://machinelearningcoban.com/2018/06/22/deeplearning/"
    },
    {
        "id": "38.main-1",
        "source": "38.main.md",
        "section": "Introduction",
        "content": "Cứ làm đi, sai đâu sửa đấy, cuối cùng sẽ thành công! Đó chính là ý tưởng chính của một thuật toán rất quan trọng trong Machine Learning - thuật toán Perceptron Learning Algorithm hay PLA. **Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) + [Bài toán Perceptron](#bai-toan-perceptron) * [2. Thuật toán Perceptron (PLA)](#-thuat-toan-perceptron-pla) + [Một số ký hiệu](#mot-so-ky-hieu) + [Xây dựng hàm mất mát](#xay-dung-ham-mat-mat) + [Tóm tắt PLA](#tom-tat-pla) * [3. Ví dụ trên Python](#-vi-du-tren-python) + [Load thư viện và tạo dữ liệu](#load-thu-vien-va-tao-du-lieu) + [Các hàm số cho PLA](#cac-ham-so-cho-pla) * [4. Chứng minh hội tụ](#-chung-minh-hoi-tu) * [5. Mô hình Neural Network đầu tiên](#-mo-hinh-neural-network-dau-tien) * [6. Thảo Luận](#-thao-luan) + [PLA có thể cho vô số nghiệm khác nhau](#pla-co-the-cho-vo-so-nghiem-khac-nhau) + [PLA đòi hỏi dữ liệu linearly separable](#pla-doi-hoi-du-lieu-linearly-separable) + [Pocket Algorithm](#pocket-algorithm) * [7. Kết luận](#-ket-luan) * [8. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-2",
        "source": "38.main.md",
        "section": "1. Giới thiệu",
        "content": "Trong bài này, tôi sẽ giới thiệu thuật toán đầu tiên trong Classification có tên là Perceptron Learning Algorithm (PLA) hoặc đôi khi được viết gọn là Perceptron. Perceptron là một thuật toán Classification cho trường hợp đơn giản nhất: chỉ có hai class (lớp) (*bài toán với chỉ hai class được gọi là binary classification*) và cũng chỉ hoạt động được trong một trường hợp rất cụ thể. Tuy nhiên, nó là nền tảng cho một mảng lớn quan trọng của Machine Learning là Neural Networks và sau này là Deep Learning. (Tại sao lại gọi là Neural Networks - tức mạng dây thần kinh - các bạn sẽ được thấy ở cuối bài). Giả sử chúng ta có hai tập hợp dữ liệu đã được gán nhãn được minh hoạ trong Hình 1 bên trái dưới đây. Hai class của chúng ta là tập các điểm màu xanh và tập các điểm màu đỏ. Bài toán đặt ra là: từ dữ liệu của hai tập được gán nhãn cho trước, hãy xây dựng một *classifier* (bộ phân lớp) để khi có một điểm dữ liệu hình tam giác màu xám mới, ta có thể dự đoán được màu (nhãn) của nó. |  |  | | --- | --- | |  |  | Hình 1: Bài toán Perceptron Hiểu theo một cách khác, chúng ta cần tìm *lãnh thổ* của mỗi class sao cho, với mỗi một điểm mới, ta chỉ cần xác định xem nó nằm vào lãnh thổ của class nào rồi quyết định nó thuộc class đó. Để tìm *lãnh thổ* của mỗi class, chúng ta cần đi tìm biên giới (boundary) giữa hai *lãnh thổ* này. Vậy bài toán classification có thể coi là bài toán đi tìm boundary giữa các class. Và boundary đơn giản nhất trong không gian hai chiều là một đường thằng, trong không gian ba chiều là một mặt phẳng, trong không gian nhiều chiều là một siêu mặt phẳng (hyperplane) (tôi gọi chung những boundary này là *đường phẳng*). Những boundary phẳng này được coi là đơn giản vì nó có thể biểu diễn dưới dạng toán học bằng một hàm số đơn giản có dạng tuyến tính, tức linear. Tất nhiên, chúng ta đang giả sử rằng tồn tại một đường phẳng để có thể phân định *lãnh thổ* của hai class. Hình 1 bên phải minh họa một đường thẳng phân chia hai class trong mặt phẳng. Phần có nền màu xanh được coi là *lãnh thổ* của lớp xanh, phần có nên màu đỏ được coi là *lãnh thổ* của lớp đỏ. Trong trường hợp này, điểm dữ liệu mới hình tam giác được phân vào class đỏ.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-3",
        "source": "38.main.md",
        "section": "Bài toán Perceptron",
        "content": "Bài toán Perceptron được phát biểu như sau: *Cho hai class được gán nhãn, hãy tìm một đường phẳng sao cho toàn bộ các điểm thuộc class 1 nằm về 1 phía, toàn bộ các điểm thuộc class 2 nằm về phía còn lại của đường phẳng đó. Với giả định rằng tồn tại một đường phẳng như thế.* Nếu tồn tại một đường phẳng phân chia hai class thì ta gọi hai class đó là *linearly separable*. Các thuật toán classification tạo ra các boundary là các đường phẳng được gọi chung là Linear Classifier.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-4",
        "source": "38.main.md",
        "section": "2. Thuật toán Perceptron (PLA)",
        "content": "Cũng giống như các thuật toán lặp trong [K-means Clustering](/2017/01/01/kmeans/) và [Gradient Descent](/2017/01/12/gradientdescent/), ý tưởng cơ bản của PLA là xuất phát từ một nghiệm dự đoán nào đó, qua mỗi vòng lặp, nghiệm sẽ được cập nhật tới một ví trí tốt hơn. Việc cập nhật này dựa trên việc giảm giá trị của một hàm mất mát nào đó.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-5",
        "source": "38.main.md",
        "section": "Một số ký hiệu",
        "content": "Giả sử \\(\\mathbf{X} = [\\mathbf{x}\\_1, \\mathbf{x}\\_2, \\dots, \\mathbf{x}\\_N] \\in \\mathbb{R}^{d \\times N}\\) là ma trận chứa các điểm dữ liệu mà mỗi cột \\(\\mathbf{x}\\_i \\in \\mathbb{R}^{d\\times 1}\\) là một điểm dữ liệu trong không gian \\(d\\) chiều. (*Chú ý: khác với các bài trước tôi thường dùng các vector hàng để mô tả dữ liệu, trong bài này tôi dùng vector cột để biểu diễn. Việc biểu diễn dữ liệu ở dạng hàng hay cột tùy thuộc vào từng bài toán, miễn sao cách biểu diễn toán học của nó khiến cho người đọc thấy dễ hiểu*). Giả sử thêm các nhãn tương ứng với từng điểm dữ liệu được lưu trong một vector hàng \\(\\mathbf{y} = [y\\_1, y\\_2, \\dots, y\\_N] \\in \\mathbb{R}^{1\\times N}\\), với \\(y\\_i = 1\\) nếu \\(\\mathbf{x}\\_i\\) thuộc class 1 (xanh) và \\(y\\_i = -1\\) nếu \\(\\mathbf{x}\\_i\\) thuộc class 2 (đỏ). Tại một thời điểm, giả sử ta tìm được boundary là đường phẳng có phương trình: \\[ \\begin{eqnarray} f\\_{\\mathbf{w}}(\\mathbf{x}) &=& w\\_1x\\_1 + \\dots + w\\_dx\\_d + w\\_0 \\newline &=&\\mathbf{w}^T\\mathbf{\\bar{x}} = 0 \\end{eqnarray} \\] với \\(\\mathbf{\\bar{x}}\\) là điểm dữ liệu mở rộng bằng cách thêm phần tử \\(x\\_0 = 1\\) lên trước vector \\(\\mathbf{x}\\) tương tự như trong [Linear Regression](/2016/12/28/linearregression/). Và từ đây, khi nói \\(\\mathbf{x}\\), tôi cũng ngầm hiểu là điểm dữ liệu mở rộng. Để cho đơn giản, chúng ta hãy cùng làm việc với trường hợp mỗi điểm dữ liệu có số chiều \\(d = 2\\). Giả sử đường thẳng \\(w\\_1 x\\_1 + w\\_2 x\\_2 + w\\_0 = 0\\) chính là nghiệm cần tìm như Hình 2 dưới đây: ![](\\assets\\pla\\pla4.png) Hình 2: Phương trình đường thẳng boundary. Nhận xét rằng các điểm nằm về cùng 1 phía so với đường thẳng này sẽ làm cho hàm số \\(f\\_{\\mathbf{w}}(\\mathbf{x})\\) mang cùng dấu. Chỉ cần đổi dấu của \\(\\mathbf{w}\\) nếu cần thiết, ta có thể giả sử các điểm nằm trong nửa mặt phẳng nền xanh mang dấu dương (+), các điểm nằm trong nửa mặt phẳng nền đỏ mang dấu âm (-). Các dấu này cũng tương đương với nhãn \\(y\\) của mỗi class. Vậy nếu \\(\\mathbf{w}\\) là một nghiệm của bài toán Perceptron, với một điểm dữ liệu mới \\(\\mathbf{x}\\) chưa được gán nhãn, ta có thể xác định class của nó bằng phép toán đơn giản như sau: \\[ \\text{label}(\\mathbf{x}) = 1 ~\\text{if}~ \\mathbf{w}^T\\mathbf{x} \\geq 0, \\text{otherwise} -1 \\] Ngắn gọn hơn: \\[ \\text{label}(\\mathbf{x}) = \\text{sgn}(\\mathbf{w}^T\\mathbf{x}) \\] trong đó, \\(\\text{sgn}\\) là hàm xác định dấu, với giả sử rằng \\(\\text{sgn}(0) = 1\\).",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-6",
        "source": "38.main.md",
        "section": "Xây dựng hàm mất mát",
        "content": "Tiếp theo, chúng ta cần xây dựng hàm mất mát với tham số \\(\\mathbf{w}\\) bất kỳ. Vẫn trong không gian hai chiều, giả sử đường thẳng \\(w\\_1x\\_1 + w\\_2x\\_2 + w\\_0 = 0\\) được cho như Hình 3 dưới đây: ![](\\assets\\pla\\pla3.png) Hình 3: Đường thẳng bất kỳ và các điểm bị misclassified được khoanh tròn. Trong trường hợp này, các điểm được khoanh tròn là các điểm bị misclassified (phân lớp lỗi). Điều chúng ta mong muốn là không có điểm nào bị misclassified. Hàm mất mát đơn giản nhất chúng ta nghĩ đến là hàm *đếm* số lượng các điểm bị misclassied và tìm cách tối thiểu hàm số này: \\[ J\\_1(\\mathbf{w}) = \\sum\\_{\\mathbf{x}\\_i \\in \\mathcal{M}} (-y\\_i\\text{sgn}(\\mathbf{w}^T\\mathbf{x\\_i})) \\] trong đó \\(\\mathcal{M}\\) là tập hợp các điểm bị misclassifed (*tập hợp này thay đổi theo* \\(\\mathbf{w}\\)). Với mỗi điểm \\(\\mathbf{x}\\_i \\in \\mathcal{M}\\), vì điểm này bị misclassified nên \\(y\\_i\\) và \\(\\text{sgn}(\\mathbf{w}^T\\mathbf{x})\\) khác nhau, và vì thế \\(-y\\_i\\text{sgn}(\\mathbf{w}^T\\mathbf{x\\_i}) = 1 \\). Vậy \\(J\\_1(\\mathbf{w})\\) chính là hàm *đếm* số lượng các điểm bị misclassified. Khi hàm số này đạt giá trị nhỏ nhất bằng 0 thì ta không còn điểm nào bị misclassified. Một điểm quan trọng, hàm số này là rời rạc, không tính được đạo hàm theo \\(\\mathbf{w}\\) nên rất khó tối ưu. Chúng ta cần tìm một hàm mất mát khác để việc tối ưu khả thi hơn. Xét hàm mất mát sau đây: \\[ J(\\mathbf{w}) = \\sum\\_{\\mathbf{x}\\_i \\in \\mathcal{M}} (-y\\_i\\mathbf{w}^T\\mathbf{x\\_i}) \\] Hàm \\(J()\\) khác một chút với hàm \\(J\\_1()\\) ở việc bỏ đi hàm \\(\\text{sgn}\\). Nhận xét rằng khi một điểm misclassified \\(\\mathbf{x}\\_i\\) nằm càng xa boundary thì giá trị \\(-y\\_i\\mathbf{w}^T\\mathbf{x}\\_i\\) sẽ càng lớn, nghĩa là sự sai lệch càng lớn. Giá trị nhỏ nhất của hàm mất mát này cũng bằng 0 nếu không có điểm nào bị misclassifed. Hàm mất mát này cũng được cho là tốt hơn hàm \\(J\\_1()\\) vì nó *trừng phạt* rất nặng những điểm *lấn sâu sang lãnh thổ của class kia*. Trong khi đó, \\(J\\_1()\\) *trừng phạt* các điểm misclassified như nhau (đều = 1), bất kể chúng xa hay gần với đường biên giới. Tại một thời điểm, nếu chúng ta chỉ quan tâm tới các điểm bị misclassified thì hàm số \\(J(\\mathbf{w})\\) khả vi (tính được đạo hàm), vậy chúng ta có thể sử dụng [Gradient Descent](/2017/01/12/gradientdescent/) hoặc [Stochastic Gradient Descent (SGD)](/2017/01/16/gradientdescent2/#-stochastic-gradient-descent) để tối ưu hàm mất mát này. Với ưu điểm của SGD cho các bài toán [large-scale](/2017/01/12/gradientdescent/#large-scale), chúng ta sẽ làm theo thuật toán này. Với *một* điểm dữ liệu \\(\\mathbf{x}\\_i\\) bị misclassified, hàm mất mát trở thành: \\[ J(\\mathbf{w}; \\mathbf{x}\\_i; y\\_i) = -y\\_i\\mathbf{w}^T\\mathbf{x}\\_i \\] Đạo hàm tương ứng: \\[ \\nabla\\_{\\mathbf{w}}J(\\mathbf{w}; \\mathbf{x}\\_i; y\\_i) = -y\\_i\\mathbf{x}\\_i \\] Vậy quy tắc cập nhật là: \\[ \\mathbf{w} = \\mathbf{w} + \\eta y\\_i\\mathbf{x}\\_i \\] với \\(\\eta\\) là learning rate được chọn bằng 1. Ta có một quy tắc cập nhật rất gọn là: \\(\\mathbf{w}\\_{t+1} = \\mathbf{w}\\_{t} + y\\_i\\mathbf{x}\\_i\\). Nói cách khác, với mỗi điểm \\(\\mathbf{x}\\_i\\) bị misclassifed, ta chỉ cần nhân điểm đó với nhãn \\(y\\_i\\) của nó, lấy kết quả cộng vào \\(\\mathbf{w}\\) ta sẽ được \\(\\mathbf{w}\\) mới. Ta có một quan sát nhỏ ở đây: \\[ \\mathbf{w}\\_{t+1}^T\\mathbf{x}\\_i = (\\mathbf{w}\\_{t} + y\\_i\\mathbf{x}\\_i)^T\\mathbf{x}\\_{i} \\newline = \\mathbf{w}\\_{t}^T\\mathbf{x}\\_i + y\\_i ||\\mathbf{x}\\_i||\\_2^2 \\] Nếu \\(y\\_i = 1\\), vì \\(\\mathbf{x}\\_i\\) bị misclassifed nên \\(\\mathbf{w}\\_{t}^T\\mathbf{x}\\_i < 0\\). Cũng vì \\(y\\_i = 1\\) nên \\(y\\_i ||\\mathbf{x}\\_i||\\_2^2 = ||\\mathbf{x}\\_i||\\_2^2 \\geq 1\\) (chú ý \\(x\\_0 = 1\\)), nghĩa là \\(\\mathbf{w}\\_{t+1}^T\\mathbf{x}\\_i > \\mathbf{w}\\_{t}^T\\mathbf{x}\\_i\\). Lý giải bằng lời, \\(\\mathbf{w}\\_{t+1}\\) tiến về phía làm cho \\(\\mathbf{x}\\_i\\) được phân lớp đúng. Điều tương tự xảy ra nếu \\(y\\_i = -1\\). Đến đây, cảm nhận của chúng ta với thuật toán này là: cứ chọn đường boundary đi. Xét từng điểm một, nếu điểm đó bị misclassified thì tiến đường boundary về phía làm cho điểm đó được classifed đúng. Có thể thấy rằng, khi di chuyển đường boundary này, các điểm trước đó được classified đúng có thể lại bị misclassified. Mặc dù vậy, PLA vẫn được đảm bảo sẽ hội tụ sau một số hữu hạn bước (tôi sẽ chứng minh việc này ở phía sau của bài viết). Tức là cuối cùng, ta sẽ tìm được đường phẳng phân chia hai lớp, miễn là hai lớp đó là linearly separable. Đây cũng chính là lý do câu đầu tiên trong bài này tôi nói với các bạn là: “Cứ làm đi, sai đâu sửa đấy, cuối cùng sẽ thành công!”. Tóm lại, thuật toán Perceptron có thể được viết như sau:",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-7",
        "source": "38.main.md",
        "section": "Tóm tắt PLA",
        "content": "1. Chọn ngẫu nhiên một vector hệ số \\(\\mathbf{w}\\) với các phần tử gần 0. 2. Duyệt ngẫu nhiên qua từng điểm dữ liệu \\(\\mathbf{x}\\_i\\): * Nếu \\(\\mathbf{x}\\_i\\) được phân lớp đúng, tức \\(\\text{sgn}(\\mathbf{w}^T\\mathbf{x}\\_i) = y\\_i\\), chúng ta không cần làm gì. * Nếu \\(\\mathbf{x}\\_i\\) bị misclassifed, cập nhật \\(\\mathbf{w}\\) theo công thức: \\[ \\mathbf{w} = \\mathbf{w} + y\\_i\\mathbf{x}\\_i \\] 3. Kiểm tra xem có bao nhiêu điểm bị misclassifed. Nếu không còn điểm nào, dừng thuật toán. Nếu còn, quay lại bước 2.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-8",
        "source": "38.main.md",
        "section": "3. Ví dụ trên Python",
        "content": "Như thường lệ, chúng ta sẽ thử một ví dụ nhỏ với Python.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-9",
        "source": "38.main.md",
        "section": "Load thư viện và tạo dữ liệu",
        "content": "Chúng ta sẽ tạo hai nhóm dữ liệu, mỗi nhóm có 10 điểm, mỗi điểm dữ liệu có hai chiều để thuận tiện cho việc minh họa. Sau đó, tạo dữ liệu mở rộng bằng cách thêm 1 vào đầu mỗi điểm dữ liệu. ```",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-10",
        "source": "38.main.md",
        "section": "list of points",
        "content": "import numpy as np import matplotlib.pyplot as plt from scipy.spatial.distance import cdist np.random.seed(2) means = [[2, 2], [4, 2]] cov = [[.3, .2], [.2, .3]] N = 10 X0 = np.random.multivariate_normal(means[0], cov, N).T X1 = np.random.multivariate_normal(means[1], cov, N).T X = np.concatenate((X0, X1), axis = 1) y = np.concatenate((np.ones((1, N)), -1*np.ones((1, N))), axis = 1)",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-11",
        "source": "38.main.md",
        "section": "Xbar",
        "content": "X = np.concatenate((np.ones((1, 2*N)), X), axis = 0) ``` Sau khi thực hiện đoạn code này, biến `X` sẽ chứa dữ liệu input (mở rộng), biến `y` sẽ chứa nhãn của mỗi điểm dữ liệu trong `X`.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-12",
        "source": "38.main.md",
        "section": "Các hàm số cho PLA",
        "content": "Tiếp theo chúng ta cần viết 3 hàm số cho PLA: 1. `h(w, x)`: tính đầu ra khi biết đầu vào `x` và weights `w`. 2. `has_converged(X, y, w)`: kiểm tra xem thuật toán đã hội tụ chưa. Ta chỉ cần so sánh `h(w, X)` với *ground truth* `y`. Nếu giống nhau thì dừng thuật toán. 3. `perceptron(X, y, w_init)`: hàm chính thực hiện PLA. ``` def h(w, x): return np.sign(np.dot(w.T, x)) def has_converged(X, y, w): return np.array_equal(h(w, X), y) def perceptron(X, y, w_init): w = [w_init] N = X.shape[1] d = X.shape[0] mis_points = [] while True:",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-13",
        "source": "38.main.md",
        "section": "mix data",
        "content": "mix_id = np.random.permutation(N) for i in range(N): xi = X[:, mix_id[i]].reshape(d, 1) yi = y[0, mix_id[i]] if h(w[-1], xi)[0] != yi: # misclassified point mis_points.append(mix_id[i]) w_new = w[-1] + yi*xi w.append(w_new) if has_converged(X, y, w[-1]): break return (w, mis_points) d = X.shape[0] w_init = np.random.randn(d, 1) (w, m) = perceptron(X, y, w_init) ``` Dưới đây là hình minh họa thuật toán PLA cho bài toán nhỏ này: ![](\\assets\\pla\\pla_vis.gif) Hình 4: Minh họa thuật toán PLA Sau khi cập nhật 18 lần, PLA đã hội tụ. Điểm được khoanh tròn màu đen là điểm misclassified tương ứng được chọn để cập nhật đường boundary. Source code cho phần này (bao gồm hình động) [có thể được tìm thấy ở đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/pla/perceptron.py).",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-14",
        "source": "38.main.md",
        "section": "4. Chứng minh hội tụ",
        "content": "Giả sử rằng \\(\\mathbf{w}^\\*\\) là một nghiệm của bài toán (ta có thể giả sử việc này được vì chúng ta đã có giả thiết hai class là linearly separable - tức tồn tại nghiệm). Có thể thấy rằng, với mọi \\(\\alpha > 0\\), nếu \\(\\mathbf{w}^\\*\\) là nghiệm, \\(\\alpha\\mathbf{w}^\\*\\) cũng là nghiệm của bài toán. Xét dãy số không âm \\( u\\_{\\alpha}(t) = ||\\mathbf{w}\\_{t} - \\alpha\\mathbf{w}^\\*||\\_2^2\\). Với \\(\\mathbf{x}\\_i\\) là một điểm bị misclassified nếu dùng nghiệm \\(\\mathbf{w}\\_t\\) ta có: \\[ \\begin{eqnarray} &&u\\_{\\alpha}(t+1) = ||\\mathbf{w}\\_{t+1} - \\alpha \\mathbf{w}^\\*||\\_2^2 \\newline &=& ||\\mathbf{w}\\_{t} + y\\_i\\mathbf{x}\\_i - \\alpha\\mathbf{w}^\\*||\\_2^2 \\newline &=& ||\\mathbf{w}\\_{t} -\\alpha\\mathbf{w}^\\*||\\_2^2 + y\\_i^2||\\mathbf{x}\\_i||\\_2^2 + 2y\\_i\\mathbf{x}\\_i^T(\\mathbf{w} - \\alpha\\mathbf{w}^\\*) \\newline &<& u\\_{\\alpha}(t) \\ + ||\\mathbf{x}\\_i||\\_2^2 - 2\\alpha y\\_i\\mathbf{x}\\_i^T \\mathbf{w}^\\* \\end{eqnarray} \\] Dấu nhỏ hơn ở dòng cuối là vì \\(y\\_i^2 = 1\\) và \\(2y\\_i\\mathbf{x}\\_i^T\\mathbf{w}\\_{t} < 0\\). Nếu ta đặt: \\[ \\begin{eqnarray} \\beta^2 &=& \\max\\_{i=1, 2, \\dots, N}||\\mathbf{x}\\_i||\\_2^2 \\newline \\gamma &=& \\min\\_{i=1, 2, \\dots, N} y\\_i\\mathbf{x}\\_i^T\\mathbf{w}^\\* \\end{eqnarray} \\] và chọn \\(\\alpha = \\frac{\\beta^2}{\\gamma}\\), ta có: \\[ 0 \\leq u\\_{\\alpha}(t+1) < u\\_{\\alpha}(t) + \\beta^2 - 2\\alpha\\gamma = u\\_{\\alpha}(t) - \\beta^2 \\] Điều này nghĩa là: nếu luôn luôn có các điểm bị misclassified thì dãy \\(u\\_{\\alpha}(t)\\) là dãy giảm, bị chặn dưới bởi 0, và phần tử sau kém phần tử trước ít nhất một lượng là \\(\\beta^2>0\\). Điều vô lý này chứng tỏ đến một lúc nào đó sẽ không còn điểm nào bị misclassified. Nói cách khác, thuật toán PLA hội tụ sau một số hữu hạn bước.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-15",
        "source": "38.main.md",
        "section": "5. Mô hình Neural Network đầu tiên",
        "content": "Hàm số xác định class của Perceptron \\(\\text{label}(\\mathbf{x}) = \\text{sgn}(\\mathbf{w}^T\\mathbf{x})\\) có thể được mô tả như hình vẽ (được gọi là network) dưới đây: ![](\\assets\\pla\\pla_nn.png) Hình 5: Biểu diễn của Perceptron dưới dạng Neural Network. Đầu vào của network \\(\\mathbf{x}\\) được minh họa bằng các node màu xanh lục với node \\(x\\_0\\) luôn luôn bằng 1. Tập hợp các node màu xanh lục được gọi là *Input layer*. Trong ví dụ này, tôi giả sử số chiều của dữ liệu \\(d = 4\\). Số node trong input layer luôn luôn là \\(d + 1\\) với một node là 1 được thêm vào. Node \\(x\\_0 = 1\\) này đôi khi được ẩn đi. Các trọng số (*weights*) \\(w\\_0, w\\_1, \\dots, w\\_d\\) được gán vào các mũi tên đi tới node \\(\\displaystyle z = \\sum\\_{i=0}^dw\\_ix\\_i = \\mathbf{w}^T\\mathbf{x}\\). Node \\(y = \\text{sgn}(z)\\) là *output* của network. Ký hiệu hình chữ Z ngược màu xanh trong node \\(y\\) thể hiện đồ thị của hàm số \\(\\text{sgn}\\). Trong thuật toán PLA, ta phải tìm các weights trên các mũi tên sao cho với mỗi \\(\\mathbf{x}\\_i\\) ở tập các điểm dữ liệu đã biết được đặt ở Input layer, output của network này trùng với nhãn \\(y\\_i\\) tương ứng. Hàm số \\(y = \\text{sgn}(z)\\) còn được gọi là *activation function*. Đây chính là dạng đơn giản nhất của Neural Network. Các Neural Networks sau này có thể có nhiều node ở output tạo thành một *output layer*, hoặc có thể có thêm các layer trung gian giữa *input layer* và *output layer*. Các layer trung gian đó được gọi là *hidden layer*. Khi biểu diễn các Networks lớn, người ta thường giản lược hình bên trái thành hình bên phải. Trong đó node \\(x\\_0 = 1\\) thường được ẩn đi. Node \\(z\\) cũng được ẩn đi và viết gộp vào trong node \\(y\\). Perceptron thường được vẽ dưới dạng đơn giản như Hình 5 bên phải. Để ý rằng nếu ta thay *activation function* bởi \\(y = z\\), ta sẽ có Neural Network mô tả thuật toán Linear Regression như hình dưới. Với đường thẳng chéo màu xanh thể hiện đồ thị hàm số \\(y = z\\). Các trục tọa độ đã được lược bỏ. ![](\\assets\\pla\\lr_nn.png) Hình 6: Biểu diễn của Linear Regression dưới dạng Neural Network. Mô hình perceptron ở trên khá giống với một node nhỏ của dây thân kinh sinh học như hình sau đây: ![](http://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_neuron.png) Hình 7: Mô tả một neuron thần kinh sinh học. (Nguồn: [Single-Layer Neural Networks and Gradient Descent](http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html)) Dữ liệu từ nhiều dây thần kinh đi về một *cell nucleus*. Thông tin được tổng hợp và được đưa ra ở output. Nhiều bộ phận như thế này kết hợp với nhau tạo nên hệ thần kinh sinh học. Chính vì vậy mà có tên Neural Networks trong Machine Learning. Đôi khi mạng này còn được gọi là Artificial Neural Networks (ANN) tức *hệ neuron nhân tạo*.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-16",
        "source": "38.main.md",
        "section": "PLA có thể cho vô số nghiệm khác nhau",
        "content": "Rõ ràng rằng, nếu hai class là linearly separable thì có vô số đường thằng phân cách 2 class đó. Dưới đây là một ví dụ: ![](/assets/pla/pla6.png) Hình 8: PLA có thể cho vô số nghiệm khác nhau. Tất cả các đường thẳng màu đen đều thỏa mãn. Tuy nhiên, các đường khác nhau sẽ quyết định điểm hình tam giác thuộc các lớp khác nhau. Trong các đường đó, đường nào là tốt nhất? Và định nghĩa “tốt nhất” được hiểu theo nghĩa nào? Có một thuật toán khác định nghĩa và tìm đường tốt nhất như thế, tôi sẽ giới thiệu trong 1 vài bài tới. Mời các bạn đón đọc.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-17",
        "source": "38.main.md",
        "section": "PLA đòi hỏi dữ liệu linearly separable",
        "content": "Hai class trong ví dụ dưới đây *tương đối* linearly separable. Mỗi class có 1 điểm coi như *nhiễu* nằm trong khu vực các điểm của class kia. PLA sẽ không làm việc trong trường hợp này vì luôn luôn có ít nhất 2 điểm bị misclassified. ![](/assets/pla/pla7.png) Hinhf 9: PLA không làm việc nếu chỉ có một nhiễu nhỏ. Trong một chừng mực nào đó, đường thẳng màu đen vẫn có thể coi là một nghiệm tốt vì nó đã giúp phân loại chính xác hầu hết các điểm. Việc không hội tụ với dữ liệu *gần* linearly separable chính là một nhược điểm lớn của PLA. Để khắc phục nhược điểm này, có một cải tiến nhỏ như thuật toán Pocket Algorithm dưới đây:",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-18",
        "source": "38.main.md",
        "section": "Pocket Algorithm",
        "content": "Một cách tự nhiên, nếu có một vài *nhiễu*, ta sẽ đi tìm một đường thẳng phân chia hai class sao cho có ít điểm bị misclassified nhất. Việc này có thể được thực hiện thông qua PLA với một chút thay đổi nhỏ như sau: 1. Giới hạn số lượng vòng lặp của PLA. 2. Mỗi lần cập nhật nghiệm \\(\\mathbf{w}\\) mới, ta đếm xem có bao nhiêu điểm bị misclassified. Nếu là lần đầu tiên, giữ lại nghiệm này trong *pocket* (túi quần). Nếu không, so sánh số điểm misclassified này với số điểm misclassified của nghiệm trong *pocket*, nếu nhỏ hơn thì *lôi* nghiệm cũ ra, đặt nghiệm mới này vào. Thuật toán này giống với thuật toán tìm phần tử nhỏ nhất trong 1 mảng.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-19",
        "source": "38.main.md",
        "section": "7. Kết luận",
        "content": "Hy vọng rằng bài viết này sẽ giúp các bạn phần nào hiểu được một số khái niệm trong Neural Networks. Trong một số bài tiếp theo, tôi sẽ tiếp tục nói về các thuật toán cơ bản khác trong Neural Networks trước khi chuyển sang phần khác. Trong tương lai, nếu có thể, tôi sẽ viết tiếp về Deep Learning và chúng ta sẽ lại quay lại với Neural Networks.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "38.main-20",
        "source": "38.main.md",
        "section": "8. Tài liệu tham khảo",
        "content": "[1] F. Rosenblatt. The perceptron, a perceiving and recognizing automaton Project Para. Cornell Aeronautical Laboratory, 1957. [2] W. S. McCulloch and W. Pitts. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4):115–133, 1943. [3] B. Widrow et al. Adaptive ”Adaline” neuron using chemical ”memistors”. Number Technical Report 1553-2. Stanford Electron. Labs., Stanford, CA, October 1960. [3] Abu-Mostafa, Yaser S., Malik Magdon-Ismail, and Hsuan-Tien Lin. Learning from data. Vol. 4. New York, NY, USA:: AMLBook, 2012. ([link to course](http://work.caltech.edu/telecourse.html)) [4] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer (2006). ([book](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)) [5] Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern classification. John Wiley & Sons, 2012.",
        "url": "https://machinelearningcoban.com/2017/01/21/perceptron/"
    },
    {
        "id": "28.main-1",
        "source": "28.main.md",
        "section": "Introduction",
        "content": "Trong loạt bài tiếp theo, tôi sẽ trình bày về một trong những thuật toán classification phổ biến nhất (cùng với [softmax regression](/2017/02/17/softmax/)). Có rất nhiều suy luận toán học trong phần này yêu cầu bạn cần có kiến thức về [Duality](/2017/04/02/duality/) cũng như về tối ưu lồi. Bạn được khuyến khích đọc các Bài 16, 17, và 18 trước khi đọc bài này. *Nếu không muốn đi sâu vào phần toán, bạn có thể bỏ qua mục 3.* **Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) + [1.1. Khoảng cách từ một điểm tới một siêu mặt phẳng](#-khoang-cach-tu-mot-diem-toi-mot-sieu-mat-phang) + [1.2. Nhắc lại bài toán phân chia hai classes](#-nhac-lai-bai-toan-phan-chia-hai-classes) * [2. Xây dựng bài toán tối ưu cho SVM](#-xay-dung-bai-toan-toi-uu-cho-svm) * [3. Bài toán đối ngẫu cho SVM](#-bai-toan-doi-ngau-cho-svm) + [3.1. Kiểm tra tiêu chuẩn Slater](#-kiem-tra-tieu-chuan-slater) + [3.2. Lagrangian của bài toán SVM](#-lagrangian-cua-bai-toan-svm) + [3.3. Hàm đối ngẫu Lagrange](#-ham-doi-ngau-lagrange) + [3.4. Bài toán đối ngẫu Lagrange](#-bai-toan-doi-ngau-lagrange) + [3.5. Điều kiện KKT](#-dieu-kien-kkt) * [4. Lập trình tìm nghiệm cho SVM](#-lap-trinh-tim-nghiem-cho-svm) + [4.1. Tìm nghiệm theo công thức](#-tim-nghiem-theo-cong-thuc) + [4.2. Tìm nghiệm theo thư viện](#-tim-nghiem-theo-thu-vien) * [5. Tóm tắt và thảo luận](#-tom-tat-va-thao-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/04/09/smv/"
    },
    {
        "id": "28.main-2",
        "source": "28.main.md",
        "section": "1. Giới thiệu",
        "content": "Trước khi đi vào phần ý tưởng chính của Support Vector Machine, tôi xin một lần nữa nhắc lại kiến thức về hình học giải tích mà chúng ta đã quá quen khi ôn thi đại học.",
        "url": "https://machinelearningcoban.com/2017/04/09/smv/"
    },
    {
        "id": "28.main-3",
        "source": "28.main.md",
        "section": "1.1. Khoảng cách từ một điểm tới một siêu mặt phẳng",
        "content": "Trong không gian 2 chiều, ta biết rằng khoảng cách từ một điểm có toạ độ \\((x\\_0, y\\_0)\\) tới *đường thẳng* có phương trình \\(w\\_1x + w\\_2y + b = 0\\) được xác định bởi: \\[ \\frac{|w\\_1x\\_0 + w\\_2y\\_0 + b|}{\\sqrt{w\\_1^2 + w\\_2^2}} \\] Trong không gian ba chiều, khoảng cách từ một điểm có toạ độ \\((x\\_0, y\\_0, z\\_0)\\) tới một *mặt phẳng* có phương trình \\(w\\_1x + w\\_2y + w\\_3 z + b = 0\\) được xác định bởi: \\[ \\frac{|w\\_1x\\_0 + w\\_2y\\_0 + w\\_3z\\_0 + b |}{\\sqrt{w\\_1^2 + w\\_2^2 + w\\_3^2}} \\] Hơn nữa, nếu ta bỏ dấu trị tuyệt đối ở tử số, chúng ta có thể xác định được điểm đó nằm về phía nào của *đường thẳng* hay *mặt phẳng* đang xét. Những điểm làm cho biểu thức trong dấu giá trị tuyệt đối mang dấu dương nằm về cùng 1 phía (tôi tạm gọi đây là *phía dương* của đường thẳng), những điểm làm cho biểu thức trong dấu giá trị tuyệt đối mang dấu âm nằm về phía còn lại (tôi gọ là *phía âm*). Những điểm nằm trên *đường thẳng*/*măt phẳng* sẽ làm cho tử số có giá trị bằng 0, tức khoảng cách bằng 0. Việc này có thể được tổng quát lên không gian nhiều chiều: Khoảng cách từ một điểm (vector) có toạ độ \\(\\mathbf{x}\\_0\\) tới *siêu mặt phẳng* (*hyperplane*) có phương trình \\(\\mathbf{w}^T\\mathbf{x} + b = 0\\) được xác định bởi: \\[ \\frac{|\\mathbf{w}^T\\mathbf{x}\\_0 + b|}{||\\mathbf{w}||\\_2} \\] Với \\(||\\mathbf{w}||\\_2 = \\sqrt{\\sum\\_{i=1}^d w\\_i^2}\\) với \\(d\\) là số chiều của không gian.",
        "url": "https://machinelearningcoban.com/2017/04/09/smv/"
    },
    {
        "id": "28.main-4",
        "source": "28.main.md",
        "section": "1.2. Nhắc lại bài toán phân chia hai classes",
        "content": "Chúng ta cùng quay lại với bài toán trong [Perceptron Learning Algorithm (PLA)](/2017/01/21/perceptron/). Giả sử rằng có hai class khác nhau được mô tả bởi các điểm trong không gian nhiều chiều, hai classes này *linearly separable*, tức tồn tại một siêu phẳng phân chia chính xác hai classes đó. Hãy tìm một siêu mặt phẳng phân chia hai classes đó, tức tất cả các điểm thuộc một class nằm về cùng một phía của siêu mặt phẳng đó và ngược phía với toàn bộ các điểm thuộc class còn lại. Chúng ta đã biết rằng, thuật toán PLA có thể làm được việc này nhưng nó có thể cho chúng ta vô số nghiệm như Hình 1 dưới đây: --- ![](/assets/19_svm/svm1.png) Hình 1: Các mặt phân cách hai classes linearly separable. ---",
        "url": "https://machinelearningcoban.com/2017/04/09/smv/"
    },
    {
        "id": "43.main-1",
        "source": "43.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Phân tích toán học](#-phan-tich-toan-hoc) + [Một số ký hiệu toán học](#mot-so-ky-hieu-toan-hoc) + [Hàm mất mát và bài toán tối ưu](#ham-mat-mat-va-bai-toan-toi-uu) + [Thuật toán tối ưu hàm mất mát](#thuat-toan-toi-uu-ham-mat-mat) - [Cố định \\(\\mathbf{M} \\), tìm \\(\\mathbf{Y}\\)](#co-dinh-\\\\\\mathbfm-\\\\-tim-\\\\\\mathbfy\\\\) - [Cố định \\(\\mathbf{Y} \\), tìm \\(\\mathbf{M}\\)](#co-dinh-\\\\\\mathbfy-\\\\-tim-\\\\\\mathbfm\\\\) + [Tóm tắt thuật toán](#tom-tat-thuat-toan) * [3. Ví dụ trên Python](#-vi-du-tren-python) + [Giới thiệu bài toán](#gioi-thieu-bai-toan) + [Hiển thị dữ liệu trên đồ thị](#hien-thi-du-lieu-tren-do-thi) + [Các hàm số cần thiết cho K-means clustering](#cac-ham-so-can-thiet-cho-k-means-clustering) + [Kết quả tìm được bằng thư viện scikit-learn](#ket-qua-tim-duoc-bang-thu-vien-scikit-learn) * [4. Thảo luận](#-thao-luan) + [Hạn chế](#han-che) - [Chúng ta cần biết số lượng cluster cần clustering](#chung-ta-can-biet-so-luong-cluster-can-clustering) - [Nghiệm cuối cùng phụ thuộc vào các centers được khởi tạo ban đầu](#nghiem-cuoi-cung-phu-thuoc-vao-cac-centers-duoc-khoi-tao-ban-dau) - [Các cluster cần có só lượng điểm gần bằng nhau](#cac-cluster-can-co-so-luong-diem-gan-bang-nhau) - [Các cluster cần có dạng hình tròn](#cac-cluster-can-co-dang-hinh-tron) - [Khi một cluster nằm phía trong 1 cluster khác](#khi-mot-cluster-nam-phia-trong--cluster-khac) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-2",
        "source": "43.main.md",
        "section": "1. Giới thiệu",
        "content": "[Trong bài trước](/2016/12/28/linearregression/), chúng ta đã làm quen với thuật toán Linear Regression - là thuật toán đơn giản nhất trong [Supervised learning](/2016/12/27/categories/#supervised-learning-hoc-co-giam-sat). Bài này tôi sẽ giới thiệu một trong những thuật toán cơ bản nhất trong [Unsupervised learning](/2016/12/27/categories/#unsupervised-learning-hoc-khong-giam-sat) - thuật toán K-means clustering (phân cụm K-means). Trong thuật toán K-means clustering, chúng ta không biết nhãn (label) của từng điểm dữ liệu. Mục đích là làm thể nào để phân dữ liệu thành các cụm (cluster) khác nhau sao cho *dữ liệu trong cùng một cụm có tính chất giống nhau*. **Ví dụ:** Một công ty muốn tạo ra những chính sách ưu đãi cho những nhóm khách hàng khác nhau dựa trên sự tương tác giữa mỗi khách hàng với công ty đó (số năm là khách hàng; số tiền khách hàng đã chi trả cho công ty; độ tuổi; giới tính; thành phố; nghề nghiệp; …). Giả sử công ty đó có rất nhiều dữ liệu của rất nhiều khách hàng nhưng chưa có cách nào chia toàn bộ khách hàng đó thành một số nhóm/cụm khác nhau. Nếu một người biết Machine Learning được đặt câu hỏi này, phương pháp đầu tiên anh (chị) ta nghĩ đến sẽ là K-means Clustering. Vì nó là một trong những thuật toán đầu tiên mà anh ấy tìm được trong các cuốn sách, khóa học về Machine Learning. Và tôi cũng chắc rằng anh ấy đã đọc blog [Machine Learning cơ bản](https://tiepvupsu.github.io). Sau khi đã phân ra được từng nhóm, nhân viên công ty đó có thể lựa chọn ra một vài khách hàng trong mỗi nhóm để quyết định xem mỗi nhóm tương ứng với nhóm khách hàng nào. Phần việc cuối cùng này cần sự can thiệp của con người, nhưng lượng công việc đã được rút gọn đi rất nhiều. Ý tưởng đơn giản nhất về cluster (cụm) là tập hợp các điểm *ở gần nhau trong một không gian nào đó* (không gian này có thể có rất nhiều chiều trong trường hợp thông tin về một điểm dữ liệu là rất lớn). Hình bên dưới là một ví dụ về 3 cụm dữ liệu (từ giờ tôi sẽ viết gọn là *cluster*). ![](/assets/kmeans/figure_2.png) Bài toán với 3 clusters. Giả sử mỗi cluster có một điểm đại diện (*center*) màu vàng. Và những điểm xung quanh mỗi center thuộc vào cùng nhóm với center đó. Một cách đơn giản nhất, xét một điểm bất kỳ, ta xét xem điểm đó gần với center nào nhất thì nó thuộc về cùng nhóm với center đó. Tới đây, chúng ta có một bài toán thú vị: *Trên một vùng biển hình vuông lớn có ba đảo hình vuông, tam giác, và tròn màu vàng như hình trên. Một điểm trên biển được gọi là thuộc lãnh hải của một đảo nếu nó nằm gần đảo này hơn so với hai đảo kia . Hãy xác định ranh giới lãnh hải của các đảo.* Hình dưới đây là một hình minh họa cho việc phân chia lãnh hải nếu có 5 đảo khác nhau được biểu diễn bằng các hình tròn màu đen: ![](/assets/kmeans/figure_1.png) Phân vùng lãnh hải của mỗi đảo. Các vùng khác nhau có màu sắc khác nhau. Chúng ta thấy rằng đường phân định giữa các lãnh hải là các đường thẳng (chính xác hơn thì chúng là các đường trung trực của các cặp điểm gần nhau). Vì vậy, lãnh hải của một đảo sẽ là một hình đa giác. Cách phân chia này trong toán học được gọi là [Voronoi Diagram](https://en.wikipedia.org/wiki/Voronoi_diagram). Trong không gian ba chiều, lấy ví dụ là các hành tinh, thì (tạm gọi là) *lãnh không* của mỗi hành tinh sẽ là một đa diện. Trong không gian nhiều chiều hơn, chúng ta sẽ có những thứ (mà tôi gọi là) *siêu đa diện* (hyperpolygon). Quay lại với bài toán phân nhóm và cụ thể là thuật toán K-means clustering, chúng ta cần một chút phân tích toán học trước khi đi tới phần [tóm tắt thuật toán](#tom-tat-thuat-toan) ở phần dưới. Nếu bạn không muốn đọc quá nhiều về toán, bạn có thể bỏ qua phần này. (*Tốt nhất là đừng bỏ qua, bạn sẽ tiếc đấy*).",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-3",
        "source": "43.main.md",
        "section": "2. Phân tích toán học",
        "content": "Mục đích cuối cùng của thuật toán phân nhóm này là: từ dữ liệu đầu vào và số lượng nhóm chúng ta muốn tìm, hãy chỉ ra center của mỗi nhóm và phân các điểm dữ liệu vào các nhóm tương ứng. Giả sử thêm rằng mỗi điểm dữ liệu chỉ thuộc vào đúng một nhóm.",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-4",
        "source": "43.main.md",
        "section": "Một số ký hiệu toán học",
        "content": "Giả sử có \\(N\\) điểm dữ liệu là \\( \\mathbf{X} = [\\mathbf{x}\\_1, \\mathbf{x}\\_2, \\dots, \\mathbf{x}\\_N] \\in \\mathbb{R}^{d \\times N}\\) và \\(K < N\\) là số cluster chúng ta muốn phân chia. Chúng ta cần tìm các center \\( \\mathbf{m}\\_1, \\mathbf{m}\\_2, \\dots, \\mathbf{m}\\_K \\in \\mathbb{R}^{d \\times 1} \\) và label của mỗi điểm dữ liệu. **Lưu ý về ký hiệu toán học:** *trong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng không in đậm, có thể viết hoa, ví dụ \\(x\\_1, N, y, k\\). Các vector được biểu diễn bằng các chữ cái thường in đậm, ví dụ \\(\\mathbf{m}, \\mathbf{x}\\_1 \\). Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụ \\(\\mathbf{X, M, Y} \\). Lưu ý này đã được nêu ở bài [Linear Regression](/2016/12/28/linearregression/). Tôi xin được không nhắc lại trong các bài tiếp theo.* Với mỗi điểm dữ liệu \\( \\mathbf{x}\\_i \\) đặt \\(\\mathbf{y}\\_i = [y\\_{i1}, y\\_{i2}, \\dots, y\\_{iK}]\\) là label vector của nó, trong đó nếu \\( \\mathbf{x}\\_i \\) được phân vào cluster \\(k\\) thì \\(y\\_{ik} = 1\\) và \\(y\\_{ij} = 0, \\forall j \\neq k \\). Điều này có nghĩa là có đúng một phần tử của vector \\(\\mathbf{y}\\_i\\) là bằng 1 (tương ứng với cluster của \\(\\mathbf{x}\\_i \\)), các phần tử còn lại bằng 0. Ví dụ: nếu một điểm dữ liệu có label vector là \\([1,0,0,\\dots,0]\\) thì nó thuộc vào cluster 1, là \\([0,1,0,\\dots,0]\\) thì nó thuộc vào cluster 2, \\(\\dots\\). Cách mã hóa label của dữ liệu như thế này được gọi là biểu diễn [*one-hot*](https://en.wikipedia.org/wiki/One-hot). Chúng ta sẽ thấy cách biểu diễn one-hot này rất phổ biến trong Machine Learning ở các bài tiếp theo. Ràng buộc của \\(\\mathbf{y}\\_i \\) có thể viết dưới dạng toán học như sau: \\[ y\\_{ik} \\in \\{0, 1\\},~~~ \\sum\\_{k = 1}^K y\\_{ik} = 1 ~~~ (1) \\]",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-5",
        "source": "43.main.md",
        "section": "Hàm mất mát và bài toán tối ưu",
        "content": "Nếu ta coi center \\(\\mathbf{m}\\_k \\) là center (hoặc representative) của mỗi cluster và *ước lượng* tất cả các điểm được phân vào cluster này bởi \\(\\mathbf{m}\\_k \\), thì một điểm dữ liệu \\(\\mathbf{x}\\_i \\) được phân vào cluster \\(k\\) sẽ bị sai số là \\( (\\mathbf{x}\\_i - \\mathbf{m}\\_k) \\). Chúng ta mong muốn sai số này có trị tuyệt đối nhỏ nhất nên ([giống như trong bài Linear Regression](/2016/12/28/linearregression/#sai-so-du-doan)) ta sẽ tìm cách để đại lượng sau đây đạt giá trị nhỏ nhất: \\[ \\|\\mathbf{x}\\_i - \\mathbf{m}\\_k\\|\\_2^2 \\] Hơn nữa, vì \\(\\mathbf{x}\\_i \\) được phân vào cluster \\(k\\) nên \\(y\\_{ik} = 1, y\\_{ij} = 0, ~\\forall j \\neq k \\). Khi đó, biểu thức bên trên sẽ được viết lại là: \\[ y\\_{ik}\\|\\mathbf{x}\\_i - \\mathbf{m}\\_k\\|\\_2^2 = \\sum\\_{j=1}^K y\\_{ij}\\|\\mathbf{x}\\_i - \\mathbf{m}\\_j\\|\\_2^2 \\] (*Hy vọng chỗ này không quá khó hiểu*) Sai số cho toàn bộ dữ liệu sẽ là: \\[ \\mathcal{L}(\\mathbf{Y}, \\mathbf{M}) = \\sum\\_{i=1}^N\\sum\\_{j=1}^K y\\_{ij} \\|\\mathbf{x}\\_i - \\mathbf{m}\\_j\\|\\_2^2 \\] Trong đó \\( \\mathbf{Y} = [\\mathbf{y}\\_1; \\mathbf{y}\\_2; \\dots; \\mathbf{y}\\_N]\\), \\( \\mathbf{M} = [\\mathbf{m}\\_1, \\mathbf{m}\\_2, \\dots \\mathbf{m}\\_K] \\) lần lượt là các ma trận được tạo bởi label vector của mỗi điểm dữ liệu và center của mỗi cluster. Hàm số mất mát trong bài toán K-means clustering của chúng ta là hàm \\(\\mathcal{L}(\\mathbf{Y}, \\mathbf{M})\\) với ràng buộc như được nêu trong phương trình \\((1)\\). Tóm lại, chúng ta cần tối ưu bài toán sau: \\[ \\mathbf{Y}, \\mathbf{M} = \\arg\\min\\_{\\mathbf{Y}, \\mathbf{M}} \\sum\\_{i=1}^N\\sum\\_{j=1}^K y\\_{ij} \\|\\mathbf{x}\\_i - \\mathbf{m}\\_j\\|\\_2^2~~~~~(2) \\] \\[ \\text{subject to:} ~~ y\\_{ij} \\in \\{0, 1\\}~~ \\forall i, j;~~~ \\sum\\_{j = 1}^K y\\_{ij} = 1~~\\forall i \\] (*subject to* nghĩa là *thỏa mãn điều kiện*). **Nhắc lại khái niệm \\(\\arg\\min\\)**: Chúng ta biết ký hiệu \\(\\min\\) là *giá trị nhỏ nhất của hàm số*, \\(\\arg\\min\\) chính là *giá trị của biến số để hàm số đó đạt giá trị nhỏ nhất đó*. Nếu \\(f(x) = x^2 -2x + 1 = (x-1)^2 \\) thì giá trị nhỏ nhất của hàm số này bằng 0, đạt được khi \\(x = 1\\). Trong ví dụ này \\(\\min\\_{x} f(x) = 0\\) và \\(\\arg\\min\\_{x} f(x) = 1\\). Thêm ví dụ khác, nếu \\(x\\_1 = 0, x\\_2 = 10, x\\_3 = 5\\) thì ta nói \\(\\arg\\min\\_{i} x\\_i = 1\\) vì \\(1\\) là chỉ số để \\(x\\_i\\) đạt giá trị nhỏ nhất (bằng \\(0\\)). Biến số viết bên dưới \\(\\min\\) là biến số cúng ta cần tối ưu. Trong các bài toán tối ưu, ta thường quan tâm tới \\(\\arg\\min\\) hơn là \\(\\min\\).",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-6",
        "source": "43.main.md",
        "section": "Thuật toán tối ưu hàm mất mát",
        "content": "Bài toán \\((2)\\) là một bài toán khó tìm *điểm tối ưu* vì nó có thêm các điều kiện ràng buộc. *Bài toán này thuộc loại mix-integer programming (điều kiện biến là số nguyên) - là loại rất khó tìm nghiệm tối ưu toàn cục (global optimal point, tức nghiệm làm cho hàm mất mát đạt giá trị nhỏ nhất có thể).* Tuy nhiên, trong một số trường hợp chúng ta vẫn có thể tìm được phương pháp để tìm được nghiệm gần đúng hoặc điểm cực tiểu. (*Nếu chúng ta vẫn nhớ chương trình toán ôn thi đại học thì điểm cực tiểu chưa chắc đã phải là điểm làm cho hàm số đạt giá trị nhỏ nhất*). Một cách đơn giản để giải bài toán \\((2)\\) là xen kẽ giải \\(\\mathbf{Y}\\) và \\( \\mathbf{M}\\) khi biến còn lại được cố định. Đây là một thuật toán lặp, cũng là kỹ thuật phổ biến khi giải bài toán tối ưu. Chúng ta sẽ lần lượt giải quyết hai bài toán sau đây:",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-7",
        "source": "43.main.md",
        "section": "Cố định \\(\\mathbf{M} \\), tìm \\(\\mathbf{Y}\\)",
        "content": "**Giả sử đã tìm được các centers, hãy tìm các label vector để hàm mất mát đạt giá trị nhỏ nhất.** Điều này tương đương với việc tìm cluster cho mỗi điểm dữ liệu. Khi các centers là cố định, bài toán tìm label vector cho toàn bộ dữ liệu có thể được chia nhỏ thành bài toán tìm label vector cho từng điểm dữ liệu \\(\\mathbf{x}\\_i\\) như sau: \\[ \\mathbf{y}\\_i = \\arg\\min\\_{\\mathbf{y}\\_i} \\sum\\_{j=1}^K y\\_{ij}\\|\\mathbf{x}\\_i - \\mathbf{m}\\_j\\|\\_2^2 ~~~ (3) \\] \\[ \\text{subject to:} ~~ y\\_{ij} \\in \\{0, 1\\}~~ \\forall j;~~~ \\sum\\_{j = 1}^K y\\_{ij} = 1 \\] Vì chỉ có một phần tử của label vector \\(\\mathbf{y}\\_i\\) bằng \\(1\\) nên bài toán \\((3)\\) có thể tiếp tục được viết dưới dạng đơn giản hơn: \\[ j = \\arg\\min\\_{j} \\|\\mathbf{x}\\_i - \\mathbf{m}\\_j\\|\\_2^2 \\] Vì \\(\\|\\mathbf{x}\\_i - \\mathbf{m}\\_j\\|\\_2^2\\) chính là bình phương khoảng cách tính từ điểm \\(\\mathbf{x}\\_i \\) tới center \\(\\mathbf{m}\\_j \\), ta có thể kết luận rằng **mỗi điểm \\(\\mathbf{x}\\_i \\) thuộc vào cluster có center gần nó nhất**! Từ đó ta có thể dễ dàng suy ra label vector của từng điểm dữ liệu.",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-8",
        "source": "43.main.md",
        "section": "Cố định \\(\\mathbf{Y} \\), tìm \\(\\mathbf{M}\\)",
        "content": "**Giả sử đã tìm được cluster cho từng điểm, hãy tìm center mới cho mỗi cluster để hàm mất mát đạt giá trị nhỏ nhất.** Một khi chúng ta đã xác định được label vector cho từng điểm dữ liệu, bài toán tìm center cho mỗi cluster được rút gọn thành: \\[ \\mathbf{m}\\_j = \\arg\\min\\_{\\mathbf{m}\\_j} \\sum\\_{i = 1}^{N} y\\_{ij}\\|\\mathbf{x}\\_i - \\mathbf{m}\\_j \\|\\_2^2. \\] Tới đây, ta có thể tìm nghiệm bằng phương pháp giải đạo hàm bằng 0, vì hàm cần tối ưu là một hàm liên tục và có đạo hàm xác định tại mọi điểm. *Và quan trọng hơn, hàm này là hàm convex (lồi) theo \\(\\mathbf{m}\\_j \\) nên chúng ta sẽ tìm được giá trị nhỏ nhất và điểm tối ưu tương ứng. Sau này nếu có dịp, tôi sẽ nói thêm về tối ưu lồi (convex optimization) - một mảng cực kỳ quan trọng trong toán tối ưu*. Đặt \\(l(\\mathbf{m}\\_j)\\) là hàm bên trong dấu \\(\\arg\\min\\), ta có đạo hàm: \\[ \\frac{\\partial l(\\mathbf{m}\\_j)}{\\partial \\mathbf{m}\\_j} = 2\\sum\\_{i=1}^N y\\_{ij}(\\mathbf{m}\\_j - \\mathbf{x}\\_i) \\] Giải phương trình đạo hàm bằng 0 ta có: \\[ \\mathbf{m}\\_j \\sum\\_{i=1}^N y\\_{ij} = \\sum\\_{i=1}^N y\\_{ij} \\mathbf{x}\\_i \\] \\[ \\Rightarrow \\mathbf{m}\\_j = \\frac{ \\sum\\_{i=1}^N y\\_{ij} \\mathbf{x}\\_i}{\\sum\\_{i=1}^N y\\_{ij}} \\] Nếu để ý một chút, chúng ta sẽ thấy rằng mẫu số chính là phép đếm *số lượng các điểm dữ liệu* trong cluster \\(j\\) (*Bạn có nhận ra không?*). Còn tử số chính là *tổng các điểm dữ liệu* trong cluster \\(j\\). (*Nếu bạn đọc vẫn nhớ điều kiện ràng buộc của các* \\(y\\_{ij} \\) *thì sẽ có thể nhanh chóng nhìn ra điều này*). Hay nói một cách đơn giản hơn nhiều: \\(\\mathbf{m}\\_j\\) **là trung bình cộng của các điểm trong cluster** \\(j\\). Tên gọi *K-means clustering* cũng xuất phát từ đây.",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-9",
        "source": "43.main.md",
        "section": "Tóm tắt thuật toán",
        "content": "Tới đây tôi xin được tóm tắt lại thuật toán (*đặc biệt quan trọng với các bạn bỏ qua phần toán học bên trên*) như sau: **Đầu vào:** Dữ liệu \\(\\mathbf{X}\\) và số lượng cluster cần tìm \\(K\\). **Đầu ra:** Các center \\(\\mathbf{M}\\) và label vector cho từng điểm dữ liệu \\(\\mathbf{Y}\\). 1. Chọn \\(K\\) điểm bất kỳ làm các center ban đầu. 2. Phân mỗi điểm dữ liệu vào cluster có center gần nó nhất. 3. Nếu việc gán dữ liệu vào từng cluster ở bước 2 không thay đổi so với vòng lặp trước nó thì ta dừng thuật toán. 4. Cập nhật center cho từng cluster bằng cách lấy trung bình cộng của tất các các điểm dữ liệu đã được gán vào cluster đó sau bước 2. 5. Quay lại bước 2. Chúng ta có thể đảm bảo rằng thuật toán sẽ dừng lại sau một số hữu hạn vòng lặp. Thật vậy, vì hàm mất mát là một số dương và sau mỗi bước 2 hoặc 3, giá trị của hàm mất mát bị giảm đi. Theo kiến thức về dãy số trong chương trình cấp 3: *nếu một dãy số giảm và bị chặn dưới thì nó hội tụ!* Hơn nữa, số lượng cách phân nhóm cho toàn bộ dữ liệu là hữu hạn nên đến một lúc nào đó, hàm mất mát sẽ không thể thay đổi, và chúng ta có thể dừng thuật toán tại đây. Chúng ta sẽ có một vài [thảo luận](#-thao-luan) về thuật toán này, về những hạn chế và một số phương pháp khắc phục. Nhưng trước hết, hãy xem nó thể hiện như thế nào trong một ví dụ cụ thể dưới đây.",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-10",
        "source": "43.main.md",
        "section": "Giới thiệu bài toán",
        "content": "Để kiểm tra mức độ hiểu quả của một thuật toán, chúng ta sẽ làm một ví dụ đơn giản (thường được gọi là *toy example*). Trước hết, chúng ta chọn center cho từng cluster và tạo dữ liệu cho từng cluster bằng cách lấy mẫu theo phân phối chuẩn có kỳ vọng là center của cluster đó và ma trận hiệp phương sai (covariance matrix) là ma trận đơn vị. Trước tiên, chúng ta cần khai báo các thư viện cần dùng. Chúng ta cần `numpy` và `matplotlib` như trong bài [Linear Regression](/2016/12/28/linearregression/) cho việc tính toán ma trận và hiển thị dữ liệu. Chúng ta cũng cần thêm thư viện `scipy.spatial.distance` để tính khoảng cách giữa các cặp điểm trong hai tập hợp một cách hiệu quả. ``` from __future__ import print_function import numpy as np import matplotlib.pyplot as plt from scipy.spatial.distance import cdist np.random.seed(11) ``` Tiếp theo, ta tạo dữ liệu bằng cách lấy các điểm theo phân phối chuẩn có kỳ vọng tại các điểm có tọa độ `(2, 2), (8, 3)` và `(3, 6)`, ma trận hiệp phương sai giống nhau và là ma trận đơn vị. Mỗi cluster có 500 điểm. (*Chú ý rằng mỗi điểm dữ liệu là một hàng của ma trận dữ liệu.* ``` means = [[2, 2], [8, 3], [3, 6]] cov = [[1, 0], [0, 1]] N = 500 X0 = np.random.multivariate_normal(means[0], cov, N) X1 = np.random.multivariate_normal(means[1], cov, N) X2 = np.random.multivariate_normal(means[2], cov, N) X = np.concatenate((X0, X1, X2), axis = 0) K = 3 original_label = np.asarray([0]*N + [1]*N + [2]*N).T ```",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-11",
        "source": "43.main.md",
        "section": "Hiển thị dữ liệu trên đồ thị",
        "content": "Chúng ta cần một hàm `kmeans_display` để hiển thị dữ liệu. Sau đó hiển thị dữ liệu theo nhãn ban đầu. ``` def kmeans_display(X, label): K = np.amax(label) + 1 X0 = X[label == 0, :] X1 = X[label == 1, :] X2 = X[label == 2, :] plt.plot(X0[:, 0], X0[:, 1], 'b^', markersize = 4, alpha = .8) plt.plot(X1[:, 0], X1[:, 1], 'go', markersize = 4, alpha = .8) plt.plot(X2[:, 0], X2[:, 1], 'rs', markersize = 4, alpha = .8) plt.axis('equal') plt.plot() plt.show() kmeans_display(X, original_label) ``` ![](/assets/kmeans/output_5_0.png) Trong đồ thị trên, mỗi cluster tương ứng với một màu. Có thể nhận thấy rằng có một vài điểm màu đỏ bị lẫn sang phần cluster màu xanh.",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-12",
        "source": "43.main.md",
        "section": "Các hàm số cần thiết cho K-means clustering",
        "content": "Viết các hàm: 1. `kmeans_init_centers` để khởi tạo các centers ban đầu. 2. `kmeans_asign_labels` để gán nhán mới cho các điểm khi biết các centers. 3. `kmeans_update_centers` để cập nhật các centers mới dữa trên dữ liệu vừa được gán nhãn. 4. `has_converged` để kiểm tra điều kiện dừng của thuật toán. ``` def kmeans_init_centers(X, k):",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-13",
        "source": "43.main.md",
        "section": "randomly pick k rows of X as initial centers",
        "content": "return X[np.random.choice(X.shape[0], k, replace=False)] def kmeans_assign_labels(X, centers):",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-14",
        "source": "43.main.md",
        "section": "calculate pairwise distances btw data and centers",
        "content": "D = cdist(X, centers)",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-15",
        "source": "43.main.md",
        "section": "return index of the closest center",
        "content": "return np.argmin(D, axis = 1) def kmeans_update_centers(X, labels, K): centers = np.zeros((K, X.shape[1])) for k in range(K):",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-16",
        "source": "43.main.md",
        "section": "collect all points assigned to the k-th cluster",
        "content": "Xk = X[labels == k, :]",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-17",
        "source": "43.main.md",
        "section": "take average",
        "content": "centers[k,:] = np.mean(Xk, axis = 0) return centers def has_converged(centers, new_centers):",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-18",
        "source": "43.main.md",
        "section": "return True if two sets of centers are the same",
        "content": "return (set([tuple(a) for a in centers]) == set([tuple(a) for a in new_centers])) ``` Phần chính của K-means clustering: ``` def kmeans(X, K): centers = [kmeans_init_centers(X, K)] labels = [] it = 0 while True: labels.append(kmeans_assign_labels(X, centers[-1])) new_centers = kmeans_update_centers(X, labels[-1], K) if has_converged(centers[-1], new_centers): break centers.append(new_centers) it += 1 return (centers, labels, it) ``` Áp dụng thuật toán vừa viết vào dữ liệu ban đầu, hiển thị kết quả cuối cùng. ``` (centers, labels, it) = kmeans(X, K) print('Centers found by our algorithm:') print(centers[-1]) kmeans_display(X, labels[-1]) ``` ``` Centers found by our algorithm: [[ 1.97563391  2.01568065] [ 8.03643517  3.02468432] [ 2.99084705  6.04196062]] ``` ![](/assets/kmeans/output_11_1.png) Từ kết quả này chúng ta thấy rằng thuật toán K-means clustering làm việc khá thành công, các centers tìm được khá gần với kỳ vọng ban đầu. Các điểm thuộc cùng một cluster hầu như được phân vào cùng một cluster (trừ một số điểm màu đỏ ban đầu đã bị phân nhầm vào cluster màu xanh da trời, nhưng tỉ lệ là nhỏ và có thể chấp nhận được). Dưới đây là hình ảnh động minh họa thuật toán qua từng vòng lặp, chúng ta thấy rằng thuật toán trên hội tụ rất nhanh, chỉ cần 6 vòng lặp để có được kết quả cuối cùng: ![](/assets/kmeans/kmeans11.gif) Các bạn có thể xem thêm các trang web minh họa thuật toán K-means cluster tại: 1. [Visualizing K-Means Clustering](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/) 2. [Visualizing K-Means Clustering - Standford](http://stanford.edu/class/ee103/visualizations/kmeans/kmeans.html)",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-19",
        "source": "43.main.md",
        "section": "Kết quả tìm được bằng thư viện scikit-learn",
        "content": "Để kiểm tra thêm, chúng ta hãy so sánh kết quả trên với kết quả thu được bằng cách sử dụng thư viện [`scikit-learn`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). ``` from sklearn.cluster import KMeans kmeans = KMeans(n_clusters=3, random_state=0).fit(X) print('Centers found by scikit-learn:') print(kmeans.cluster_centers_) pred_label = kmeans.predict(X) kmeans_display(X, pred_label) ``` ``` Centers found by scikit-learn: [[ 8.0410628   3.02094748] [ 2.99357611  6.03605255] [ 1.97634981  2.01123694]] ``` ![](/assets/kmeans/output_14_1.png) Thật may mắn (*cho tôi*), hai thuật toán cho cùng một đáp số! Với cách thứ nhất, tôi mong muốn các bạn hiểu rõ được thuật toán K-means clustering làm việc như thế nào. Với cách thứ hai, tôi hy vọng các bạn biết áp dụng thư viện sẵn có như thế nào.",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-20",
        "source": "43.main.md",
        "section": "Hạn chế",
        "content": "Có một vài hạn chế của thuật toán K-means clustering:",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-21",
        "source": "43.main.md",
        "section": "Chúng ta cần biết số lượng cluster cần clustering",
        "content": "Để ý thấy rằng trong [thuật toán nêu trên](#tom-tat-thuat-toan), chúng ta cần biết đại lượng \\(K\\) là số lượng clusters. Trong thực tế, nhiều trường hợp chúng ta không xác định được giá trị này. Có một số phương pháp giúp xác định số lượng clusters, tôi sẽ dành thời gian nói về chúng sau nếu có dịp. Bạn đọc có thể tham khảo [Elbow method - Determining the number of clusters in a data set](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set).",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-22",
        "source": "43.main.md",
        "section": "Nghiệm cuối cùng phụ thuộc vào các centers được khởi tạo ban đầu",
        "content": "Tùy vào các center ban đầu mà thuật toán có thể có tốc độ hội tụ rất chậm, ví dụ: ![](/assets/kmeans/kmeans_slowconverge.gif) hoặc thậm chí cho chúng ta nghiệm không chính xác (chỉ là local minimum - điểm cực tiểu - mà không phải giá trị nhỏ nhất): ![](/assets/kmeans/kmeans_badresult.gif) Có một vài cách khắc phục đó là: * Chạy K-means clustering nhiều lần với các center ban đầu khác nhau rồi chọn cách có hàm mất mát cuối cùng đạt giá trị nhỏ nhất. * [K-means++ -Improve initialization algorithm - wiki](https://en.wikipedia.org/wiki/K-means%2B%2B#Improved_initialization_algorithm). * Bạn nào muốn tìm hiểu sâu hơn có thể xem bài báo khoa học [Cluster center initialization algorithm for K-means clustering](http://www.sciencedirect.com/science/article/pii/S0167865504000996).",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-23",
        "source": "43.main.md",
        "section": "Các cluster cần có só lượng điểm gần bằng nhau",
        "content": "Dưới đây là một ví dụ với 3 cluster với 20, 50, và 1000 điểm. Kết quả cuối cùng không chính xác. ![](/assets/kmeans/kmeans_unbalanced.gif)",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-24",
        "source": "43.main.md",
        "section": "Các cluster cần có dạng hình tròn",
        "content": "Tức các cluster tuân theo phân phối chuẩn và ma trận hiệp phương sai là ma trận đường chéo có các điểm trên đường chéo giống nhau. Dưới đây là 1 ví dụ khi 1 cluster có dạng hình dẹt. ![](/assets/kmeans/kmeans_diffcov.gif)",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-25",
        "source": "43.main.md",
        "section": "Khi một cluster nằm phía trong 1 cluster khác",
        "content": "Đây là ví dụ kinh điển về việc K-means clustering không thể phân cụm dữ liệu. Một cách tự nhiên, chúng ta sẽ phân ra thành 4 cụm: mắt trái, mắt phải, miệng, xung quanh mặt. Nhưng vì mắt và miệng nằm trong khuôn mặt nên K-means clustering không thực hiện được: ![](/assets/kmeans/smile_face.png) Mặc dù có những hạn chế, K-means clustering vẫn cực kỳ quan trọng trong Machine Learning và là nền tảng cho nhiều thuật toán phức tạp khác sau này. Chúng ta cần bắt đầu từ những thứ đơn giản. *Simple is best!*",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "43.main-26",
        "source": "43.main.md",
        "section": "5. Tài liệu tham khảo",
        "content": "[Clustering documents using k-means](http://scikit-learn.org/stable/auto_examples/text/document_clustering.html) [Voronoi Diagram - Wikipedia](https://en.wikipedia.org/wiki/Voronoi_diagram) [Cluster center initialization algorithm for K-means clustering](http://www.sciencedirect.com/science/article/pii/S0167865504000996) [Visualizing K-Means Clustering](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/) [Visualizing K-Means Clustering - Standford](http://stanford.edu/class/ee103/visualizations/kmeans/kmeans.html)",
        "url": "https://machinelearningcoban.com/2017/01/01/kmeans/"
    },
    {
        "id": "21.main-1",
        "source": "21.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Một chút về Đại số tuyến tính](#-mot-chut-ve-dai-so-tuyen-tinh) + [2.1. Trị riêng và vector riêng](#-tri-rieng-va-vector-rieng) + [2.2. Hệ trực giao và trực chuẩn](#-he-truc-giao-va-truc-chuan) * [3. Singular Value Decomposition](#-singular-value-decomposition) + [3.1. Phát biểu SVD](#-phat-bieu-svd) + [3.2. Nguồn gốc tên gọi Singular Value Decomposition](#-nguon-goc-ten-goi-singular-value-decomposition) + [3.3. Compact SVD](#-compact-svd) + [3.4. Truncated SVD](#-truncated-svd) + [3.5. Best Rank \\(k\\) Approximation](#-best-rank-\\\\k\\\\-approximation) * [4. Một vài ứng dụng của SVD](#-mot-vai-ung-dung-cua-svd) + [4.1. Image Compression](#-image-compression) + [4.2. Truncated SVD cho Recommendation System](#-truncated-svd-cho-recommendation-system) * [5. Thảo luận](#-thao-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/06/07/svd/"
    },
    {
        "id": "21.main-2",
        "source": "21.main.md",
        "section": "1. Giới thiệu",
        "content": "Hẳn các bạn vẫn nhớ một loại bài toán được làm rất nhiều khi học Đại số tuyến tính: Bài toán chéo hoá ma trận. Bài toán đó nói rằng: Một ma trận vuông \\(\\mathbf{A} \\in \\mathbb{R}^{n\\times n}\\) được gọi là *chéo hoá được* (diagonalizable) nếu tồn tại ma trận đường chéo \\(\\mathbf{D}\\) và ma trận khả nghịch \\(\\mathbf{P}\\) sao cho: \\[ \\mathbf{A} = \\mathbf{P} \\mathbf{D} \\mathbf{P}^{-1}~~~~(1) \\] Số lượng phần tử khác 0 của ma trận đường chéo \\(\\mathbf{D}\\) chính là rank của ma trận \\(\\mathbf{A}\\). Nhân cả hai vế của \\((1)\\) với \\(\\mathbf{P}\\) ta có: \\[ \\mathbf{AP} = \\mathbf{PD}~~~~(2) \\] Gọi \\(\\mathbf{p}\\_i, \\mathbf{d}\\_i\\) lần lượt là cột thứ \\(i\\) của ma trận \\(\\mathbf{P}\\) và \\(\\mathbf{D}\\). Vì mỗi một cột của vế trái và vế phải của \\((2)\\) phải bằng nhau, ta sẽ có: \\[ \\mathbf{Ap}\\_i = \\mathbf{Pd}\\_i = d\\_{ii}\\mathbf{p}\\_i ~~~~ (3) \\] với \\(d\\_{ii}\\) là phần tử thứ \\(i\\) của \\(\\mathbf{p}\\_i\\). Dấu bằng thứ hai xảy ra vì \\(\\mathbf{D}\\) là ma trận đường chéo, tức \\(\\mathbf{d}\\_i\\) chỉ có thành phần \\(d\\_{ii}\\) là khác 0. Và nếu bạn vẫn nhớ, biểu thức \\((3)\\) chỉ ra rằng mỗi phần tử \\(d\\_{ii}\\) phải là một *trị riêng* (eigenvalue) của \\(\\mathbf{A}\\) và mỗi vector cột \\(\\mathbf{p}\\_i\\) phải là một *vector riêng* (eigenvector) của \\(\\mathbf{A}\\) ứng với trị riêng \\(d\\_{ii}\\). Cách phân tích một ma trận vuông thành nhân tử như \\((1)\\) còn được gọi là *Eigen Decomposition*. Một điểm quan trọng là cách phân tích như \\((1)\\) chỉ được áp dụng với ma trận vuông và không phải lúc nào cũng tồn tại. Nó chỉ tồn tại nếu ma trận \\(\\mathbf{A}\\) có \\(n\\) vector riêng độc lập tuyến tính, vì nếu không thì không tồn tại ma trận \\(\\mathbf{P}\\) khả nghịch. Thêm nữa, cách phân tích này cũng không phải là duy nhất vì nếu \\(\\mathbf{P}, \\mathbf{D}\\) thoả mãn \\((1)\\) thì \\(k\\mathbf{P}, \\mathbf{D}\\) cũng thoả mãn với \\(k\\) là một số thực khác 0 bất kỳ. Việc phân tích một ma trận ra thành tích của nhiều ma trận đặc biệt khác (Matrix Factorization hoặc Matrix Decomposition) mang lại nhiều ích lợi quan trọng mà các bạn sẽ thấy: giảm số chiều dữ liệu, nén dữ liệu, tìm hiểu các đặc tính của dữ liệu, giải các hệ phương trình tuyến tính, clustering, và nhiều ứng dụng khác. [Recommendation System cũng là một trong rất nhiều ứng dụng của Matrix Factorization](/2017/05/31/matrixfactorization/). Trong bài viết này, tôi sẽ giới thiệu với các bạn một trong những phương pháp Matrix Factorization rất đẹp của Đại số tuyến tính. Phương pháp đó có tên là Singular Value Decomposition (SVD). Các bạn sẽ thấy, mọi ma trận, không nhất thiết là vuông, đều có thể được phân tích thành tích của ba ma trận đặc biệt. Dưới đây, tôi sẽ phát biểu SVD cũng như các tính chất và ứng dụng điển hình của nó. Trước hết, chúng ta cần ôn tập lại một chút về Đại số tuyến tính. **Chú ý rằng các ma trận trong bài viết này đều được ngầm giả sử là ma trận thực**.",
        "url": "https://machinelearningcoban.com/2017/06/07/svd/"
    },
    {
        "id": "21.main-3",
        "source": "21.main.md",
        "section": "2.1. Trị riêng và vector riêng",
        "content": "Cho một ma trận vuông \\(\\mathbf{A} \\in \\mathbb{R}^{n\\times n}\\), nếu số vô hướng \\(\\lambda\\) và vector \\(\\mathbf{x} \\neq \\mathbf{0} \\in \\mathbb{R}^n\\) thoả mãn: \\[ \\mathbf{Ax} = \\lambda \\mathbf{x} \\] thì \\(\\lambda\\) được gọi là một trị riêng của \\(\\mathbf{A}\\) và \\(\\mathbf{x}\\) được gọi là vector riêng tương ứng với trị riêng đó. Một vài tính chất: 1. Nếu \\(\\mathbf{x}\\) là một vector riêng của \\(\\mathbf{A}\\) ứng với \\(\\lambda\\) thì \\(k\\mathbf{x}, k \\neq 0\\) cũng là vector riêng ứng với trị riêng đó. 2. Mọi ma trận vuông bậc \\(n\\) đều có \\(n\\) trị riêng (kể cả lặp) và có thể là các số phức. 3. Với ma trận đối xứng, tất cả các trị riêng đều là các số thực. 4. Với [*ma trận xác định dương*](/2017/03/12/convexity/#positive-semidefinite), tất cả các trị riêng của nó đều là các số thực dương. Với *ma trận nửa xác định dương*, tất cả các trị riêng của nó đều là các số thực không âm. Tính chất cuối cùng có thể được suy ra từ định nghĩa của ma trận (nửa) xác định dương. Thật vậy, gọi \\(\\mathbf{u} \\neq \\mathbf{0}\\) là vector riêng ứng với một trị riêng \\(\\lambda\\) của ma trận \\(\\mathbf{A}\\) xác định dương, ta có: \\[ \\mathbf{Au} = \\lambda \\mathbf{u} \\Rightarrow \\mathbf{u}^T\\mathbf{Au} = \\lambda \\mathbf{u}^T\\mathbf{u} = \\lambda ||\\mathbf{u}||\\_2^2 \\] Vì \\(\\mathbf{A}\\) là nửa xác định dương nên với mọi \\(\\mathbf{u} \\neq \\mathbf{0}\\): \\(\\mathbf{u}^T\\mathbf{Au} \\geq 0\\); \\(\\mathbf{u} \\neq 0\\) nên \\(||\\mathbf{u}||\\_2^2 > 0\\). Từ đó suy ra \\(\\lambda\\) là một số không âm.",
        "url": "https://machinelearningcoban.com/2017/06/07/svd/"
    },
    {
        "id": "21.main-4",
        "source": "21.main.md",
        "section": "2.2. Hệ trực giao và trực chuẩn",
        "content": "Một hệ cơ sở \\({\\mathbf{u}\\_1, \\mathbf{u}\\_2,\\dots, \\mathbf{u}\\_m \\in \\mathbb{R}^m}\\) được gọi là *trực giao* (orthogonal) nếu mỗi vector là khác 0 và tích của hai vector khác nhau bất kỳ bằng 0: \\[ \\mathbf{u}\\_i \\neq \\mathbf{0}; ~~ \\mathbf{u}\\_i^T \\mathbf{u}\\_j = 0 ~ \\forall ~1 \\leq i \\neq j \\leq m \\] Một hệ cơ sở \\({\\mathbf{u}\\_1, \\mathbf{u}\\_2,\\dots, \\mathbf{u}\\_m \\in \\mathbb{R}^m}\\) được gọi là *trực chuẩn* (orthonormal) nếu nó là một hệ *trực giao* và độ dài Euclidean (norm 2) của mỗi vector bằng 1: \\[ \\begin{eqnarray} \\mathbf{u}\\_i^T \\mathbf{u}\\_j = \\left\\{ \\begin{matrix} 1 & \\text{if} &i = j \\newline 0 & \\text{otherwise} \\end{matrix} \\right. ~~~~ (4) \\end{eqnarray} \\] Gọi \\(\\mathbf{U} = [\\mathbf{u}\\_1, \\mathbf{u}\\_2,\\dots, \\mathbf{u}\\_m]\\) với \\({\\mathbf{u}\\_1, \\mathbf{u}\\_2,\\dots, \\mathbf{u}\\_m \\in \\mathbb{R}^m}\\) là *trực chuẩn*, thế thì từ \\((4)\\) có thể suy ra ngay: \\[ \\mathbf{UU}^T = \\mathbf{U}^T\\mathbf{U} = \\mathbf{I} \\] trong đó \\(\\mathbf{I}\\) là ma trận đơn vị bậc \\(m\\). Ta gọi \\(\\mathbf{U}\\) là *ma trận trực giao* (orthogonal matrix). *Ma trận loại này không được gọi là ma trận trực chuẩn, không có định nghĩa cho ma trận trực chuẩn.* Một vài tính chất: 1. \\(\\mathbf{U}^{-1} = \\mathbf{U}^T\\): nghịch đảo của một ma trận trực giao chính là chuyển vị của nó. 2. Nếu \\(\\mathbf{U}\\) là ma trận trực giao thì chuyển vị của nó \\(\\mathbf{U}^T\\) cũng là một ma trận trực giao. 3. Định thức (determinant) của ma trận trực giao bằng \\(1\\) hoặc \\(-1\\). Điều này có thể suy ra từ việc \\(\\det(\\mathbf{U}) = \\det(\\mathbf{U}^T)\\) và \\(\\det(\\mathbf{U}) \\det(\\mathbf{U}^T) = \\det(\\mathbf{I}) = 1\\). 4. Ma trận trực giao thể hiện cho phép xoay (rotate) một vector. Giả sử có hai vector \\(\\mathbf{x,y} \\in \\mathbb{R}^m\\) và ma trận trực giao \\(\\mathbf{U} \\in \\mathbb{R}^{m \\times m}\\). Dùng ma trận này để xoay hai vector trên ta được \\(\\mathbf{Ux}, \\mathbf{Uy}\\). Tích vô hướng của hai vector mới là: \\[ (\\mathbf{Ux})^T (\\mathbf{Uy}) = \\mathbf{x}^T \\mathbf{U}^T \\mathbf{Uy} = \\mathbf{x}^T\\mathbf{y} \\] như vậy *phép xoay không làm thay đổi tích vô hướng giữa hai vector*. 5. Giả sử \\(\\hat{\\mathbf{U}} \\in \\mathbb{R}^{m \\times r}, r < m\\) là môt ma trận con của ma trận trực giao \\(\\mathbf{U}\\) được tạo bởi \\(r\\) cột của \\(\\mathbf{U}\\), ta sẽ có \\(\\hat{\\mathbf{U}}^T\\hat{\\mathbf{U}} = \\mathbf{I}\\_{r}\\). Việc này có thể được suy ra từ \\((4)\\).",
        "url": "https://machinelearningcoban.com/2017/06/07/svd/"
    },
    {
        "id": "21.main-5",
        "source": "21.main.md",
        "section": "3. Singular Value Decomposition",
        "content": "Vì trong mục này cần nắm vững chiều của mỗi ma trận nên tôi sẽ thay đổi ký hiệu một chút để chúng ta dễ hình dung. Ta sẽ ký hiệu một ma trận cùng với số chiều của nó, ví dụ \\(\\mathbf{A}\\_{m \\times n}\\) nghĩa là ma trận \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\).",
        "url": "https://machinelearningcoban.com/2017/06/07/svd/"
    },
    {
        "id": "21.main-6",
        "source": "21.main.md",
        "section": "3.1. Phát biểu SVD",
        "content": "--- Một ma trận \\(\\mathbf{A}\\_{m \\times n}\\) bất kỳ đều có thể phân tích thành dạng: \\[ \\mathbf{A}\\_{m \\times n} = \\mathbf{U}\\_{m \\times m}\\mathbf{\\Sigma}\\_{m \\times n} (\\mathbf{V}\\_{n \\times n})^T ~~~~ (5) \\] Trong đó, \\(\\mathbf{U}, \\mathbf{V}\\) là các *ma trận trực giao*, \\(\\mathbf{\\Sigma}\\) là ma trận *đường chéo không vuông* với các phần tử trên đường chéo \\(\\sigma\\_1 \\geq \\sigma\\_2 \\geq \\dots \\geq\\sigma\\_r \\geq 0 = 0 = \\dots = 0\\) và \\(r\\) là rank của ma trận \\(\\mathbf{A}\\). Lưu ý rằng mặc dù \\(\\Sigma\\) không phải ma trận vuông, ta vẫn có thể coi nó là ma trận chéo nếu các thành phần khác không của nó chỉ nằm ở vị trí *đường chéo*, tức tại các vị trí có chỉ số hàng và chỉ số cột là như nhau. Số lượng các phần tử khác 0 trong \\(\\Sigma\\) chính là rank của ma trận \\(\\mathbf{A}\\). ---",
        "url": "https://machinelearningcoban.com/2017/06/07/svd/"
    },
    {
        "id": "31.main-1",
        "source": "31.main.md",
        "section": "Introduction",
        "content": "Bài này có khá nhiều khái niệm mới, mong bạn đọc thông cảm khi tôi sử dụng các khái niệm này ở cả tiếng Anh và tiếng Việt. *Bài chủ yếu nói về toán, nếu bạn đọc không hiểu ngay cũng không sao, ngày đầu tôi làm quen với những khái niệm này cũng không thể hấp thụ được ngay. Làm nhiều, đọc nhiều rồi sẽ ngấm dần.* Bạn đọc có thể xem bản pdf [tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/latex/book_CVX.pdf). * [1. Giới thiệu](#-gioi-thieu) * [2. Convex sets](#-convex-sets) + [2.1. Định nghĩa](#-dinh-nghia) + [2.2. Ví dụ](#-vi-du) - [2.2.1. Hyperplanes và halfspaces](#-hyperplanes-va-halfspaces) - [2.2.2. Norm balls](#-norm-balls) + [2.3. Giao của các tập lồi là một tập lồi.](#-giao-cua-cac-tap-loi-la-mot-tap-loi) + [2.4. Convex combination và Convex hulls](#-convex-combination-va-convex-hulls) * [3. Convex functions](#-convex-functions) + [3.1. Định nghĩa](#-dinh-nghia-1) + [3.2. Các tính chất cơ bản](#-cac-tinh-chat-co-ban) + [3.3. Ví dụ](#-vi-du-1) - [3.3.1. Các hàm một biến](#-cac-ham-mot-bien) - [3.3.3. Affine functions](#-affine-functions) - [3.3.3. Quadratic forms](#-quadratic-forms) - [3.3.4. Norms](#-norms) + [3.4. \\(\\alpha-\\) sublevel sets](#-\\\\\\alpha-\\\\-sublevel-sets) + [3.5. Kiểm tra tính chất lồi dựa vào đạo hàm.](#-kiem-tra-tinh-chat-loi-dua-vao-dao-ham) - [3.5.1. First-order condition](#-first-order-condition) - [3.5.2. Second-order condition](#-second-order-condition) * [4. Tóm tắt](#-tom-tat) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/03/12/convexity/"
    },
    {
        "id": "31.main-2",
        "source": "31.main.md",
        "section": "1. Giới thiệu",
        "content": "Từ đầu đến giờ, chúng ta đã làm quen với rất nhiều bài toán tối ưu. Học Machine Learning là phải học Toán Tối Ưu, và để hiểu hơn về Toán Tối Ưu, với tôi cách tốt nhất là tìm hiểu các thuật toán Machine Learning. Cho tới lúc này, những bài toán tối ưu các bạn đã nhìn thấy trong blog đều là các bài toán tối ưu không ràng buộc (unconstrained optimization problems), tức tối ưu hàm mất mát mà không có điều kiện ràng buộc (constraints) nào về nghiệm cả. Không chỉ trong Machine Learning, trên thực tế các bài toán tối ưu thường có rất nhiều ràng buộc khác nhau. Ví dụ: * Tôi muốn thuê một ngôi nhà cách trung tâm Hà Nội không quá 5km với giá càng thấp càng tốt. Trong bài toán này, giá thuê nhà chính là hàm mất mát (*loss function*, đôi khi người ta cũng dùng *cost function* để chỉ hàm số cần tối ưu), điều kiện khoảng cách không quá 5km chính là ràng buộc (constraint). * Quay lại [bài toán dự đoán giá nhà theo Linear Regression](/2016/12/28/linearregression/#-gioi-thieu), giá nhà là một hàm tuyến tính của diện tích, số phòng ngủ và khoảng cách tới trung tâm. Rõ ràng, khi làm bài toán này, ta dự đoán rằng giá nhà tăng theo diện tích và số phòng ngủ, giảm theo khoảng cách. Vậy nên một nghiệm được gọi là *có lý một chút* nếu hệ số tương ứng với diện tích và số phòng ngủ là dương, hệ số tương ứng với khoảng cách là âm. Để tránh các nghiệm ngoại lai không mong muốn, khi giải bài toán tối ưu, ta nên cho thêm các điều kiện ràng buộc này. Trong Tối Ưu, một bài toán có ràng buộc thường được viết dưới dạng: \\[ \\begin{eqnarray} \\mathbf{x}^\\* &=& \\arg\\min\\_{\\mathbf{x}} f\\_0(\\mathbf{x})\\newline \\text{subject to:}~ && f\\_i(\\mathbf{x}) \\leq 0, ~~ i = 1, 2, \\dots, m \\newline && h\\_j(\\mathbf{x}) = 0, ~~ j = 1, 2, \\dots, p \\end{eqnarray} \\] Trong đó, vector \\(\\mathbf{x} = [x\\_1, x\\_2, \\dots, x\\_n]^T\\) được gọi là *biến tối ưu* (*optimization variable*). Hàm số \\(f\\_0: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) được gọi là *hàm mục tiêu* (*objective function*, các hàm mục tiêu trong Machine Learning thường được gọi là *hàm mất mát*). Các hàm số \\(f\\_i, h\\_j: \\mathbb{R}^n \\rightarrow \\mathbb{R}, i = 1, 2, \\dots, m; j = 1, 2, \\dots, p\\) được gọi là các *hàm ràng buộc* (hoặc đơn giản là *ràng buộc* - constraints). Tập hợp các điểm \\(\\mathbf{x}\\) thỏa mãn các *ràng buộc* được gọi là *feasible set*. Mỗi điểm trong *feasible set* được gọi là *feasible point*, các điểm không trong *feasible set* được gọi là *infeasible points*. **Chú ý:** * Nếu bài toán là tìm giá trị lớn nhất thay vì nhỏ nhất, ta chỉ cần đổi dấu của \\(f\\_0(\\mathbf{x})\\). * Nếu ràng buộc là *lớn hơn hoặc bằng*, tức \\(f\\_i(\\mathbf{x}) \\geq b\\_i\\), ta chỉ cần đổi dấu của ràng buộc là sẽ có điều kiện *nhỏ hơn hoặc bằng* \\(-f\\_i(\\mathbf{x}) \\leq -b\\_i\\). * Các ràng buộc cũng có thể là *lớn hơn* hoặc *nhỏ hơn*. * Nếu ràng buộc là *bằng nhau*, tức \\(h\\_j(\\mathbf{x}) = 0\\), ta có thể viết nó dưới dạng hai bất đẳng thức \\(h\\_j(\\mathbf{x}) \\leq 0\\) và \\(-h\\_j(\\mathbf{x}) \\leq 0\\). Trong một vài tài liệu, người ta bỏ các phương trình ràng buộc \\(h\\_j(\\mathbf{x})= 0\\) đi. * Trong bài viết này, \\(\\mathbf{x}, \\mathbf{y}\\) được dùng chủ yếu để ký hiệu các biến số, không phải là dữ liệu như trong các bài trước. Biến tối ưu chính là biến được ghi dưới dấu \\(\\arg \\min\\). Khi viết một bài toán Tối Ưu, ta cần chỉ rõ biến nào cần được tối ưu, biến nào là cố định. Các bài toán tối ưu, nhìn chung không có cách giải tổng quát, thậm chí có những bài chưa có lời giải. Hầu hết các phương pháp tìm nghiệm không chứng minh được nghiệm tìm được có phải là *global optimal* hay không, tức đúng là điểm làm cho hàm số đạt giá trị nhỏ nhất hay lớn nhất hay không. Thay vào đó, nghiệm thường là các *local optimal*, tức các *điểm cực trị*. Để bắt đầu học Tối Ưu, chúng ta cần học một mảng rất quan trọng trong đó, có tên là *Tối Ưu Lồi* (convex optimization), trong đó *hàm mục tiêu* là một *hàm lồi* (convex function), *feasible set* là một *tập lồi* (convex set). Những tính chất đặc biệt về *local optimal* và *global optimal* của một *hàm lồi* khiến Tối Ưu Lồi trở nên cực kỳ quan trọng. Trong bài viết này, tôi sẽ giới thiệu tới các bạn các định nghĩa và tính chất cơ bản của *tập lồi* và *hàm lồi*. *Bài toán tối ưu lồi* (convex optimization problems) sẽ được đề cập trong bài tiếp theo.",
        "url": "https://machinelearningcoban.com/2017/03/12/convexity/"
    },
    {
        "id": "31.main-3",
        "source": "31.main.md",
        "section": "2.1. Định nghĩa",
        "content": "Khái niệm về *convex sets* có lẽ không xa lạ với các bạn học sinh Việt Nam khi chúng ta đã nghe về *đa giác lồi*. *Lồi*, hiểu đơn giản là *phình ra ngoài*, hoặc *nhô ra ngoài*. Trong toán học, *bằng phẳng* cũng được coi là *lồi*. **Định nghĩa 1:** Một tập hợp được gọi là *tập lồi* (convex set) nếu đoạn thẳng nối hai điểm *bất kỳ* trong tập hợp hợp đó nằm trọn vẹn trong tập hợp đó. Một vài ví dụ về convex sets: --- ![](/assets/16_convexity/convexsets.png) Hình 1: Các ví dụ về convex sets. ---",
        "url": "https://machinelearningcoban.com/2017/03/12/convexity/"
    },
    {
        "id": "42.main-1",
        "source": "42.main.md",
        "section": "Introduction",
        "content": "Trong bài này, tôi sẽ áp dụng thuật toán [K-means clustering](/2017/01/01/kmeans/) vào ba bài toán xử lý ảnh thực tế hơn: i) Phân nhóm các chữ số viết tay, ii) Tách vật thể (image segmentation) và iii) Nén ảnh/dữ liệu (image compression). Qua đây, tôi cũng muốn độc giả làm quen với một số kỹ thuật đơn giản trong xử lý hình ảnh - một mảng quan trọng trong Machine Learning. Souce code cho các ví dụ trong trang này có thể được tìm thấy [tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/kmeans/Kmeans2.ipynb). **Cảnh báo:** *bài này không có nhiều toán.* **Trong trang này:** * [1. Phân nhóm chữ số viết tay](#1-phan-nhom-ch-s-vit-tay) + [Bộ cơ sở dữ liệu MNIST](#b-c-s-d-liu-mnist) + [Bài toán phân nhóm giả định](#bai-toan-phan-nhom-gi-nh) + [Làm việc trên Python](#lam-vic-tren-python) * [2. Object Segmentation (tách vật thể trong ảnh)](#2-object-segmentation-tach-vt-th-trong-nh) + [Đặt vấn đề](#t-vn) + [Lên ý tưởng](#len--tng) + [Làm việc trên Python](#lam-vic-tren-python) * [3. Image Compression (nén ảnh và nén dữ liệu nói chung)](#3-image-compression-nen-nh-va-nen-d-liu-noi-chung) * [4. Thảo luận](#4-tho-lun) * [5. Souce code](#5-souce-code) * [6. Tài liệu tham khảo](#6-tai-liu-tham-kho)",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-2",
        "source": "42.main.md",
        "section": "Bộ cơ sở dữ liệu MNIST",
        "content": "[Bộ cơ sở dữ liệu MNIST](http://yann.lecun.com/exdb/mnist/) là bộ cơ sở dữ liệu lớn nhất về chữ số viết tay và được sử dụng trong hầu hết các thuật toán nhận dạng hình ảnh (Image Classification). MNIST bao gồm hai tập con: tập dữ liệu huấn luyện (training set) có tổng cộng 60k ví dụ khác nhau về chữ số viết tay từ 0 đên 9, tập dữ liệu kiểm tra (test set) có 10k ví dụ khác nhau. Tất cả đều đã được gán nhãn. Hình dưới đây là ví dụ về một số hình ảnh được trích ra từ MNIST. ![](http://www.rubylab.io/img/mnist.png) [MNIST](http://yann.lecun.com/exdb/mnist/): bộ cơ sở dữ liệu của chữ số viết tay. (Nguồn: [Simple Neural Network implementation in Ruby)](http://www.rubylab.io/2015/03/18/simple-neural-network-implenentation-in-ruby/) Mỗi bức ảnh là một ảnh đen trắng (có 1 channel), có kích thước 28x28 pixel (tổng cộng 784 pixels). Mỗi pixel mang một giá trị là một số tự nhiên từ 0 đến 255. Các pixel màu đen có giá trị bằng 0, các pixel càng trắng thì có giá trị càng cao (nhưng không quá 255). Dưới đây là một ví dụ về chữ số 7 và giá trị các pixel của nó. (*Vì mục đích hiển thị ma trận pixel ở bên phải, tôi đã resize bức ảnh về 14x14*) ![](/assets/kmeans/digit_7.png)",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-3",
        "source": "42.main.md",
        "section": "Bài toán phân nhóm giả định",
        "content": "**Bài toán: Giả sử rằng chúng ta không biết nhãn của các chữ số này, chúng ta muốn phân nhóm các bức ảnh gần giống nhau về một nhóm.** Lại thêm một giả sử nữa là chúng ta mới chỉ biết tới thuật toán phân nhóm [K-means clustering](/2017/01/01/kmeans/) gần đây từ blog [Machine Learning cơ bản](https://tiepvupsu.github.io/) (*xin lỗi độc giả vì để các bài học có ý nghĩa hơn, chúng ta đôi khi cần những giả định không được thực tế cho lắm*), chúng ta sẽ giải quyết bài toán này thế nào? Trước khi áp dụng thuật toán [K-means clustering](/2017/01/01/kmeans/), chúng ta cần coi mỗi bức ảnh là một điểm dữ liệu. Và vì mỗi điểm dữ liệu là 1 vector (hàng hoặc cột) chứ không phải ma trận như số 7 ở trên, chúng ta phải làm thêm một bước đơn giản trung gian gọi là *vectorization* (vector hóa). Nghĩa là, để có được 1 vector, ta có thể tách các hàng của ma trận pixel ra, sau đó đặt chúng cạnh nhau, và chúng ta được một vector hàng rất dài biểu diễn 1 bức ảnh chữ số. **Chú ý**: *Cách làm này chỉ là cách đơn giản nhất để mô tả dữ liệu ảnh bằng 1 vector. Trên thực tế, người ta áp dụng rất nhiều kỹ thuật khác nhau để có thể tạo ra các vector đặc trưng (feature vector) giúp các thuật toán có được kết quả tốt hơn.*",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-4",
        "source": "42.main.md",
        "section": "Làm việc trên Python",
        "content": "Trước tiên các bạn vào trang chủ của MNIST để [download](http://yann.lecun.com/exdb/mnist/) bộ cơ sở dữ liệu này. Mặc dù trong bài này chúng ta chỉ dùng bộ dữ liệu test với 10k ảnh và không cần label, các bạn vẫn cần download cả hai file `t10k-images-idx3-ubyte.gz` và `t10k-labels-idx1-ubyte.gz` vì thư viện `python-mnist` cần cả hai file này để load dữ liệu từ tập test. **Trước tiên chúng ta cần khai báo một số thư viện:** `numpy` cho các phép toán liên quan đến ma trận. [`mnist`](https://pypi.python.org/pypi/python-mnist/) để đọc dữ liệu từ MNIST. `matplotlib` để hiển thị hình vẽ. `sklearn` chính là `scikit-learn` mà chúng ta đã làm quen trong các bài trước. (*Về việc cài đặt các thư viện này, tôi hy vọng bạn đọc có thể Google thêm đôi chút. Nếu có khó khăn trong việc cài đặt, hãy để lại comment ở dưới bài. Lưu ý, làm việc trên Windows sẽ khó khăn hơn một chút so với Linux*) ```",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-5",
        "source": "42.main.md",
        "section": "%reset",
        "content": "import numpy as np from mnist import MNIST # require `pip install python-mnist` import matplotlib.pyplot as plt from sklearn.cluster import KMeans ``` **Để hiện thị nhiều bức ảnh các chữ số cùng một lúc, tôi có dùng thêm hàm số [`display_network.py`](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/kmeans/display_network.py)**. **Thực hiện thuật toán K-means clustering trên toàn bộ 10k chữ số.** ``` from display_network import * mndata = MNIST('../MNIST/') # path to your MNIST folder mndata.load_testing() X = mndata.test_images kmeans = KMeans(n_clusters=K).fit(X) pred_label = kmeans.predict(X) ``` (*Phần còn lại của source code có thể được tìm thấy [tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/kmeans/Kmeans2.ipynb)*) Đến đây, sau khi đã tìm được các center và phân nhóm dữ liệu vào từng cluster, tôi muốn hiển thị xem center trông như thế nào và các bức ảnh được phân vào mỗi cluster có giống nhau hay không. Dưới đây là kết quả khi tôi chọn ngẫu nhiên 20 bức ảnh từ mỗi cluster. ![](/assets/kmeans/kmeans_random.png) Áp dụng K-means clustering vào tập test set của bộ cơ sở dữ liệu MNIST với K = 10 cluster. Cột 1: centers của các cluster. Các cột còn lại: Mỗi hàng là 20 điểm dữ liệu ngẫu nhiên được chọn ra từ mỗi cluster. Mỗi hàng tương ứng với một cluster, cột đầu tiên có nền xanh bên trái là centers tìm được của các clusters (màu đỏ hơn là các pixel có giá trị cao hơn). Chúng ta thấy rằng các center đều hoặc là giống với một chữ số nào đó, hoặc là kết hợp của hai/ba chữ số nào đó. Ví dụ: center của nhóm thứ 4 là sự kết hợp của các số 4, 7, 9; của hàng thứ 7 là kết hợp của chữ số 7, 8 và 9. Tuy nhiên, các bức ảnh lấy ra ngẫu nhiên từ mỗi nhóm trông không thực sự giống nhau. Lý do có thể là những bức ảnh này ở xa các center của mỗi nhóm (mặc dù center đó đã là gần nhất). Như vậy thuật toán K-means clustering làm việc không thực sự tốt trong trường hợp này. (*Thật may là vì thế nên chúng ta vẫn còn nhiều thứ để học nữa*). Chúng ta vẫn có thể khai thác một số thông tin hữu ích sau khi thực hiện thuật toán này. Bây giờ, thay vì chọn ngẫu nhiên các bức ảnh trong mỗi cluster, tôi chọn 20 bức ảnh gần center của mỗi cluster nhất, vì càng gần center thì độ tin cậy càng cao. Hãy xem hình dưới đây: ![](/assets/kmeans/kmeans_knn.png) Áp dụng K-means clustering vào tập test set của bộ cơ sở dữ liệu MNIST với K = 10 cluster. Cột 1: centers của các cluster. Các cột còn lại: Mỗi hàng là 20 điểm dữ liệu gần center nhất của mỗi cluster. Bạn đọc có thể thấy dữ liệu trong mỗi hàng khá giống nhau và giống với center ở cột đầu tiên bên trái. Có một vài quan sát thú vị có thể rút ra từ đây: 1. Có hai kiểu viết chữ số 1, một thẳng, một chéo. Và K-means clustering nghĩ rằng đó là hai chữ số khác nhau. Điều này là dễ hiểu vì K-means clustering là thuật toán [Unsupervised learning](/2016/12/27/categories/#unsupervised-learning-hoc-khong-giam-sat). Nếu có sự can thiệp của con người, chúng ta có thể nhóm hai clusters này vào làm một. 2. Hàng số 9, chữ số 4 và 9 được phân vào cùng 1 cluster. Sự thật là hai chữ số này cũng khá giống nhau. Điều tương tự xảy ra đối với hàng số 7 với các chữ số 7, 8, 9 được xếp vào 1 cluster. Với các cluster này, chúng ta có thể tiếp tục áp dụng K-means clustering để phân nhỏ cluster đó ra. 3. Trong clustering có một kỹ thuật thường được sử dụng là [Hierarchical clustering (clustering phân tầng )](https://en.wikipedia.org/wiki/Hierarchical_clustering). Có hai loại Hierachical clustering: * **Agglomerative** tức “đi từ dưới lên”. Ban đầu coi mỗi điểm dữ liệu thuộc 1 cluster khác nhau, sau đó các cặp cluster gần giống nhau được gộp lại làm một cluster lớn hơn. Lặp lại quá trình này đến khi nhận được kết quả chấp nhận được. * **Divisive** tức “đi từ trên xuống”. Ban đầu coi tất cả các điểm dữ liệu thuộc cùng một cluster, sau đó chia nhỏ mỗi cluster bằng một thuật toán clustering nào đó.",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-6",
        "source": "42.main.md",
        "section": "Đặt vấn đề",
        "content": "Chúng ta cùng thử áp dụng thuật toán K-means clustering vào một bài toán xử lý ảnh khác: tách vật thể. Giả sử chúng ta có bức ảnh dưới đây và muốn một thuật toán tự động nhận ra vùng khuôn mặt và tách nó ra. ![](/assets/kmeans/girl3.jpg) Credit ảnh:  [Trọng Vũ](https://www.facebook.com/photo.php?fbid=1219980151402370&set=a.113129725420757.13101.100001711890571&type=3&theater)",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-7",
        "source": "42.main.md",
        "section": "Lên ý tưởng",
        "content": "(*Lại giả sử rằng chúng ta chưa biết gì khác ngoài K-means clustering, các bạn hãy dừng vài giây để nghĩ xem chúng ta có thể xử lý thế nào. Gợi ý: Có ba màu chủ đạo trong bức ảnh.*) Ok, có ba màu, ba clusters! Bức ảnh có ba màu chủ đạo: hồng ở khăn và môi; đen ở mắt, tóc, và hậu cảnh; màu da ở vùng còn lại của khuôn mặt. Vậy chúng ta có thể áp dụng thuật toán K-means clustering để phân các pixel ảnh thành 3 clusters, sau đó chọn cluster chứa phần khuôn mặt (phần này do con người làm). Đây là một bức ảnh màu, mỗi điểm ảnh sẽ được biểu diễn bới 3 giá trị tương ứng với màu Red, Green, và Blue (mỗi giá trị này cũng là một số tự nhiên không vượt quá 255). Nếu ta coi mỗi điểm dữ liệu là một vector 3 chiều chứa các giá trị này, sau đó áp dụng thuật toán K-means clustering, chúng ta có thể có kết quả mong muốn. Hãy thử xem",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-8",
        "source": "42.main.md",
        "section": "Làm việc trên Python",
        "content": "**Khai báo thư viện và load bức ảnh:** ``` import matplotlib.image as mpimg import matplotlib.pyplot as plt import numpy as np from sklearn.cluster import KMeans img = mpimg.imread('girl3.jpg') plt.imshow(img) imgplot = plt.imshow(img) plt.axis('off') plt.show() ``` **Biến đổi bức ảnh thành 1 ma trận mà mỗi hàng là 1 pixel với 3 giá trị màu** ``` X = img.reshape((img.shape[0]*img.shape[1], img.shape[2])) ``` (*Phần còn lại của source code có thể xem [tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/kmeans/Kmeans2.ipynb)*). Sau khi tìm được các cluster, tôi thay giá trị của mỗi pixel bằng center của cluster chứa nó, và được kết quả như sau: ![](/assets/kmeans/girl_seg.png) Ba màu: Hồng, đen, và màu da đã được phân nhóm. Và khuôn mặt có thể được tách ra từ phần có màu da (và vùng bên trong nó). Vậy là K-means clustering tạo ra một kết quả chấp nhận được.",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-9",
        "source": "42.main.md",
        "section": "3. Image Compression (nén ảnh và nén dữ liệu nói chung)",
        "content": "Để ý thấy rằng mỗi một pixel có thể nhận một trong số \\(256^3 = 16,777,216\\) (16 triệu màu mà chúng ta vẫn nghe khi quảng cáo màn hình). Đây là một số rất lớn (tương đương với 24 bit cho một điểm ảnh). Nếu ta muốn lưu mỗi điểm ảnh với một số bit nhỏ hơn và chấp nhận mất dữ liệu ở một mức nào đó, có cách nào không nếu ta chỉ biết K-means clustering? Câu trả lời là có. Trong bài toán Segmentation phía trên, chúng ta có 3 clusters, và mỗi một điểm ảnh sau khi xử lý sẽ được biểu diễn bởi 1 số tương ứng với 1 cluster. Tuy nhiên, chất lượng bức ảnh rõ ràng đã giảm đi nhiều. Tôi làm một thí nghiệm nhỏ với số lượng clusters được tăng lên là 5, 10, 15, 20. Sau khi tìm được centers cho mỗi cluster, tôi thay giá trị của một điểm ảnh bằng giá trị của center tương ứng: ``` for K in [5, 10, 15, 20]: kmeans = KMeans(n_clusters=K).fit(X) label = kmeans.predict(X) img4 = np.zeros_like(X)",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-10",
        "source": "42.main.md",
        "section": "replace each pixel by its center",
        "content": "for k in range(K): img4[label == k] = kmeans.cluster_centers_[k]",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-11",
        "source": "42.main.md",
        "section": "reshape and display output image",
        "content": "img5 = img4.reshape((img.shape[0], img.shape[1], img.shape[2])) plt.imshow(img5, interpolation='nearest') plt.axis('off') plt.show() ``` Kết quả: ![](/assets/kmeans/girl_all.png) Bạn đọc có thể quan sát là khi số lượng clusters tăng lên, chất lượng bức ảnh đã được cải thiện. Đồng thời, chúng ta chỉ cần lưu các centers và label của mỗi điểm ảnh là đã có được một bức ảnh nén (có mất dữ liệu).",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-12",
        "source": "42.main.md",
        "section": "4. Thảo luận",
        "content": "1. Với một thuật toán K-means clustering đơn giản, chúng ta đã có thể áp dụng nó vào các bài toán thực tế. Mặc dù kết quả chưa thực sự như ý, chúng ta vẫn thấy được tiềm năng của thuật toán đơn giản này. 2. Cách thay một điểm dữ liệu bằng center tương ứng là một trong số các kỹ thuật có tên chung là [Vector Quantization (VQ)](https://en.wikipedia.org/wiki/Vector_quantization). Không chỉ trong nén dữ liệu, VQ còn được áp dụng rộng rãi trong các thuật toán tạo Feature Vector cho các bài toán Phân loại (classification). 3. Các thuật toán trong bài toán này được áp dụng cho xử lý ảnh vì việc này giúp tôi dễ dàng minh họa kết quả hơn. Các kỹ thuật này hoàn toàn có thể áp dụng cho các loại cơ sở dữ liệu khác.",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-13",
        "source": "42.main.md",
        "section": "5. Souce code",
        "content": "Các bạn có thể [download source code ở đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/kmeans/Kmeans2.ipynb).",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "42.main-14",
        "source": "42.main.md",
        "section": "6. Tài liệu tham khảo",
        "content": "[Pattern Recognition and Machine Learning - Christopher Bishop](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)",
        "url": "https://machinelearningcoban.com/2017/01/04/kmeans2/"
    },
    {
        "id": "30.main-1",
        "source": "30.main.md",
        "section": "Introduction",
        "content": "* [1. Giới thiệu](#-gioi-thieu) + [1.1. Bài toán nhà xuất bản](#-bai-toan-nha-xuat-ban) - [Bài toán](#bai-toan) - [Phân tích](#phan-tich) + [1.2. Bài toán canh tác](#-bai-toan-canh-tac) - [Bài toán](#bai-toan-1) - [Phân tích](#phan-tich-1) + [1.3. Bài toán đóng thùng](#-bai-toan-dong-thung) - [Bài toán](#bai-toan-2) - [Phân tích](#phan-tich-2) * [2. Nhắc lại bài toán tối ưu](#-nhac-lai-bai-toan-toi-uu) + [2.1. Các khái niệm cơ bản](#-cac-khai-niem-co-ban) + [2.2. Optimal and locally optimal points](#-optimal-and-locally-optimal-points) + [2.3. Một vài lưu ý](#-mot-vai-luu-y) * [3. Bài toán tối ưu lồi](#-bai-toan-toi-uu-loi) + [3.1. Định nghĩa](#-dinh-nghia) + [3.2. Cực tiểu của bài toán tối ưu lồi chính là điểm tối ưu.](#-cuc-tieu-cua-bai-toan-toi-uu-loi-chinh-la-diem-toi-uu) + [3.3. Điều kiện tối ưu cho hàm mục tiêu khả vi](#-dieu-kien-toi-uu-cho-ham-muc-tieu-kha-vi) + [3.4. Giới thiệu thư viện CVXOPT](#-gioi-thieu-thu-vien-cvxopt) * [4. Linear Programming](#-linear-programming) + [4.1. Dạng tổng quát của LP](#-dang-tong-quat-cua-lp) + [4.2. Dạng tiêu chuẩn của LP](#-dang-tieu-chuan-cua-lp) + [4.3. Minh hoạ bằng hình học của bài toán LP](#-minh-hoa-bang-hinh-hoc-cua-bai-toan-lp) + [Giải LP bằng CVXOPT](#giai-lp-bang-cvxopt) * [5. Quadratic Programming](#-quadratic-programming) + [5.1. Định nghĩa bài toán Quadratic Programming](#-dinh-nghia-bai-toan-quadratic-programming) + [5.2. Ví dụ về QP](#-vi-du-ve-qp) + [5.3. Ví dụ về giải QP bằng CVXOPT](#-vi-du-ve-giai-qp-bang-cvxopt) * [6. Geometric Programming](#-geometric-programming) + [6.1. Monomials và posynomials](#-monomials-va-posynomials) + [6.2. Geometric Programming](#-geometric-programming-1) + [6.3. Biến đổi GP về dạng convex](#-bien-doi-gp-ve-dang-convex) + [6.4. Giải GP bằng CVXOPT](#-giai-gp-bang-cvxopt) * [7. Tóm tắt](#-tom-tat) * [8. Tài liệu tham khảo](#-tai-lieu-tham-khao) **Bạn được khuyến khích đọc [Bài 16](/2017/03/12/convexity/) trước khi đọc bài này. Nội dung trong bài viết này chủ yếu được dịch từ Chương 4 của cuốn *Convex Optimization* trong phần Tài liệu tham khảo.**. Bài này cũng có rất nhiều khái niệm mới và nhiều lý thuyết nên có thể không hấp dẫn như các bài khác. Tuy nhiên, tôi không thể bỏ qua vì không muốn các bạn hoàn toàn mất phương hướng khi đọc các bài sau. Bạn đọc có thể xem bản pdf [tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/latex/book_CVX.pdf).",
        "url": "https://machinelearningcoban.com/2017/03/19/convexopt/"
    },
    {
        "id": "30.main-2",
        "source": "30.main.md",
        "section": "1. Giới thiệu",
        "content": "Tôi xin bắt đầu bài viết này bằng ba bài toán khá gần với thực tế:",
        "url": "https://machinelearningcoban.com/2017/03/19/convexopt/"
    },
    {
        "id": "30.main-3",
        "source": "30.main.md",
        "section": "Bài toán",
        "content": "Một nhà xuất bản (NXB) nhận được đơn hàng 600 bản của cuốn “Machine Learning cơ bản” tới Thái Bình và 400 bản tới Hải Phòng. NXB đó có 800 cuốn ở kho Nam Định và 700 cuốn ở kho Hải Dương. Giá chuyển phát một cuốn sách từ Nam Định tới Thái Bình là 50,000 VND (50k), tới Hải Phòng là 100k. Giá chuyển phát một cuốn từ Hải Dương tới Thái Bình là 150k, trong khi tới Hải Phòng chỉ là 40k. Hỏi để tốn ít chi phí chuyển phát nhất, công ty đó nên phân phối mỗi kho chuyển bao nhiêu cuốn tới mỗi địa điểm?",
        "url": "https://machinelearningcoban.com/2017/03/19/convexopt/"
    },
    {
        "id": "30.main-4",
        "source": "30.main.md",
        "section": "Phân tích",
        "content": "Để cho đơn giản, ta xây dựng bảng số lượng chuyển sách từ nguồn tới đích như sau: | Nguồn | Đích | Đơn giá (\\(\\times\\)10k) | Số lượng | | --- | --- | --- | --- | | Nam Định | Thái Bình | 5 | \\(x\\) | | Nam Định | Hải Phỏng | 10 | \\(y\\) | | Hải Dương | Thái Bình | 15 | \\(z\\) | | Hải Dương | Hải Phòng | 4 | \\(t\\) | Tổng chi phí (objective function) sẽ là \\(f(x, y, z, t) = 5x + 10y + 15z + 4t\\). Các điều kiện ràng buộc (constraints) viết dưới dạng biểu thức toán học là: * Chuyển 600 cuốn tới Thái Bình: \\(x + z = 600\\). * Chuyển 400 cuốn tới Hải Phòng: \\(y + t = 400\\). * Lấy từ kho Nam Định không quá 800: \\(x + y \\leq 800\\). * Lấy từ kho Hải Dương không quá 700: \\(z + t \\leq 700\\). * \\(x, y, z, t\\) là các số tự nhiên. Ràng buộc là số tự nhiên sẽ khiến cho bài toán rất khó giải nếu số lượng biến là rất lớn. Với bài toán này, ta giả sử rằng \\(x, y, z, t\\) là các số thực dương. Khi tìm được nghiệm, nếu chúng không phải là số tự nhiên, ta sẽ lấy các giá trị tự nhiên gần nhất. Vậy ta cần giải bài toán tối ưu sau đây: --- **Bài toán NXB:** \\[ \\begin{align} (x, y, z, t) =& \\arg\\min\\_{x, y, z, t} 5x + 10y + 15z + 4t ~~~~ (1)\\newline \\text{subject to:}~ & x + z = 600 ~~~~ (2)\\newline & y + t = 400 ~~~~ (3) \\newline & x + y \\leq 800 ~~~(4) \\newline & z + t \\leq 700 ~~~ (5)\\newline & x, y, z, t \\geq 0 ~~~ (6) \\end{align} \\] ---",
        "url": "https://machinelearningcoban.com/2017/03/19/convexopt/"
    },
    {
        "id": "20.main-1",
        "source": "20.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#1-gii-thiu) * [2. Một chút toán](#2-mt-chut-toan) + [2.1. Norm 2 của ma trận](#21-norm-2-ca-ma-trn) + [2.2. Biễu diễn vector trong các hệ cơ sở khác nhau](#22-biu-din-vector-trong-cac-h-c-s-khac-nhau) + [2.3. Trace](#23-trace) + [2.4. Kỳ vọng và ma trận hiệp phương sai](#24-k-vng-va-ma-trn-hip-phng-sai) - [2.4.1. Dữ liệu một chiều](#241-d-liu-mt-chiu) - [2.4.2. Dữ liệu nhiều chiều](#242-d-liu-nhiu-chiu) * [3. Principal Component Analysis](#3-principal-component-analysis) * [4. Các bước thực hiện PCA](#4-cac-bc-thc-hin-pca) * [5. Thảo luận](#5-tho-lun) * [6. Tài liệu tham khảo](#6-tai-liu-tham-kho)",
        "url": "https://machinelearningcoban.com/2017/06/15/pca/"
    },
    {
        "id": "20.main-2",
        "source": "20.main.md",
        "section": "1. Giới thiệu",
        "content": "Dimensionality Reduction (giảm chiều dữ liệu), như đã được đề cập một vài lần trong blog, là một trong những kỹ thuật quan trọng trong Machine Learning. Các feature vectors trong các bài toán thực tế có thể có số chiều rất lớn, tới vài nghìn. Ngoài ra, số lượng các điểm dữ liệu cũng thường rất lớn. Nếu thực hiện lưu trữ và tính toán trực tiếp trên dữ liệu có số chiều cao này thì sẽ gặp khó khăn cả về việc lưu trữ và tốc độ tính toán. Vì vậy, giảm số chiều dữ liệu là một bước quan trọng trong nhiều bài toán. Đây cũng được coi là một phương pháp nén dữ liệu. Dimensionality Reduction, nói một cách đơn giản, là việc đi tìm một hàm số, hàm số này lấy đầu vào là một điểm dữ liệu ban đầu \\(\\mathbf{x} \\in \\mathbb{R}^D\\) với \\(D\\) rất lớn, và tạo ra một điểm dữ liệu mới \\(\\mathbf{z} \\in \\mathbb{R}^K\\) có số chiều \\(K < D\\). Và như thường lệ, tôi sẽ trình bày một phương pháp đơn giản nhất trong các thuật toán Dimensionality Reduction dựa trên một mô hình tuyến tính. Phương pháp này có tên là *Principal Component Analysis* (PCA), tức *Phân tích thành phần chính*. Phương pháp này dựa trên quan sát rằng dữ liệu thường không phân bố ngẫu nhiên trong không gian mà thường phân bố gần các đường/mặt đặc biệt nào đó. PCA xem xét một trường hợp đặc biệt khi các mặt đặc biệt đó có dạng tuyến tính là các không gian con (subspace). Bài viết này dành cho nhiều đối tượng độc giả khác nhau: * Nếu bạn cần ôn tập lại các kiến thức về hệ độc lập tuyến tính, kỳ vọng, phương sai, ma trận hiệp phương sai, bạn có thể đọc Mục 2. * Nếu bạn muốn hiểu nguồn gốc, ý tưởng đứng sau PCA, tại sao PCA lại được thực hiện như vậy, bạn có thể tìm được ở Mục 3. * Nếu bạn không muốn đi sâu vào toán mà chỉ cần hiểu các bước thực hiện PCA, bạn có thể tới ngay Mục 4. * Nếu bạn không muốn hiểu các bước thực hiện mà chỉ muốn biết hàm số thực hiện PCA, một vài ứng dụng của PCA, và có thể thêm các phần mở rộng của PCA, bạn có thể thấy PCA phần 2 có ích, dự tính được ra mắt sau đây một tuần. * Nếu tôi là các bạn, tôi sẽ đọc hết cả bài. Trước khi đi vào chi tiết của PCA, chúng ta cùng điểm lại một chút về Đại số tuyến tính và Thống kê.",
        "url": "https://machinelearningcoban.com/2017/06/15/pca/"
    },
    {
        "id": "20.main-3",
        "source": "20.main.md",
        "section": "2.1. Norm 2 của ma trận",
        "content": "Chúng ta vẫn thường nhắc nhiều đến [norm cho vector](https://machinelearningcoban.com/math/#-norms-chuan) nhưng chưa thực sự làm việc nhiều với norm của ma trận (ngoài [Frobenius norm](https://machinelearningcoban.com/math/#chuan-cua-ma-tran)). Trong mục này, chúng ta sẽ làm quen với 1 lớp các norm cho ma trận được định nghĩa dựa trên norm của vector. Lớp các norms này còn được gọi là *Induced Norms*. Giả sử hàm số \\(||\\mathbf{x}||\\_{\\alpha}\\) là một norm bất kỳ của vector \\(\\mathbf{x}\\). Ứng với norm này, định nghĩa norm tương ứng cho ma trận \\(\\mathbf{A}\\): \\[ ||\\mathbf{A}||\\_{\\alpha} = \\max\\_{\\mathbf{x}} \\frac{||\\mathbf{Ax}||\\_{\\alpha}}{||\\mathbf{x}||\\_{\\alpha}} \\] chú ý rằng ma trận \\(\\mathbf{A}\\) có thể không vuông và số cột của nó bằng với số chiều của \\(\\mathbf{x}\\). Như vậy, bản thân việc tính toán norm của ma trận là việc giải một bài toán tối ưu. Chú ý rằng hàm tối ưu có cả tử số và mẫu số là các norm trên vectors. Chúng ta sẽ quan tâm nhiều hơn tới norm 2. Norm 2 của ma trận được định nghĩa là: \\[ ||\\mathbf{A}||\\_2 = \\max\\_{\\mathbf{x}} \\frac{||\\mathbf{Ax}||\\_2}{||\\mathbf{x}||\\_2} ~~~ (1) \\] Nhận thấy rằng nếu \\(\\mathbf{x}\\) là nghiệm của bài toán tối ưu \\((1)\\) thì \\(k\\mathbf{x}\\) cũng là nghiệm với \\(k\\) là một số thực khác không bất kỳ. Không mất tính tổng quát, ta có thể giả sử mẫu số bằng 1. Khi đó, bài toán tối ưu \\((1)\\) có thể được viết dưới dạng: \\[ ||\\mathbf{A}||\\_2 = \\max\\_{||\\mathbf{x}||\\_2 = 1} ||\\mathbf{Ax}||\\_2 ~~~ (2) \\] Nói cách khác, ta cần đi tìm \\(\\mathbf{x}\\) sao cho: \\[ \\begin{eqnarray} \\mathbf{x} &=& \\text{argmax}\\_{\\mathbf{x}} ||\\mathbf{Ax}||\\_2^2 & \\newline \\text{s.t.: } && ||\\mathbf{x}||\\_2^2 = 1 & (3) \\end{eqnarray} \\] Ở đây, các norm 2 đã được bình phương lên để tránh dấu căn bậc hai. Bài toán \\((3)\\) có thể được giải bằng [Phương pháp nhân tử Lagrange](/2017/04/02/duality/#--phuong-phap-nhan-tu-lagrange) vì ràng buộc là một phương trình. Lagrangian của Bài toán \\((3)\\) là: \\[ \\mathcal{L}(\\mathbf{x}, \\lambda) = ||\\mathbf{Ax}||\\_2^2 + \\lambda (1 - ||\\mathbf{x}||\\_2^2) \\] Nghiệm của bài toán \\((3)\\) sẽ thoả mãn hệ phương trình: \\[ \\begin{eqnarray} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}} &=& 2\\mathbf{A}^T\\mathbf{Ax} - 2\\lambda \\mathbf{x} = \\mathbf{0} & (4)\\newline \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} &=& 1 - ||\\mathbf{x}||\\_2^2 = 0 & (5) \\end{eqnarray} \\] Từ \\((4)\\) ta có: \\[ \\mathbf{A}^T\\mathbf{Ax} = \\lambda\\mathbf{x} ~~~~ (6) \\] Điều này suy ra rằng \\(\\lambda\\) là một trị riêng của \\(\\mathbf{A}^T\\mathbf{A}\\) và \\(\\mathbf{x}\\) là 1 vector riêng ứng với trị riêng đó. Tiếp tục nhân hai vế của \\((6)\\) với \\(\\mathbf{x}^T\\) vào bên trái, ta có: \\[ \\mathbf{x}^T\\mathbf{A}^T\\mathbf{Ax} = \\lambda \\mathbf{x}^T\\mathbf{x} = \\lambda \\] Nhận thấy rằng vế trái chính là \\(||\\mathbf{Ax}||\\_2^2\\) chính là hàm mục tiêu trong \\((3)\\). Vậy hàm mục tiêu đạt giá trị lớn nhất khi \\(\\lambda\\) đạt giá trị lớn nhất. Nói cách khác, \\(\\lambda\\) chính là trị riêng lớn nhất của \\(\\mathbf{A}^T\\mathbf{A}\\) hay chính là [singular value](/2017/06/07/svd/#-nguon-goc-ten-goi-singular-value-decomposition) lớn nhất của ma trận \\(\\mathbf{A}\\). Như vậy, norm 2 của một ma trận chính là singular value lớn nhất của ma trận đó. Và nghiệm của bài toán \\((3)\\) chính một là *right-singular vector* ứng với singular value đó. Với lý luận tương tự, chúng ta có thể suy ra rằng bài toán: \\[ \\min\\_{||\\mathbf{x}||\\_2 =1} \\mathbf{x}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{x} \\] có nghiệm là vector riêng ứng với trị riêng nhỏ nhất của \\(\\mathbf{A}^T\\mathbf{A}\\). Khi đó, hàm số đạt giá trị nhỏ nhất bằng chính trị riêng nhỏ nhất này.",
        "url": "https://machinelearningcoban.com/2017/06/15/pca/"
    },
    {
        "id": "20.main-4",
        "source": "20.main.md",
        "section": "2.2. Biễu diễn vector trong các hệ cơ sở khác nhau",
        "content": "Trong không gian \\(D\\) chiều , toạ độ của mỗi điểm được xác định dựa trên một hệ toạ độ nào đó. Ở các hệ toạ độ khác nhau, hiển nhiên là toạ độ của mỗi điểm cũng khác nhau. Tập hợp các vector \\(\\mathbf{e}\\_1, \\dots, \\mathbf{e}\\_D\\) mà mỗi vector \\(\\mathbf{e}\\_d\\) có đúng 1 phần tử khác 0 ở thành phần thứ \\(d\\) và phần tử đó bằng 1, được gọi là hệ cơ sở đơn vị (hoặc hệ đơn vị) trong không gian \\(D\\) chiều. Nếu xếp các vector \\(\\mathbf{e}\\_d, d = 1, 2, \\dots, D\\) theo đúng thứ tự đó, ta sẽ được ma trận đơn vị \\(D\\) chiều. Mỗi vector cột \\(\\mathbf{x} = [x\\_1, x\\_2, \\dots, x\\_D] \\in \\mathbb{R}^D\\), biểu diễn của nó trong hệ đơn vị là: \\[ \\mathbf{x} = x\\_1 \\mathbf{e}\\_1 + x\\_2 \\mathbf{e}\\_2 + \\dots + x\\_D\\mathbf{e}\\_D \\] Giả sử có một hệ cơ sở khác \\(\\mathbf{u}\\_1, \\mathbf{u}\\_2, \\dots, \\mathbf{u}\\_D\\) (các vector này độc lập tuyến tính), vậy thì biểu diễn của vector \\(\\mathbf{x}\\) trong hệ cơ sở mới này có dạng: \\[ \\mathbf{x} = y\\_1 \\mathbf{u}\\_1 + y\\_2 \\mathbf{u}\\_2 + \\dots + y\\_D\\mathbf{u}\\_D = \\mathbf{U}\\mathbf{y} \\] \\(\\mathbf{U}\\) là ma trận mà cột thứ \\(d\\) của nó chính là vector \\(\\mathbf{u}\\_d\\). Lúc này, vector \\(\\mathbf{y}\\) chính là biểu diễn của \\(\\mathbf{x}\\) trong hệ cơ sở mới. Bộ các số \\(y\\_d, d = 1, 2, \\dots, D\\) là duy nhất vì \\(\\mathbf{y}\\) có thể tính được bằng: \\[ \\mathbf{y} = \\mathbf{U}^{-1} \\mathbf{x} ~~~ (7) \\] với chú ý rằng \\(\\mathbf{U}\\) là ma trận khả nghịch vì các cột của nó độc lập tuyến tính. Trong các ma trận đóng vai trò như hệ cơ sở \\(\\mathbf{U}\\), [các ma trận trực giao](/2017/06/07/svd/#-he-truc-giao-va-truc-chuan), tức \\(\\mathbf{U}^T\\mathbf{U} = \\mathbf{I}\\), được quan tâm nhiều hơn vì nghịch đảo của chúng chính là chuyển vị của chúng: \\[ \\mathbf{U}^{-1} = \\mathbf{U}^T \\] Khi đó, \\(\\mathbf{y}\\) trong \\((7)\\) có thể được tính một cách nhanh chóng: \\[ \\mathbf{y} = \\mathbf{U}^{T} \\mathbf{x} \\] từ đó suy ra: \\(y\\_i = \\mathbf{x}^T \\mathbf{u}\\_i = \\mathbf{u}\\_i^T\\mathbf{x}, i= 1, 2, \\dots, D\\). Có thể nhận thấy rằng vector \\(\\mathbf{0}\\) được biểu diễn như nhau trong mọi hệ cơ sở. Hình 1 dưới đây là 1 ví dụ về việc chuyển hệ cơ sở: --- |  |  | | --- | --- | |  | Hình 1: Chuyển đổi toạ độ trong các hệ cơ sở khác nhau. | ---",
        "url": "https://machinelearningcoban.com/2017/06/15/pca/"
    },
    {
        "id": "16.main-1",
        "source": "16.main.md",
        "section": "Introduction",
        "content": "Trước Deep Learning, bài toán phân loại ảnh (các loại dữ liệu khác cũng tương tự) thường được chia thành 2 bước: Feature Engineering và Train a Classifier. Hai bước này thường được tách rời nhau. Với Feature Engineering, các phương pháp thường được sử dụng cho ảnh là [SIFT](http://docs.opencv.org/3.1.0/da/df5/tutorial_py_sift_intro.html) (Scale Invariant Feature Transform), [SURF](http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_surf_intro/py_surf_intro.html) (Speeded-Up Robust Features), [HOG](http://www.learnopencv.com/histogram-of-oriented-gradients/) (Histogram of Oriented Gradients), LBP (Local Binary Pattern), etc. Các Classifier thường được sử dụng là [multi-class SVM](/2017/04/28/multiclasssmv/), [Softmax Regression](/2017/02/17/softmax/), Discriminative Dictionary Learning, Random Forest, etc. Các phương pháp Feature Engineering nêu trên thường được gọi là các *hand-crafted features* (feature được tạo thủ công) vì nó chủ yếu dựa trên các quan sát về đặc tính riêng của ảnh. Các phương pháp này cho kết quả khá ấn tượng trong một số trường hợp. Tuy nhiên, chúng vẫn còn nhiều hạn chế vì quá trình tìm ra các features và các classifier phù hợp vẫn là riêng biệt. (Tôi đã từng đề cập tới vấn đề này trong [các mô hình end-to-end](/2017/04/28/multiclasssmv/#-mo-hinh-end-to-end)) Những năm gần đây, Deep Learning phát triển cực nhanh dựa trên lượng dữ liệu training khổng lồ và khả năng tính toán ngày càng được cải tiến của các máy tính. Các kết quả cho bài toán phân loại ảnh ngày càng được nâng cao. Bộ cơ sở dữ liệu thường được dùng nhất là [ImageNet](https://www.image-net.org) với 1.2M ảnh cho 1000 classes khác nhau. Rất nhiều các mô hình Deep Learning đã giành chiến thắng trong các cuộc thi [ILSVRC](https://www.google.com/search?client=opera&q=imagenet+results&sourceid=opera&ie=UTF-8&oe=UTF-8#q=ILSVRC+) (ImageNet Large Scale Visual Recognition Challenge). Có thể kể ra một vài: [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), [ZFNet](https://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf), [GoogLeNet](https://arxiv.org/abs/1409.4842v1), [ResNet](https://arxiv.org/pdf/1502.01852.pdf), [VGG](https://www.robots.ox.ac.uk/~vgg/research/very_deep/). --- ![](/assets/q2_tl/multi_layers.png) Hình 1: Mô hình chung cho các bài toán classification sử dụng Deep Learning. Layer cuối cùng thường là một Fully Connected Layer và thường là một Softmax Regression. ---",
        "url": "https://machinelearningcoban.com/2017/07/02/tl/"
    },
    {
        "id": "5.main-1",
        "source": "5.main.md",
        "section": "Introduction",
        "content": "*Bạn [Giang Phương Hoa](https://www.facebook.com/phuonghoa.giang) từng học Đại học Ngoại Thương Hà Nội, học Thạc sỹ tại Imperial College London, hiện đang làm việc tại Microsoft AI Research London chia sẻ về con đường trở thành Data Scientist của mình.* Chào cả nhà, Cảm ơn anh Tiệp đã tạo cơ hội cho mình viết bài này để chia sẻ. Follow [Forum Machine Learning cơ bản](https://www.facebook.com/groups/machinelearningcoban/) đã lâu mà chưa đóng góp được gì nhiều. Dạo gần đây mình có gặp nhiều bạn trẻ muốn theo nghề Data Science và PM mình hỏi về con đường mình đến với Data Science và bắt đầu học Machine Learning như thế nào. Vì thế mình đã xin phép anh Tiệp để viết bài ở đây, chia sẻ cùng mọi người và hy vọng sẽ giúp ích cho các bạn đang tự học Data Science, hoặc có background trái ngành trái nghề và muốn làm Data Science một cách nghiêm túc. Bài viết sẽ rất vớ vẩn với các chuyên gia 😊. Đây là con đường không hề dễ dàng nếu bạn không học Khoa học máy tính hay Toán từ bậc ĐH nhưng cũng không có nghĩa là không thể. *Everything is impossible until you do it.*",
        "url": "https://machinelearningcoban.com/2018/03/22/phuonghoagiang/"
    },
    {
        "id": "5.main-2",
        "source": "5.main.md",
        "section": "Học Ngoại Thương HN",
        "content": "Con đường mình đến với Data Science không hề bằng phẳng và mình tin nhiều bạn ở đây cũng vậy. Mình học Ngoại Thương chuyên ngành Tài chính. Cũng tự coi là có chút background về Toán Cao Cấp và Xác suất thống kê nhưng sẽ chỉ là muối bỏ bể so với các bạn học bài bản về Toán Lý Thuyết hay Xác suất thống kê. Rất may là trong quá trình học Ngoại Thương thì mình nhận ra môn học mà mình yêu thích nhất là môn Phân tích dữ liệu tài chính. Cảm giác nhìn những con số rồi tìm tòi ra một ý tưởng gì đó mới rồi trình bày bảng biểu vô cùng hấp dẫn (mãi sau này mình mới biết khái niệm đó gọi là insights 😊). Vì thế mình có tham gia một số cuộc thi sinh viên về phân tích dữ liệu.",
        "url": "https://machinelearningcoban.com/2018/03/22/phuonghoagiang/"
    },
    {
        "id": "5.main-3",
        "source": "5.main.md",
        "section": "Nielsen Case Competition",
        "content": "Hồi đó hình như chỉ có Nielsen Case Competition–cuộc thi dành cho sinh viên của Nielsen, một công ty data consulting khá lớn tại Mỹ. Mình cũng may mắn cùng với các bạn trong nhóm giành giải của cuộc thi đó và bắt đầu đầu quân cho Nielsen để làm Chuyên viên phân tích dữ liệu 😊–Insight Analyst. Thời gian làm việc cho Nielsen là thời gian mình luôn cảm thấy là thời gian tạo một nền tảng vững chắc cho bản thân trong nghề làm Analyst. Nếu bạn google Nielsen thì Nielsen là một công ty nghiên cứu thị trường truyền thống, dữ liệu cung cấp chủ yếu bằng survey và phỏng vấn người tiêu dùng. Thời đó khái niệm Dữ liệu lớn hay là Khoa học máy tính vẫn còn xa vời với mình. Nhưng chính từ thời gian làm việc giống như một nhân viên tư vấn dữ liệu đã giúp mình hiểu được ứng dụng thực sự của dữ liệu là gì? Làm sao để dữ liệu có ích cho doanh nghiệp? Mình cũng học được cách từ một câu hỏi lớn và mơ hồ, làm sao để chia nhỏ câu hỏi đó thành những câu hỏi nhỏ hơn mà bạn có thể *translate* (*phiên dịch*) thành một câu hỏi có thể trả lời bằng dữ liệu sẵn có? Mình cũng hiểu khái niệm *connecting the dots* (*xâu chuỗi*) dữ liệu là gì? Vì vậy, đừng tự nghĩ rằng công việc mình đang làm không có gì hấp dẫn, không có gì liên quan đến Machine Learning hay Dữ liệu lớn mà nản lòng. Nhiều lúc bạn sẽ ngạc nhiên về những gì bạn học được từ các *dirty jobs* trong cuộc sống.",
        "url": "https://machinelearningcoban.com/2018/03/22/phuonghoagiang/"
    },
    {
        "id": "5.main-4",
        "source": "5.main.md",
        "section": "Bắt đầu con đường học Khoa học dữ liệu",
        "content": "Sau một thời gian làm việc ở Nielsen thì mình nhận thấy hạn chế của các phương pháp nghiên cứu truyền thống (limited samples, biased trong cách đặt câu hỏi và trả lời). Vì thế mình bắt đầu tìm hiểu phương pháp mới để có thể thực sự phân tích *user behavior* mà không cần phải “hỏi” họ. Và thế là mình khám phá ra một thế giới mới là Khoa học dữ liệu (Data Science-DS). Thời điểm mình bắt đầu tìm hiểu về DS và học về DS thì mọi thứ còn khá mới mẻ (2013) cũng chưa có nhiều các khóa học open source như bây giờ. Mình hoàn toàn tự học mọi thứ từ xác suất thống kê (may mà trong công việc cũng có dùng), toán, lập trình, hệ thống dữ liệu. Mình hiểu là với các bạn không có nền tảng về Khoa học máy tính như mình, việc các bạn làm một cách bản năng là cố gắng lấp đầy lỗ hổng về lĩnh vực này càng nhiều càng tốt. Vì thế, các bạn sẽ cố gắng học Python, học R hay học các ngôn ngữ lập trình. Điều này dẫn đến một hệ quả là các bạn bị *tool-driven*. Học Python không khó, bỏ ra 6 tháng học một cách tập trung, các bạn sẽ viết được những dòng codes như mẫu. Nhưng điều mình hay gặp đó là các bạn học Python hay R như Kinh Thánh vậy. Nhiều bạn nghĩ rằng chỉ cần biết Python hay R là có thể làm được phân tích dữ liệu rồi. Thực ra thì không phải. Mình rất may mắn là trong thời kỳ đầu bắt đầu học, cảm thấy hoang mang quá thì một lần đi gặp khách hàng, gặp một bạn đã làm quantitative analyst ở Wall Street nhiều năm. Bạn ấy thấy mình ôm một quyển Python Fundamentals dầy cộp thì mới bảo “**Mày nên học cách nghĩ, đừng học cách làm vội**”. Chỉ một câu nói nhỏ mà mình nghĩ là có thể trao thưởng huy chương cho bạn ấy vì đã cứu rỗi cuộc đời mình. 😊. Và quyển sách đã thay đổi cuộc đời mình là [How to think like a Computer Scientist](http://openbookproject.net/thinkcs/python/english3e/). Mình đã có dịp gặp tác giả của cuốn sách này và nói với anh ấy là “You saved my life. 😊”. Thực sự thì đối với người học trái ngành, trái nghề, vấn đề lớn nhất là thay đổi cách suy nghĩ và sự tự ti. *Bạn có xuất phát điểm không giống người khác và thế là tìm mọi cách để làm được NHƯ người ta mà quên mất mục đích ban đầu của mình là gì.* Sau khi đọc cuốn sách trên thì mình hiểu ra vấn đề vì sao mình học Python đến hai tháng mà vẫn rất thụ động, chỉ có thể viết những gì code mẫu mà gặp vấn đề mới thì chịu. Đó là vì mình không suy nghĩ theo cách máy tính có thể suy nghĩ. Vì không *think the language* nên mình cũng không thể *speak the language*. Điều này cũng giống như lúc bạn học Tiếng Anh hay ngoại ngữ vậy, không hiểu cách tư duy của ngôn ngữ thì bạn sẽ thành học vẹt. Vì thế mình dành hẳn ba tháng chỉ để học *computational thinking* và *computer logic*, về những thứ như *directory, class, variables, binary operations, algorithmic thinking, big O notation, v.v.*. Điểm này sẽ không thể nào so sánh được với các bạn học Khoa học máy tính trong 3-4 năm nhưng cũng đủ để mình học lập trình một cách đúng hướng (programming in the right way). Mình đã nói chuyện với nhiều bạn tự học programming và nhiều bạn bị cuốn theo cách học Google knowledge–có vấn đề gì thì google–stackoverflows có câu trả lời sẵn. Cuối cùng thì chương trình cũng vẫn chạy, các bạn vẫn thấy hạnh phúc, nhưng lần sau gặp vấn đề khác các bạn không tự trả lời được. Cũng giống như hồi nhỏ ở trường học “How are you?” và trả lời “I’m fine, thank you”. Đến lúc người ta hỏi “How do you feel today?” thì không biết trả lời thế nào. **Lập trình cũng chỉ là công cụ. Cái cốt lõi của Data Science và Machine Learning (ML) vẫn là Toán và Xác suất thống kê.** Về điểm này thì [forum](https://www.facebook.com/groups/257768141347267/) và [cuốn sách](https://machinelearningcoban.com/ebook/) của anh Tiệp sẽ rất hữu ích. **Nền tảng Toán của mình không tệ vì cũng từng học chuyên Toán. Tuy nhiên, cũng giống như câu chuyện lập trình thì mình cảm thấy cũng cần học ML bằng cách *think in ML ways*. Các thuật toán quan trọng trong ML hầu như đều đã được viết và tạo thành thư viện nên vài bạn có thể lười chỉ cần `from sckitlearn import *` và thế là ung dung chạy một cái chương trình ML. Nhưng để thực sự làm DS/ML thì nhiều khi nên bắt đầu ôn lại khái niệm đạo hàm, ma trận và toán cơ bản.**",
        "url": "https://machinelearningcoban.com/2018/03/22/phuonghoagiang/"
    },
    {
        "id": "5.main-5",
        "source": "5.main.md",
        "section": "Học Thạc sỹ tại Imperial College London",
        "content": "Một điểm nữa mà nhiều bạn rất hay quên hoặc bỏ qua khi học DS vì nghĩ nó nhàm chán đó là *database structure và data manipulation*. Mình cũng vấp phải vấn đề tương tự khi mình bắt đầu học Thạc sỹ về Data Science ở Imperial College London. Ngay Kỳ 1 thì trong chương trình có một môn học mà rất nhiều bạn bỏ lớp (mình cũng cúp cua mấy lần) đó là Database Admin. Môn này phải nói là cực kỳ chán vì nó sẽ không có kết quả ngay cho bạn như khi bạn chạy môt chương trình máy tính hay vẽ biểu đồ, đem lại cảm giác cực kỳ *cool* vì *I did something*. Tuy nhiên khi bắt đầu thực sự làm dự án nghiên cứu ở Data Science Institute in Imperial College (mình làm cộng tác viên) thì mình có thể thực sự hiểu được tầm quan trọng kinh khủng của môn này. Bạn không thể thi triển được thuật toán hay tối ưu hóa thuật toán nếu không hiểu cấu trúc dữ liệu hay *database relation, handle missing values, organizing the table in long/wide format, normalization of the database, etc.\\*\\* Những việc nhỏ nhặt, \\*dirty jobs*, tốn thời gian vậy thực ra là vô cùng quan trọng. Khi bạn hiểu cấu trúc dữ liệu thì bạn mới quay lại bước 1 được: Từ câu hỏi lớn làm sao để thi triển ra nhiều câu hỏi nhỏ và trả lời? Rốt cuộc thì DS chính là công cụ để trả lời câu hỏi mà thôi. Đừng quên mục đích ban đầu!",
        "url": "https://machinelearningcoban.com/2018/03/22/phuonghoagiang/"
    },
    {
        "id": "5.main-6",
        "source": "5.main.md",
        "section": "Microsoft AI Research",
        "content": "Sau rất nhiều chông gai thì bây giờ mình được gọi là *data scientist* tại Microsoft AI Research. Chặng đường học thì vẫn còn rất dài, bây giờ mình vẫn phải đọc forum Machine Learning thường xuyên để hiểu thêm. Dưới đây là một ít bài học mình đã đúc kết sau 4 năm ròng rã mất nhiều máu (ngã cầu thang mấy lần vì mải nghĩ) và nước mắt (khó quá làm thế nào), hy vọng sẽ giúp ích cho nhiều bạn có nền tảng giống mình. 1. Đừng chạy theo *buzzwords*, cuộc sống nhiều cám dỗ, hãy bắt đầu từ những thứ căn bản nhất. Thinking và mindset là những thứ quan trọng nhất. Python hay R hay Java cũng chỉ là công cụ. 2. Machine Learning là học máy, trước khi làm ML nếu bạn không có nền tảng về Computer Science thì hãy thử tìm hiểu về *Computational thinking* và *computer logic*. 3. Data science rất rộng lớn. Hãy thử nghĩ về một mảng nhỏ mà bạn muốn theo đuổi: nhiều người có thể theo đuổi Optimization, mình thì chọn cho mình con đường đã đưa mình đến với DS ngay từ đầu: User Behavior Analytics. Điều này sẽ giúp các bạn định hình và tập trung vào những mảng lý thuyết liên quan mật thiết đến mảng này. Nghe có vẻ thực dụng nhưng mình chủ yếu tìm hiểu về các mô hình/thuật toán liên quan đến *time series, sequential pattern mining, pattern recognition, clustering/classification, association mining, etc.* vì đây sẽ là những thứ giúp bạn tìm hiểu về User Behavior. Các thuật toán simulation như Monte Carlo hay các thuật toán tối ưu khác mình không biết quá sâu. Chúc mọi người học Machine Learning vui. 😊",
        "url": "https://machinelearningcoban.com/2018/03/22/phuonghoagiang/"
    },
    {
        "id": "29.main-1",
        "source": "29.main.md",
        "section": "Introduction",
        "content": "* [1. Giới thiệu](#-gioi-thieu) * [2. Phương pháp nhân tử Lagrange](#--phuong-phap-nhan-tu-lagrange) + [Ví dụ](#vi-du) * [3. Hàm đối ngẫu Lagrange (The Lagrange dual function)](#-ham-doi-ngau-lagrange-the-lagrange-dual-function) + [3.1. Lagrangian](#-lagrangian) + [3.2. Hàm đối ngẫu Lagrange](#-ham-doi-ngau-lagrange) + [3.3. Chặn dưới của giá trị tối ưu](#-chan-duoi-cua-gia-tri-toi-uu) + [3.4. Ví dụ](#-vi-du) - [Ví dụ 1](#vi-du-) - [Ví dụ 2](#vi-du--1) * [4. Bài toán đối ngẫu Lagrange (The Lagrange dual problem)](#-bai-toan-doi-ngau-lagrange-the-lagrange-dual-problem) + [4.1. Weak duality](#-weak-duality) + [4.2. Strong duality và Slater’s constraint qualification](#-strong-duality-va-slaters-constraint-qualification) * [5. Optimality conditions](#-optimality-conditions) + [5.1. Complementary slackness](#-complementary-slackness) + [5.2. KKT optimality conditions](#-kkt-optimality-conditions) - [5.2.1. KKT condition cho bài toán *không* lồi](#-kkt-condition-cho-bai-toan-khong-loi) - [5.2.2. KKT conditions cho bài toán lồi](#-kkt-conditions-cho-bai-toan-loi) * [5. Tóm tắt](#-tom-tat) * [6. Kết luận](#-ket-luan) * [7. Tài liệu tham khảo](#-tai-lieu-tham-khao) **Trong bài viết này, chúng ta giả sử rằng các đạo hàm tồn tại.** **Bài viết này chủ yếu được dịch lại từ Chương 5 của cuốn *Convex Optimization* trong tài liệu tham khảo.** Bạn đọc có thể xem bản pdf [tại đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/latex/book_CVX.pdf). *Nếu bạn gặp khó khăn trong việc hiểu đạo hàm trong bài viết này, bạn được khuyến khích đọc [Đạo hàm của hàm nhiều biến](/math/#-dao-ham-cua-ham-nhieu-bien). Ngoài ra, các kiến thức trong [Bài 16](/2017/03/12/convexity/) và [Bài 17](/2017/03/19/convexopt/) là quan trọng để hiểu rõ hơn bài viết này.*",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "29.main-2",
        "source": "29.main.md",
        "section": "1. Giới thiệu",
        "content": "Trong [Bài 16](/2017/03/12/convexity/), chúng ta đã làm quen với các khái niệm về tập hợp lồi và hàm số lồi. Tiếp theo đó, trong [Bài 17](/2017/03/19/convexopt/), tôi cũng đã trình bày về các bài toán tối ưu lồi, cách nhận dạng và cách sử dụng thư viện để giải các bài toán lồi cơ bản. Trong bài này, chúng ta sẽ tiếp tục tiếp cận một cách sâu hơn: các điều kiện về nghiệm của các bài toán tối ưu, cả lồi và không lồi; bài toán đối ngẫu (dual problem) và điều kiện KKT. Trước tiên, chúng ta lại bắt đầu bằng những kỹ thuật đơn giản cho các bài toán cơ bản. Kỹ thuật này có lẽ các bạn đã từng nghe đến: Phương pháp nhân tử Lagrange (method of [Lagrange multipliers](https://en.wikipedia.org/wiki/Lagrange_multiplier)). Đây là một phương pháp giúp tìm các điểm cực trị của hàm mục tiêu trên feasible set của bài toán. Nhắc lại rằng giá trị lớn nhất và nhỏ nhất (nếu có) của một hàm số \\(f\\_0(\\mathbf{x})\\) khả vi (và tập xác định là một [*tập mở*](https://en.wikipedia.org/wiki/Open_set)) đạt được tại một trong các điểm cực trị của nó. Và điều kiện cần để một điểm là điểm cực trị là đạo hàm của hàm số tại điểm này \\(f\\_0’(x) = 0\\). Chú ý rằng một điểm thoả mãn \\(f\\_0’(\\mathbf{x})\\) = 0 thì được gọi là *điểm dừng* hay *stationary point*. Điểm cực trị là một điểm dừng nhưng không phải điểm dừng nào cũng là điểm cực trị. Ví dụ hàm \\(f(x) = x^3\\) có \\(0\\) là một điểm dừng nhưng không phải là điểm cực trị. Với hàm nhiều biến, ta cũng có thể áp dụng quan sát này. Tức chúng ta cần đi tìm nghiệm của phương trình đạo hàm *theo mỗi biến* bằng 0. Tuy nhiên, đó là với các bài toán không ràng buộc (unconstrained optimization problems), với các bài toán có ràng buộc như chúng ta đã gặp trong Bài 17 thì sao? Trước tiên chúng ta xét bài toán mà ràng buộc chỉ là một phương trình: \\[ \\begin{eqnarray} \\mathbf{x}=& \\arg\\min\\_{\\mathbf{x}} f\\_0(\\mathbf{x}) \\newline \\text{subject to:}~& f\\_1(\\mathbf{x}) = 0~~~~~~~~~(1) \\end{eqnarray} \\] Bài toán này là bài toán tổng quát, không nhất thiết phải lồi. Tức hàm mục tiêu và hàm ràng buộc không nhất thiết phải lồi.",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "29.main-3",
        "source": "29.main.md",
        "section": "2. Phương pháp nhân tử Lagrange",
        "content": "Nếu chúng ta đưa được bài toán này về một bài toán không ràng buộc thì chúng ta có thể tìm được nghiệm bằng cách giải hệ phương trình đạo hàm theo từng thành phần bằng 0 (giả sử rằng việc giải hệ phương trình này là khả thi). Điều này là động lực để nhà toán học [Lagrange](https://en.wikipedia.org/wiki/Joseph-Louis_Lagrange) sử dụng hàm số: \\(\\mathcal{L}(\\mathbf{x}, \\lambda) = f\\_0(\\mathbf{x}) + \\lambda f\\_1(\\mathbf{x})\\). Chú ý rằng, trong hàm số này, chúng ta có thêm một biến nữa là \\(\\lambda\\), biến này được gọi là nhân tử Lagrange (Lagrange multiplier). Hàm số \\(\\mathcal{L}(\\mathbf{x}, \\lambda)\\) được gọi là *hàm hỗ trợ* (*auxiliary function*), hay *the Lagrangian*. Người ta đã chứng minh được rằng, điểm *optimal value* của bài toán \\((1)\\) thoả mãn điều kiện \\(\\nabla\\_{\\mathbf{x}, \\lambda} \\mathcal{L}(\\mathbf{x}, \\lambda) = 0\\) (tôi xin được bỏ qua chứng minh của phần này). Điều này tương đương với: \\[ \\begin{eqnarray} \\nabla\\_{\\mathbf{x}}f\\_0(\\mathbf{x}) + \\lambda \\nabla\\_{\\mathbf{x}} f\\_1(\\mathbf{x}) &=& 0~~~~(2) \\newline f\\_1(\\mathbf{x}) & = & 0 ~~~~(3) \\end{eqnarray} \\] Để ý rằng điều kiện thứ hai chính là \\(\\nabla\\_{\\lambda}\\mathcal{L}(\\mathbf{x}, \\lambda) = 0\\), và cũng chính là ràng buộc trong bài toán \\((1)\\). Việc giải hệ phương trình \\((2) - (3)\\), trong nhiều trường hợp, đơn giản hơn việc trực tiếp đi tìm *optimal value* của bài toán \\((1)\\). Xét các ví dụ đơn giản sau đây.",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "29.main-4",
        "source": "29.main.md",
        "section": "Ví dụ",
        "content": "**Ví dụ 1:** Tìm giá trị lớn nhất và nhỏ nhất của hàm số \\(f\\_0(x, y) = x + y\\) thoả mãn điều kiện \\(f\\_1(x, y) = x^2 + y^2 = 2\\). Ta nhận thấy rằng đây không phải là một bài toán tối ưu lồi vì *feasible set* \\(x^2 + y^2 = 2\\) không phải là một tập lồi (nó chỉ là một đường tròn). ***Lời giải:*** *Lagrangian* của bài toán này là: \\(\\mathcal{L}(x, y, \\lambda) = x + y + \\lambda(x^2 + y^2 - 2)\\). Các điểm cực trị của hàm số Lagrange phải thoả mãn điều kiện: \\[ \\nabla\\_{x, y, \\lambda} \\mathcal{L}(x, y, \\lambda) = 0 \\Leftrightarrow \\left\\{ \\begin{matrix} 1 + 2\\lambda x &= 0~~~ (4) \\newline 1 + 2\\lambda y &= 0~~~ (5) \\newline x^2 + y^2 &= 2 ~~~~(6) \\end{matrix} \\right. \\] Từ \\((4)\\) và \\((5)\\) ta suy ra \\(x = y = \\frac{-1}{2\\lambda}\\). Thay vào \\((6)\\) ta sẽ có \\(\\lambda^2 = \\frac{1}{4} \\Rightarrow \\lambda = \\pm \\frac{1}{2}\\). Vậy ta được 2 cặp nghiệm \\((x, y) \\in \\{(1, 1), (-1, -1)\\}\\). Bằng cách thay các giá trị này vào hàm mục tiêu, ta tìm được giá trị nhỏ nhất và lớn nhất của hàm số cần tìm. **Ví dụ 2: Cross-entropy**. Trong [Bài 10](/2017/01/27/logisticregression/) và [Bài 13](/2017/02/17/softmax/), chúng ta đã được biết đến hàm mất mát ở dạng [*cross entropy*](/2017/02/17/softmax/#-cross-entropy). Chúng ta cũng đã biết rằng hàm cross entropy được dùng để đo sự giống nhau của hai phân phối xác suất với giá trị của hàm số này càng nhỏ thì hai xác suất càng gần nhau. Chúng ta cũng đã phát biểu rằng giá trị nhỏ nhất của hàm cross entropy đạt được khi từng cặp xác suất là giống nhau. Bây giờ, tôi xin phát biểu lại và chứng minh nhận định trên. Cho một phân bố xác xuất \\(\\mathbf{p} = [p\\_1, p\\_2, \\dots, p\\_n]^T\\) với \\(p\\_i \\in [0, 1]\\) và \\(\\sum\\_{i=1}^n p\\_i = 1\\). Với một phân bố xác suất bất kỳ \\(\\mathbf{q} = [q\\_1, q\\_2, \\dots, q\\_n]\\) và giả sử rằng \\(q\\_i \\neq 0, \\forall i\\), hàm số cross entropy được định nghĩa là: \\[ f\\_0(\\mathbf{q}) = -\\sum\\_{i=1}^n p\\_i \\log(q\\_i) \\] Hãy tìm \\(\\mathbf{q}\\) để hàm cross entropy đạt giá trị nhỏ nhất. Trong bài toán này, ta có ràng buộc là \\(\\sum\\_{i=1}^n q\\_i = 1\\). *Lagrangian* của bài toán là: \\[ \\mathcal{L}(q\\_1, q\\_2, \\dots, q\\_n, \\lambda) = -\\sum\\_{i=1}^n p\\_i \\log(q\\_i) + \\lambda(\\sum\\_{i=1}^n q\\_i - 1) \\] Ta cần giải hệ phương trình: \\[ \\nabla\\_{q\\_1, \\dots, q\\_n, \\lambda} \\mathcal{L}(q\\_1, \\dots, q\\_n, \\lambda) = 0 \\Leftrightarrow \\left\\{ \\begin{matrix} -\\frac{p\\_i}{q\\_i} + \\lambda &=& 0, ~~ i = 1, \\dots, n ~~~(7)\\newline q\\_1 + q\\_2 + \\dots + q\\_n &=& 1 ~~~~~~ (8) \\end{matrix} \\right. \\] Từ \\((7)\\) ta có \\(p\\_i = \\lambda q\\_i\\). Vậy nên: \\( 1 = \\sum\\_{i=1}^n p\\_i = \\lambda\\sum\\_{i=1}^n q\\_i = \\lambda \\Rightarrow \\lambda = 1 \\Rightarrow q\\_i = p\\_i, \\forall i\\). Qua đây, chúng ta đã hiểu rằng vì sao hàm số cross entropy được dùng để *ép* hai xác suất *gần nhau*.",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "29.main-5",
        "source": "29.main.md",
        "section": "3.1. Lagrangian",
        "content": "Với bài toán tối ưu tổng quát: \\[ \\begin{eqnarray} \\mathbf{x}^\\* &=& \\arg\\min\\_{\\mathbf{x}} f\\_0(\\mathbf{x}) \\newline \\text{subject to:}~ && f\\_i(\\mathbf{x}) \\leq 0, ~~ i = 1, 2, \\dots, m ~~~(9)\\newline && h\\_j(\\mathbf{x}) = 0, ~~ j = 1, 2, \\dots, p \\end{eqnarray} \\] với miền xác đinh \\(\\mathcal{D} = (\\cap\\_{i=0}^m \\text{dom}f\\_i) \\cap (\\cap\\_{j=1}^p \\text{dom}h\\_j)\\). Chú ý rằng, chúng ta đang không giả sử về tính chất lồi của hàm tối ưu hay các hàm ràng buộc ở đây. Giả sử duy nhất ở đây là \\(\\mathcal{D} \\neq \\emptyset\\) (tập rỗng). *Lagrangian* cũng được xây dựng tương tự với mỗi nhân tử Lagrange cho một (bất) phương trình ràng buộc: \\[ \\mathcal{L}(\\mathbf{x}, \\lambda, \\nu) = f\\_0(\\mathbf{x}) + \\sum\\_{i=1}^m \\lambda\\_if\\_i(\\mathbf{x}) + \\sum\\_{j=1}^p \\nu\\_j h\\_j(\\mathbf{x}) \\] với \\(\\lambda = [\\lambda\\_1, \\lambda\\_2, \\dots, \\lambda\\_m]; \\nu = [\\nu\\_1, \\nu\\_2, \\dots, \\nu\\_p]\\) (*ký hiệu \\(\\nu\\) này không phải là chữ v mà là chữ nu trong tiếng Hy Lạp, đọc như từ new*) là các vectors và được gọi là *dual variables* (*biến đối ngẫu*) hoặc *Lagrange multiplier vectors* (vector nhân tử Lagrange). Lúc này nếu biến chính \\(\\mathbf{x} \\in \\mathbb{R}^n\\) thì tổng số biến của hàm số này sẽ là \\(n + m + p\\). (*Thông thường, tôi dùng các chữ cái viết thường in đậm để biểu diễn một vector, trong trường hợp này tôi không bôi đậm được \\(\\lambda\\) và \\(\\nu\\) do hạn chế của LaTeX khi viết cùng markdown. Tôi lưu ý điều này để hạn chế nhầm lẫn cho bạn đọc*)",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "29.main-6",
        "source": "29.main.md",
        "section": "3.2. Hàm đối ngẫu Lagrange",
        "content": "Hàm đối ngẫu Lagrange của bài toán tối ưu (hoặc gọn là *hàm số đối ngẫu*) \\((9)\\) là một hàm của các biến đối ngẫu, được định nghĩa là giá trị nhỏ nhất theo \\(\\mathbf{x}\\) của *Lagrangian*: \\[ \\begin{eqnarray} g(\\lambda, \\nu) &=& \\inf\\_{\\mathbf{x} \\in \\mathcal{D}} \\mathcal{L}(\\mathbf{x}, \\lambda, \\nu)\\newline &=& \\inf\\_{\\mathbf{x} \\in \\mathcal{D}}\\left( f\\_0(\\mathbf{x}) + \\sum\\_{i=1}^m \\lambda\\_if\\_i(\\mathbf{x}) + \\sum\\_{j=1}^p \\nu\\_j h\\_j(\\mathbf{x})\\right) \\end{eqnarray} \\] Nếu *Lagrangian không bị chặn dưới*, hàm đối ngẫu tại \\(\\lambda, \\nu\\) sẽ lấy giá trị \\(-\\infty\\). **Đặc biệt quan trọng:** * \\(\\inf\\) được lấy trên miền \\(x \\in \\mathcal{D}\\), tức miền xác định của bài toán (là giao của miền xác định của mọi hàm trong bài toán). Miền xác định này khác với *feasible set*. Thông thường, *feasible set* là tập con của miền xác định \\(\\mathcal{D}\\). * Với mỗi \\(\\mathbf{x}\\), *Lagrangian* là một hàm *affine* của \\((\\lambda, \\nu)\\), tức là một [hàm *concave*](/2017/03/12/convexity/#concave-function). Vậy, *hàm đối ngẫu* chính là *pointwise infimum* của (có thể vô hạn) các hàm concave, tức là một hàm concave. Vậy **hàm đối ngẫu của một bài toán tối ưu bất kỳ là một hàm concave, bất kể bài toán ban đầu có phải là convex hay không**. Nhắc lại rằng *pointwise supremum* của các hàm *convex* là một hàm *convex*, và một hàm là *concave* nếu khi đổi dấu hàm đó, ta được một hàm *convex*.",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "29.main-7",
        "source": "29.main.md",
        "section": "3.3. Chặn dưới của giá trị tối ưu",
        "content": "Nếu \\(p^\\*\\) là [*optimal value*](/2017/03/19/convexopt/#-cac-khai-niem-co-ban) (giá trị tối ưu) của bài toán \\((9)\\), thì với các biến đối ngẫu \\(\\lambda\\_i \\geq 0, \\forall i\\) và \\(\\nu\\) *bất kỳ*, chúng ta sẽ có: \\[ g(\\lambda, \\nu) \\leq p^\\*~~~~ (10) \\] Tính chất này có thể được chứng minh dễ dàng. Giả sử \\(\\mathbf{x}\\_0\\) là một điểm *feasible* bất kỳ của bài toán \\((9)\\), tức thoả mãn các điều kiện ràng buộc \\(f\\_i(\\mathbf{x}\\_0) \\leq 0, \\forall i = 1, \\dots, m; h\\_j(\\mathbf{x}\\_0) = 0, \\forall j = 1, \\dots, p\\), ta sẽ có: \\[ \\sum\\_{i=1}^m \\lambda\\_if\\_i(\\mathbf{x}\\_0) + \\sum\\_{j=1}^p \\nu\\_j h\\_j(\\mathbf{x}\\_0) \\leq 0 \\Rightarrow \\mathcal{L}(\\mathbf{x}\\_0, \\lambda, \\nu) \\leq f\\_0(\\mathbf{x}\\_0) \\] Vì điều này đúng với mọi \\(\\mathbf{x}\\_0\\) *feasible*, ta sẽ có tính chất quan trọng sau đây: \\[ g(\\lambda, \\nu) = \\inf\\_{\\mathbf{x} \\in \\mathcal{D}} \\mathcal{L}(\\mathbf{x}, \\lambda, \\nu) \\leq \\mathcal{L}(\\mathbf{x}\\_0, \\lambda, \\nu) \\leq f\\_0(\\mathbf{x}\\_0). \\] Khi \\(\\mathbf{x}\\_0 = \\mathbf{x}^\\*\\), ta có bất đẳng thức \\((10)\\).",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "29.main-8",
        "source": "29.main.md",
        "section": "Ví dụ 1",
        "content": "Xét bài toán tối ưu sau: \\[ \\begin{eqnarray} x=& \\arg\\min\\_{x} x^2 + 10\\sin(x) + 10 \\newline \\text{subject to:}~& (x-2)^2 \\leq 4 \\end{eqnarray} \\] Chú ý: Với bài toán này, miền xác định \\(\\mathcal{D} = \\mathbb{R}\\) nhưng *feasible set* là \\(0 \\leq x \\leq 4\\). Với hàm mục tiêu là đường đậm màu xanh lam trong Hình 1 dưới đây. Ràng buộc thực ra \\(0 \\leq x \\leq 4\\), nhưng tôi viết ở dạng này để bài toán thêm phần thú vị. Hàm số ràng buộc \\(f\\_1(x) = (x-2)^2 - 4\\) được cho bởi đường nét đứt màu xanh lục. Optimal value của bài toán này có thể được nhận ra là điểm trên đồ thị có hoành độ bằng 0. Chú ý rằng hàm mục tiêu ở đây không phải là hàm lồi nên bài toán tối ưu này cũng không phải là lồi, mặc dù hàm bất phương trình ràng buộc \\(f\\_1(x)\\) là lồi. *Lagrangian* của bài toàn này có dạng: \\[ \\mathcal{L}(x, \\lambda) = x^2 + 10\\sin(x) +10+ \\lambda((x-2)^2 - 4) \\] Các đường dấu chấm màu đỏ trong Hình 1 là các đường ứng với các \\(\\lambda \\) khác nhau. Vùng bị chặn giữa hai đường thẳng đứng màu đen thể hiện miền *feasible* của bài toán tối ưu. --- |  |  | | --- | --- | |  |  | Hình 1: Ví dụ về dual function. ---",
        "url": "https://machinelearningcoban.com/2017/04/02/duality/"
    },
    {
        "id": "39.main-1",
        "source": "39.main.md",
        "section": "Introduction",
        "content": "![](http://sebastianruder.com/content/images/2016/09/contours_evaluation_optimizers.gif) Tốc độ hội tụ của các thuật toán GD khác nhau. (Nguồn  An overview of gradient descent optimization algorithms). Trong [phần 1](/2017/01/12/gradientdescent/) của Gradient Descent (GD), tôi đã giới thiệu với bạn đọc về thuật toán Gradient Descent. Tôi xin nhắc lại rằng nghiệm cuối cùng của Gradient Descent phụ thuộc rất nhiều vào điểm khởi tạo và learning rate. Trong bài này, tôi xin đề cập một vài phương pháp thường được dùng để khắc phục những hạn chế của GD. Đồng thời, các thuật toán biến thể của GD thường được áp dụng trong các mô hình Deep Learning cũng sẽ được tổng hợp. **Trong trang này:** * [1. Các thuật toán tối ưu Gradient Descent](#-cac-thuat-toan-toi-uu-gradient-descent) + [1.1 Momentum](#-momentum) - [Nhắc lại thuật toán Gradient Descent](#nhac-lai-thuat-toan-gradient-descent) - [Gradient dưới góc nhìn vật lý](#gradient-duoi-goc-nhin-vat-ly) - [Gradient Descent với Momentum](#gradient-descent-voi-momentum) - [Một ví dụ nhỏ](#mot-vi-du-nho) + [1.2. Nesterov accelerated gradient (NAG)](#-nesterov-accelerated-gradient-nag) - [Ý tưởng chính](#y-tuong-chinh) - [Công thức cập nhật](#cong-thuc-cap-nhat) - [Ví dụ minh họa](#vi-du-minh-hoa) + [1.3. Các thuật toán khác](#-cac-thuat-toan-khac) * [2. Biến thể của Gradient Descent](#-bien-the-cua-gradient-descent) + [2.1. Batch Gradient Descent](#-batch-gradient-descent) + [2.2. Stochastic Gradient Descent.](#-stochastic-gradient-descent) - [Ví dụ với bài toán Linear Regression](#vi-du-voi-bai-toan-linear-regression) + [2.3. Mini-batch Gradient Descent](#-mini-batch-gradient-descent) * [3. Stopping Criteria (điều kiện dừng)](#-stopping-criteria-dieu-kien-dung) * [4. Một phương pháp tối ưu đơn giản khác: Newton’s method](#-mot-phuong-phap-toi-uu-don-gian-khac-newtons-method) + [Newton’s method cho giải phương trình \\(f(x) = 0\\)](#newtons-method-cho-giai-phuong-trinh-\\\\fx--\\\\) + [Newton’s method trong bài toán tìm local minimun](#newtons-method-trong-bai-toan-tim-local-minimun) + [Hạn chế của Newton’s method](#han-che-cua-newtons-method) * [5. Kết luận](#-ket-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/01/16/gradientdescent2/"
    },
    {
        "id": "39.main-2",
        "source": "39.main.md",
        "section": "Nhắc lại thuật toán Gradient Descent",
        "content": "Dành cho các bạn chưa đọc [phần 1](/2017/01/12/gradientdescent/) của Gradient Descent. Để giải bài toán tìm điểm *global optimal* của hàm mất mát \\(J(\\theta)\\) (Hàm mất mát cũng thường được ký hiệu là \\(J()\\) với \\(\\theta\\) là tập hợp các tham số của mô hình), tôi xin nhắc lại thuật toán GD: --- **Thuật toán Gradient Descent:** 1. Dự đoán một điểm khởi tạo \\(\\theta = \\theta\\_0\\). 2. Cập nhật \\(\\theta\\) đến khi đạt được kết quả chấp nhận được: \\[ \\theta = \\theta - \\eta \\nabla\\_{\\theta}J(\\theta) \\] với \\(\\nabla\\_{\\theta}J(\\theta)\\) là đạo hàm của hàm mất mát tại \\(\\theta\\). ---",
        "url": "https://machinelearningcoban.com/2017/01/16/gradientdescent2/"
    },
    {
        "id": "13.main-1",
        "source": "13.main.md",
        "section": "Introduction",
        "content": "* [1. Review papers](#-review-papers) + [1.1. Associate Editor](#-associate-editor) + [1.2. Các quyết định của Associate Editor](#-cac-quyet-dinh-cua-associate-editor) + [1.3. Các tiêu chí đánh giá](#-cac-tieu-chi-danh-gia) * [2. Viết papers](#-viet-papers) + [2.1. Giai đoạn 1: Lên ý tưởng và trình bày trong và ngoài lab](#-giai-doan--len-y-tuong-va-trinh-bay-trong-va-ngoai-lab) + [2.2. Giai đoạn 2: conference paper](#-giai-doan--conference-paper) + [2.3. Giai đoạn 3: Nộp và sửa journal paper](#-giai-doan--nop-va-sua-journal-paper) + [2.4. Thời hạn cho mỗi vòng bình luận/phản hồi:](#-thoi-han-cho-moi-vong-binh-luanphan-hoi) + [2.5. Một vài điểm khác](#-mot-vai-diem-khac)",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-2",
        "source": "13.main.md",
        "section": "1. Review papers",
        "content": "Khi học PhD, chúng tôi có thể phải làm một nhiệm vụ là review các paper được viết bởi các tác giả khác. Dạo này chậm ra bài, tôi xin chia sẻ với các bạn một chút về cuộc sống PhD của mình. Hy vọng giúp các bạn hiểu thêm về cuộc sống của những người làm nghiên cứu như tôi. Một chút xíu thôi.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-3",
        "source": "13.main.md",
        "section": "1.1. Associate Editor",
        "content": "Thông thường, khi nộp một paper lên các tạp chí, paper đó sẽ được chuyển tới một Associate Editor (AE). AE này sẽ ‘nhờ’ khoảng 3 reviewers để ‘chấm điểm’ cho paper này. Giáo sư hướng dẫn của tôi là AE cho một vài tạp chí lớn. Và tôi đã bị ‘chỉ định’ làm reviewer cho khoảng trên dưới 30 bài transaction. Một vài trong số đó là các paper hay, phần lớn là các paper tệ. Tỉ lệ acceptance của các tạp chí này cũng thấp (1/6-1/4) nên đó cũng là chuyện dễ hiểu. Vì thế, tôi cũng không thích review lắm vì khá mất thời gian. Những reviewers được AE ‘mời’ sẽ được giấu tên, chỉ có AE mới biết mỗi reviewer này ai. Sau khi hoàn tất review một bài báo, AE sẽ rate các reviewers. Như vậy là sẽ có một bảng ranking của các reviewer ở đâu đó. Lần tới, một AE khác sẽ lựa chọn từ bảng ranking đó và tìm các reviewers có background liên quan để mời review. Để có những nhận xét đa chiều, giáo sư của tôi thường chọn 3 đối tượng reviewers: 1. Senior PhDs, tức những sinh viên PhD như tôi đã có bài báo được published; 2. Những sinh viên PhD mới tốt nghiệp được vài năm, thường là Postdoc; 3. Các giáo sư khác hoặc những người làm nghiên cứu lâu năm. Ba nhóm reviewers này thường có những cách đánh giá khác nhau. Nhóm thứ nhất thường để ý tới các phương trình toán, kiểm tra chính tả ngữ pháp các kiểu. Ban đầu vì chưa có kinh nghiệm nên tôi kiểm tra các phương trình rất kỹ xem có lỗi gì không. Vì chẳng lẽ mình review mà không viết được cái gì :D. Một điểm cũng rất lo lắng là liệu quyết định của mình có lệch quá so với các reviewers khác không (mình cho Chấp nhận mà những người khác cho Từ chối thì cũng không được). Nhóm thứ ba thường quan tâm tới bức tranh lớn (big picture). Họ thường quan tâm tới ý tưởng chính của paper và đưa ra nhận xét. Họ cũng biết nhiều các paper khác nên việc kiểm chứng novelty của paper cũng là việc tương đối đơn giản. Các bác này có lẽ không đọc các phương trình làm gì. Nhớm thứ hai thì có cái nhìn ở giữa nhóm thứ nhất và thứ ba.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-4",
        "source": "13.main.md",
        "section": "1.2. Các quyết định của Associate Editor",
        "content": "Dựa trên bình luận và quyết định của các reviewer, AE sẽ ra quyết định cuối cùng, thường có mấy lựa chọn sau: 1. Chấp nhận (A - Publish Unaltered) 2. Chấp nhận với chỉnh sửa nhỏ (AQ - Minor revision) 3. Chỉnh sửa lớn (RQ - Major revision) 4. Từ chối ngay (R - Reject) Rất ít khi có một paper được A ngay ở lần nộp đầu tiên, thậm chí là AQ. Các reviewer bao giờ cũng cố tìm ra một điểm nào đó để ‘khuyên’ tác giả thay đổi một chút. Cũng gọi là có công của mình trong quá trình review. Tần số để 1 paper nhận R ngay từ lần đầu cao hơn một chút nếu paper không có điểm gì mới, tiếng Anh tệ, các công thức toán không rõ ràng, hoặc/và hình vẽ không rõ ràng. Chủ yếu các paper sẽ nhận được RQ từ vòng đầu, tức yêu cầu thay đổi và trả lời các câu hỏi của reviewers trước khi có quyết định ở vòng tiếp theo từ AE. Các tạp chí lớn thường không cho phép 2 lần RQ liên tiếp. RQ hai lần liên tiếp là sẽ coi như bị R.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-5",
        "source": "13.main.md",
        "section": "1.3. Các tiêu chí đánh giá",
        "content": "Các tiêu chí để đánh giá một paper thường là: * Importance / Relevance: Chủ đề của bài báo có phù hợp với tạp chí không. * Novelty: ý tưởng trong bài báo có mới không, có lặp lại hoặc được xào nấu từ các bài báo trước đây không. * Clarity of Presentation: Cách trình bày có rõ ràng, khoa học, dễ hiểu không. Các hình vẽ, bảng, biểu đồ có giúp người đọc hiểu rõ hơn về bài báo hay không. * Experimental Validation: Các kết quả thực nghiệm có chứng minh rằng ý tưởng của bài báo là tốt không. * Technical Correctness: Các vấn đề kỹ thuật được nêu trong bài báo có chuẩn xác không. Việc này bao gồm cả các công thức toán. Tiêu chuẩn mà tôi thấy khó đánh giá nhất là Novelty. Ranh giới giữa ‘simple but effective’ và ‘minor novelty/ not original’ là rất mong manh. Nhiều khi việc cải tiến một chút xíu làm cho một mô hình nổi tiếng khác đơn giản hơn làm cho hệ thống hoạt động khá hiệu quả. Nhưng ngược lại, việc đó cũng có thể được coi là ‘không có tính sáng tạo, không có gì mới’. Việc này tuỳ thuộc rất nhiều vào trạng thái tâm lý tình cảm của reviewer. Ngày mới làm review, tôi thường đọc bài rất kỹ. Tôi xem ý tưởng có bị lặp không, các công thức có sai sót gì không, hình vẽ có đẹp không :D, tiếng Anh có phải sửa không, … Thậm chí, tôi còn quan tâm tới việc paper có được soạn thảo bằng LaTeX hay không (đọc các công thức toán được soạn bằng Word rất là nản, xin lỗi các bạn). Và tôi từng là một ‘tough reviewer’, cho rất nhiều bài RQ hoặc R. Thật là có lỗi. Hôm nay tôi review một bài ở một tạp chí cũng tương đối lớn (một bài Signal Processing Letter). Bài này tôi đã từng review và cho R. Đây là bài nộp lại kèm theo phản hồi tới những comments của tôi ở lần review trước. Ý tưởng của bài này rất đơn giản, chỉ sửa một chút và việc sửa này cũng không có gì là sáng tạo, chỉ là vay mượn từ các mô hình khác. Quả thật, nghĩ ra một cái hoàn toàn mới là cực kỳ khó! Ở lần review thứ nhất cách đây 2 tháng, tôi đã cho R cũng vì tính ‘not novel’ này. Nhưng hôm nay nhân một ngày mát trời, sau khi đọc lại rất kỹ paper này, tôi đã quyết định cho AQ. Tôi cũng nói riêng với AE rằng tôi thay đổi quyết định từ R lên AQ vì ý tưởng của bài báo rất đơn giản nhưng đã giúp cho mô hình linh hoạt và thời gian huấn luyện giảm đi khá nhiều, đồng thời kết quả cũng tốt. Tôi chưa cho A vì kết quả chưa được mô tả đẹp lắm. Có một vài bảng kết quả nên được vẽ dưới dạng biểu đồ cột. Các tác giả đã may mắn vì hôm nay chỗ tôi có một cơn mưa rào lớn lúc chập tối. Ranh giới giữa Chấp nhận và Từ chối đôi khi rất mong manh, có thể phụ thuộc vào thời tiết. Cùng một ý tưởng, cùng một kết quả nhưng cách viết thế nào cũng rất quan trọng.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-6",
        "source": "13.main.md",
        "section": "2. Viết papers",
        "content": "Điều kiện để chúng tôi tốt nghiệp bậc học PhD là phải có một lượng các bài báo khoa học. Tuỳ từng trường, tuỳ từng thầy mà yêu cầu về số lượng tối thiểu các bài báo là khác nhau. Trong lab của tôi, chúng tôi cần ba bài journal papers. Tại thời điểm bảo vệ tốt nghiệp, chúng tôi cần có ít nhất hai bài đã được chấp nhận và một bài đã được nộp chờ phản hồi. Có hai loại bài báo khoa học chính: conference papers và journal/transaction papers. Hiểu một cách đơn giản, conference papers là các papers được nộp vào các hội nghị khoa học. Sau khi bài báo được chấp nhận, chúng tôi cần đến tham dự hội nghị đó và trình bày về bài báo, thường dưới dạng poster hoặc lecture presentation. Tôi sẽ nói về hài loại presentations này khi có dịp. Về độ dài, thường có hai loại: 4 trang + 1 trang references hoặc 8 trang + 1 trang references. **Trong bài viết này, tôi sẽ viết về loại 4 trang + 1. Loại 8 trang + 1 hoặc dài hơn sẽ khó hơn nhiều, thậm chí còn khó hơn journal.** Journal papers là các bài được nộp vào các tạp chí khoa học. Chúng tôi không cần đến dự hội nghị nào mà chỉ cần nộp và qua một vài lần nhận xét. Sau đó AE ra quyết định xem bài có được chấp nhận hay không. Bảng dưới đây mô tả sự khác nhau cơ bản giữa loại conference paper (4 trang + 1) và journal paper. |  | Conference paper | Journal paper | | --- | --- | --- | | Độ dài (tối đa) | 4 trang + 1 | > 10 trang | | Deadline | thường là 1 năm 1 lần | không có deadline | | Số vòng đánh giá | thường là 1 | có thể nhiều hơn 1 | | Thời gian để biết kết quả | ~ 3-4 tháng | 6 tháng - 1 năm, hoặc hơn | | Độ khó | dễ hơn | khó hơn | | Yêu cầu chất lượng | thấp hơn | cao hơn | Với mỗi một ý tưởng, cái đích cuối cùng của chúng tôi là viết một journal paper. Trên đường tới đích, chúng tôi cần viết 1 bài conference cho cùng ý tưởng đó. Cho tới khi viết journal paper, chúng tôi thường phải trình bày ý tưởng của mình nhiều lần trong và ngoài lab. Quá trình viết một journal paper thường gồm 3 giai đoạn.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-7",
        "source": "13.main.md",
        "section": "2.1. Giai đoạn 1: Lên ý tưởng và trình bày trong và ngoài lab",
        "content": "Ở trong lab, chúng tôi có Group Meetings (GM) được tổ chức hàng tuần vào chiều Thứ Sáu. Mỗi tuần sẽ có 1-2 thành viên trong lab trình bày về công việc mình đang làm trước giáo sư và toàn lab. Trừ người trình bày, chúng tôi thường rất thích các buổi GM này vì cả lab được gặp nhau và ngồi dưới bắt nạt người trình bày. Chúng tôi được khuyến khích đặt câu hỏi để sự tương tác giữa các thành viên vào 1 vấn đề lớn hơn. Ngay khi có ý tưởng, tôi thường nóng lòng xin giáo sư cho trình bày trong lần GM trống gần nhất. Vì khi có ý tưởng mới là lúc chúng ta cảm thấy ‘excited’ nhất, muốn chia sẻ nhất để xem mọi người nhận xét thế nào. Ở lần trình bày thứ nhất, thường là đề xuất ý tưởng, chúng tôi sẽ nhận được phản hồi từ giáo sư về tính novelty và tính khả thi của ý tưởng. Nếu mọi việc thuận lợi, chúng tôi sẽ làm experiment và trình bày thêm khoảng 1-2 lần nữa. Sau khi có kết quả, chúng tôi sẽ quyết định nộp bài vào conference nào cho kịp thời gian. Đồng thời, cũng phải lựa xem phần nào nên viết trong conference, phần nào nên để lại cho journal. Journal paper, mặc dù được phát triển từ conference paper, cần có những điểm mới riêng biệt mà conference paper không có. Nếu có dịp, ví dụ như các hội nghị sinh viên nghiên cứu khoa học ở trường, chúng tôi sẽ mang ý tưởng ra trình bày và nhận các phản hồi trong trường. Phần này thường không mang nhiều ý nghĩa vì trong trường thường ít người biết về nghiên cứu của chúng tôi.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-8",
        "source": "13.main.md",
        "section": "2.2. Giai đoạn 2: conference paper",
        "content": "Với conference paper, vì là một bài ngắn nên paper chủ yếu là chia sẻ ý tưởng và một vài kết quả cơ bản. Sau khi nộp bài cho conference, chúng tôi phải bắt tay vào làm thêm experiment, phân tích thuật toán, cải thiện tốc độ và thêm một vài chứng minh toán cần thiết. Và hy vọng bài conference paper vừa nộp được Chấp nhận. Thật may mắn cho tôi là các papers của tôi chưa bao giờ bị Từ chối. Sau 3-4 tháng kể từ nộp, tới khi nhận được kết quả của bài conference, tôi sẽ nhận được các nhận xét của các reviewers. Dựa trên các nhận xét đó, tôi bắt tay vào lên dàn ý và bắt đầu viết journal paper. Lý tưởng nhất, tới khi conference diễn ra, thường là 3-4 tháng nữa sau đó, tôi phải hoàn thành bản nháp đầu tiên cho bài journal paper. Tại conference, nội dung của poster hoặc slide sẽ dựa trên bản journal paper mà không phải conference paper nữa. Dựa trên phản hồi của khán giả, chúng tôi sẽ sửa đổi journal paper thêm một lần nữa trước khi nộp.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-9",
        "source": "13.main.md",
        "section": "2.3. Giai đoạn 3: Nộp và sửa journal paper",
        "content": "Có một điểm tôi muốn đề cập là bản nộp lần đầu tiên thường không được vượt quá một số lượng trang nào đó. Ví dụ là 12 đối với bài IEEE Transactions on Image Processing (TIP) tôi nộp gần đây. Ở lần đầu, các reviewers không muốn tác giả viết quá nhiều. Làm sao gói gọn trong 12 trang là được. Sau lần đầu thì giới hạn là 16 trang. Thêm một điểm nữa, các reviewers thường không bao giờ hài lòng ở lần review đầu tiên. Bao giờ họ cũng yêu cầu mình làm thêm experiment này nọ, giải thích rõ hơn về ý tưởng và thêm một vài chứng minh khác. Ở bản cuối cùng, nhà xuất bản cũng mong mình viết nhiều để họ còn thu thêm tiền quá trang, vì chỉ 10 trang đầu tiên là miễn phí. Mỗi trang sau trang thứ 10 sẽ bị tính thêm $200-$300 nữa. Thế đấy, viết bài đã không được nhuận bút mà còn phải trả thêm để được xuất bản. Và nghèo thì không làm khoa học được. Dựa trên quan sát này, ở lần nộp thứ nhất, chúng tôi thường để lại một vài thí nghiệm mà biết chắc reviewers sẽ hỏi. Sau vòng thứ nhất, hy vọng chưa bị reject, chúng tôi sẽ thêm những ý kia vào sau. Có một điều tôi hay thấy là có những reviewers không thực sự hiểu ý tưởng của mình vì có thể họ không quen với lĩnh vực đó. Họ hay có những nhận xét chung chung kiểu như: A, bài này không khác bài conference là mấy; Với tập training nhỏ hơn thì kết quả thế nào; khi tham số mô hình thay đổi thì kết quả có tốt không; độ phức tạp của thuật toán là ntn. Những bình luận như thế này thường rất dễ trả lời :). Khi phản hổi lại bình luận của reviewers, chúng tôi phải trả lời TỪNG Ý một. Phải thêm bớt vào bài báo sao cho mỗi reviewer đều cảm thấy các thắc mắc của mình đề đã được giải đáp triệt để. Nếu bạn làm họ hài lòng, thường ở lần thứ hai họ sẽ chấp nhận bài báo, vì cũng không muốn mất thêm thời gian vào việc review bài này nữa :). Thi thoảng có những bình luận không được xác đáng, thầy tôi sẽ là người trực tiếp viết phản hồi. Tôi vẫn thường nhớ câu của thầy: *We politely but strongly disagree with the reviewer that blah blah* . Đọc câu này, các reviewer thường chột dạ, cũng sợ là mình nói gì đó sai sai, nên lần tới không dám nói bậy nữa. Tất nhiên, phải ở một trình độ rất cao mới dám viết một câu như thế này.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-10",
        "source": "13.main.md",
        "section": "2.4. Thời hạn cho mỗi vòng bình luận/phản hồi:",
        "content": "Ở lần nộp đầu tiên, các reviewers thường được nhắc là có 6 tuần để gửi bình luận. Nhưng thường là các bác để lâu, có khi tới 5-6 tháng. Với reviewers, họ có quyền sinh sát nên chẳng quan tâm việc quá deadline. AE cũng phải ‘nhờ’ họ làm mà. Khi làm reviewer, tôi thường luôn làm đúng hẹn. Vì thường chỉ mất vài tiếng để hoàn thành, làm xong thì mình bớt đi 1 mục ở to-do list. Nếu tới 5-6 tháng mà vẫn chưa có phản hồi, chúng tôi thường gửi một email ngắn nhắc nhở lịch sự tới AE. Thường thì sau khi nhắc, các AE sẽ thúc reviewers làm việc luôn và vài ngày sau sẽ có kết quả. Sau khi có kết quả vòng 1 mà vẫn chưa bị Reject, chúng tôi có 6 tuần để trả lời tất cả các thắc mắc và nộp lại. Chúng tôi phải nộp 2 bản: 1 bản là bản sửa của bài báo, 1 bản là bản phản hồi tới các reviewers. Tốt nhất là làm xong trong 6 tuần, đừng có để lâu như các reviewers, chúng ta không có quyền đó. Nếu cảm thấy làm không kịp thì xin AE thêm extension. Tôi chưa xin bao giờ. Chú ý rằng phải viết thế nào để không làm phật lòng các reviewer và cho họ thấy rằng mình đã rất nỗ lực sửa bài báo theo ý của họ. Chú ý highlight những phần thay đổi so với vòng một để reviewers không mất thời gian đọc lại những phần cũ nữa. Hai bài journal papers tôi từng viết đều được chấp nhận ở vòng thứ hai này. Ở lần review thứ hai, các reviewers có 3 tuần để phản hồi vì họ đã quen với nội dung rồi. Và họ đôi khi cũng hay trì hoãn để tới vài tháng. May mắn cho tôi là bài đầu tiên tôi nhận kết quả Chấp nhận sau 3 tuần; bài thứ hai là sau 2 tháng, không tệ lắm.",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "13.main-11",
        "source": "13.main.md",
        "section": "2.5. Một vài điểm khác",
        "content": "Tôi có vài nguyên tắc khi trình bày bài viết: * Các hình vẽ là vũ khí quan trọng nhất. Tiếng Anh của mình không tốt nên nếu vẽ hình tốt để mô tả được ý tưởng thì reviewers sẽ rất thích. Về một vài tiêu chuẩn khi vẽ hình, các bạn có thể xem trong video của tôi dưới đây (*giọng của tôi bên ngoài khác trong video rất nhiều*) Lưu ý khi vẽ hình cho văn bản khoa học * Lời lẽ trong các bài phản hồi phải thật lịch sự. Phải luôn tránh làm reviewer bực bội vì họ nắm trong tay vận mệnh bài báo của mình :D. Một điểm lưu ý nữa là hình thức của bài phản hồi cũng cần được chau chuốt. * Các tài liệu nên được viết bằng LaTex vì nó hỗ trợ các công thức cũng như việc trích dẫn chéo rất tốt, và rất khoa học. Đã lâu rồi tôi không dùng các sản phẩm Microsoft Office để soạn thảo, chỉ dùng để đọc các tài liệu khác. (Tôi hơi bị định kiến với các sản phẩm của Microsoft, thường nặng và đắt). * Cố gắng publish mã nguồn nếu có thể. Việc có mã nguồn sẽ khiến các reviewers ‘tin tưởng’ vào bài của mình hơn. * Làm Literature review thật kỹ trước khi viết bài. Tránh trường hợp có một bài báo khác có ý tưởng gần giống với bài của mình và đã được xuất bản từ trước. Việc nộp bài vào một tạp chí và nhận phản hồi là miễn phí cho tới khi bài báo được Chấp nhận. Lợi dụng việc này, nhiều tác giả bắt đầu bằng việc nộp bài vào các tạp chí có thứ hạng cao hơn chất lượng của bài để nhận phản hồi; sau đó nếu bị Từ chối thì họ cũng đã có một bản tốt hơn với rất nhiều góp ý miễn phí và chất lượng. Sau đó đem bản này nộp tới tạp chí có thứ hạng thấp hơn. Tôi thực sự phản đối cách làm này. Tôi cho rằng các tác giả làm như thế là thiếu tôn trọng các reviewers và thiếu tôn trọng chính mình. Một mặt, nó lấy đi thời gian của rất nhiều người, bao gồm AE, các reviewers, các nhân viên trong tạp chí, và cũng trì hoãn việc được Chấp nhận của chính bài báo đó. Một mặt khác, khi nộp một bài chất lượng thấp vào một tạp chí lớn, giáo sư đứng kèm tên cho bài báo đó sẽ bị đồng nghiệp (AR và các reviewers) đánh giá thấp hơn. Thi thoảng tôi có gặp một vài bài ở các nhóm nghiên cứu có giáo sư nổi tiếng nhưng chất lượng rất tệ, có thể vì giáo sư đó bận nên không đọc kỹ bài. Giáo sư của tôi rất cẩn thận, ông đọc và trực tiếp sửa trên Latex cho tất cả các bài. Vì dù sao ông cũng là người đứng tên và tài trợ trung gian cho dự án. Một bài viết chưa thể nói hết ý về những công việc chúng tôi phải làm thường xuyên. Tôi cũng không gọi đây là bài chia sẻ kinh nghiệm mà chỉ là kể lại những gì chúng tôi gặp phải trong quá trình viết bài báo khoa học. Hy vọng rằng bài viết có ích cho các bạn. Thân mến, Tiệp Vũ",
        "url": "https://machinelearningcoban.com/2017/08/05/phdlife/"
    },
    {
        "id": "0.main-1",
        "source": "0.main.md",
        "section": "Introduction",
        "content": "* [1. Quá trình xin học PhD](#-qua-trinh-xin-hoc-phd) + [1.1. Quyết định học cao học](#-quyet-dinh-hoc-cao-hoc) + [1.2. Những khó khăn trước khi chuẩn bị](#-nhung-kho-khan-truoc-khi-chuan-bi) + [1.3. Quá trình lựa chọn trường và gửi hồ sơ](#-qua-trinh-lua-chon-truong-va-gui-ho-so) * [2. Quá trình lấy bằng PhD](#-qua-trinh-lay-bang-phd) + [2.1. Kỳ học PhD đầu tiên](#-ky-hoc-phd-dau-tien) + [2.2. Một năm rưỡi tiếp theo](#-mot-nam-ruoi-tiep-theo) + [2.3. Ba năm cuối](#-ba-nam-cuoi) + [2.4. Tôi làm gì ngoài thời gian nghiên cứu](#-toi-lam-gi-ngoai-thoi-gian-nghien-cuu) * [3. Khó khăn xuất hiện cuối chặng đường](#-kho-khan-xuat-hien-cuoi-chang-duong) * [4. Kết luận](#-ket-luan) * [5. Các bài viết liên quan](#-cac-bai-viet-lien-quan) Chuyện muốn đi du học của tôi đã nhen nhóm từ ngày lớp 9, nhưng tôi chưa từng có một kết hoạch đầy đủ cho tới khi tốt nghiệp đại học. Tôi chỉ biết rằng mình có học lực tốt và nhiều người khuyên tôi nên đi học nước ngoài. Nhưng học từ bậc nào, học ở đâu, học chuyên ngành nào thì tới tận khi tốt nghiệp đại học tôi mới định hình được.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-2",
        "source": "0.main.md",
        "section": "1.1. Quyết định học cao học",
        "content": "Tôi học chương trình Kỹ sư tài năng (KSTN) chuyên ngành Điện tử viễn thông ở Đại học Bách Khoa Hà Nội (BKHN). Trong những năm đầu, tôi được dạy tiếng Anh để thi TOEFL PBT – chỉ để có một chứng chỉ tiếng Anh giúp ích cho tương lai sau này. Ngữ pháp của tôi khá tốt, nhưng kỹ năng nghe và nói rất tệ. Năm thứ tư đại học, chương trình có thay đổi và yêu cầu để tốt nghiệp với bằng KSTN, chúng tôi cần có chứng chỉ TOEFL hoặc IELTS. Sau ba năm học TOEFL mà không thấy mình tiến bộ, tôi tình cờ tham gia học IELTS cùng một bạn và thấy mình phù hợp với chứng chỉ này hơn. Sau một năm ôn tập, tôi đạt 6.5 IELTS vào tháng 3/2012. Một số điểm vừa đủ để nộp hồ sơ vào các trường đại học ở Mỹ. Sau khi có điểm IELTS, thầy Nam – thầy hướng dẫn tôi ở BKHN – khuyến khích tôi nộp hồ sơ vào chương trình PhD của các trường đại học tại Mỹ và nhắc tôi tìm hiểu VEF. Tôi có nghe tới chương trình VEF từ lâu nhưng chưa bao giờ dám tìm hiểu xem họ yêu cầu những gì vì cho rằng chương trình này quá tầm với. Khi có điểm IELTS, tôi vẫn chưa có điểm GRE nên không thể hoàn thành hồ sơ VEF đúng hạn. Tôi đã nghĩ tới việc tìm học bổng ở Châu Âu, Hàn Quốc, hoặc Nhật vì nghĩ rằng các nơi đó phù hợp với khả năng của mình hơn. Tuy nhiên, thầy Nam nói vui với tôi rằng: “Hồ sơ của em đủ để đi Mỹ, thầy sẽ chỉ viết thư giới thiệu cho em nếu em chọn đi Mỹ”. Tôi tự tin hơn một chút và bắt đầu quyết tâm từ đó. Tuy vậy, tôi vẫn chưa thể toàn tâm làm hồ sơ được vì còn đề tài tốt nghiệp chưa làm xong.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-3",
        "source": "0.main.md",
        "section": "1.2. Những khó khăn trước khi chuẩn bị",
        "content": "Tháng Sáu năm 2012 tôi tốt nghiệp BKHN. Thầy còn một dự án quan trọng nữa nên tôi tiếp tục làm cùng thầy tới giữa tháng Tám mới có thể tập trung cho việc nộp hồ sơ đi Mỹ. Tôi chỉ còn bốn tháng cho đợt nộp hồ sơ giữa tháng 12. Tôi thực sự lo lắng khi biết những người khác thường dành hai ba năm để chuẩn bị hồ sơ. Tôi mới chỉ có điểm IELTS, chưa có GRE, chưa có bài báo khoa học, và cũng chưa có một hướng nghiên cứu rõ rệt ngoài việc sẽ theo Xử lý ảnh/tín hiệu số. Các kiến thức tôi học được về phần cứng ở đại học lại dường như không giúp hồ sơ của tôi mạnh thêm. Tôi gần như không có gì ngoài niềm tin của thầy cô, bạn bè, và của chính mình. Bước đầu tiên là phải lấy chứng chỉ GRE. Tôi tìm được một nhóm bạn khoảng mười lăm người đang ôn tập GRE. Nhóm học ba buổi một tuần ở một quán cà phê sách trong ngõ 30 Tạ Quang Bửu, Hà Nội. Ngày đầu đến tôi thấy các anh chị em học thực sự nghiêm túc và bài bản. Tôi thấy mình may mắn, vì sau khi thi GRE xong cả nhóm còn tập trung cùng nhau nộp hồ sơ và đã giúp đỡ nhau rất nhiều. Nhóm vẫn liên lạc và giúp đỡ nhau trong nhiều năm sau đó. Lúc đó ra trường rồi nên tôi hạn chế xin trợ cấp từ gia đình, thu nhập kiếm được chủ yếu từ việc dạy thêm. Tôi khá lo lắng vì mỗi buổi đi học thường tốn 20k cho cà phê, và sau đó là các loại phí gửi hồ sơ sang Mỹ và phí ứng tuyển vào các trường. Bố mẹ đã đầu tư cho tôi học tiếng Anh rất nhiều trong những năm trước nên tôi cũng không muốn họ mang thêm gánh nặng. Bố mẹ cũng không hiểu được khả năng được đi học của tôi và thường lo lắng khuyên tôi cân nhắc việc đi làm. Tôi nộp hồ sơ lấy học bổng Honda YES năm 2012 với kỳ vọng cao nhưng không thành. Lúc đó tôi khá khủng hoảng về mặt tài chính. May mắn thay, tôi luôn được quý nhân giúp đỡ trong lúc khó khăn. Chị Phương trong nhóm GRE đưa tôi một phong bì $500 và nói rằng: “Chị tin em sẽ thành công, khi nào sang Mỹ trả lại chị cũng được”. Thầy Nam gọi tôi lên văn phòng và đưa tôi một phong bì dày: “Em làm cùng thầy hai dự án quan trọng, thầy có một chút trả công cho em, thầy cũng hỗ trợ thêm cho em trong việc nộp hồ sơ. Chúc em thành công”. Tôi thực sự xúc động, càng xúc động hơn khi về nhà mở phong bì thấy một số tiền lớn. Những khoản tiền này cực kỳ quan trọng với tôi thời điểm đó, chắc chắn tôi không bao giờ quên! Thời gian này anh Long – anh trai tôi – giúp đỡ tôi nhiều, mặc dù anh cũng lo lắng về khả năng thành công của tôi.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-4",
        "source": "0.main.md",
        "section": "1.3. Quá trình lựa chọn trường và gửi hồ sơ",
        "content": "Tháng 9/2012 tôi vừa ôn GRE và bắt đầu tìm hiểu thông tin các trường bên Mỹ. Tôi vào trang web USNews xem thứ hạng các trường có ngành Kỹ thuật điện tử (Electrical Engineering, EE). Sau đó bỏ hết các trường trong top 10 vì biết chắc mình không đủ khả năng đỗ. Với mỗi trường trong danh sách từ 10 đến 50, tôi vào trang web của khoa EE tìm các giáo sư làm về xử lý tín hiệu số và gửi email tìm cơ hội. Tôi cũng gửi thư cho một số giáo sư người Việt ở các trường top trên. Hầu hết các giáo sư không trả lời. Thầy Minh Đỗ ở UIUC có trả lời tôi nói rằng hồ sơ của tôi khá tốt, tuy nhiên thầy không có ý định tuyển thêm sinh viên năm đó và gợi ý tôi nộp cho các thầy khác trong khoa. Một vài giáo sư khác trả lời nhưng nói rằng họ có thể nhận nhưng không có hỗ trợ tài chính. Chỉ duy nhất thầy Vishal Monga ở Penn State trả lời tích cực, chỉ một ngày sau khi tôi gửi email: “Your application seems interesting. I certainly like students with a strong foundation in linear algebra and probability. Please just apply to Penn State EE.” Email này khiến tôi rất vui và tìm mọi cách tạo hồ sơ tốt nhất gửi vào Penn State. Tôi thi GRE ngày 17/11/2012. Điểm vừa đủ để nộp hồ sơ (Verbal 145, Toán 167, Viết 3.0). Tôi biết có cố gắng thêm nữa thì điểm GRE cũng không cải thiện được nhiều nên dành thời gian tập trung cho việc chuẩn bị các văn bản khác. Tôi chỉ đủ kinh phí nộp hồ sơ vào năm trường, trong đó Penn State là trường tôi hy vọng nhất. Cuộc phỏng vấn duy nhất của tôi là với thầy Vishal Monga vào 28 Tết năm 2013. Bốn trường kia báo trượt, thầy Vishal Monga email cuối cùng báo sẽ nhận tôi vào ngày 21/03/2013. *Trong cả quá trình làm hồ sơ, tôi nhận được sự giúp đỡ nhiệt tình của nhiều bạn bè. Tôi đặc biệt cảm ơn anh Phạm Toàn Thắng (PhD UC Berkeley) – người đã giúp tôi sửa hồ sơ, phỏng vấn thử và cách email cho giáo sư.*",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-5",
        "source": "0.main.md",
        "section": "2.1. Kỳ học PhD đầu tiên",
        "content": "Tôi đặt chân tới nước Mỹ đầu tháng 8 năm 2013. Tôi vào lab cùng năm với một bạn Yuelong Li người Trung Quốc. Việc đầu tiên tôi phải làm là thi một bài thi tiếng Anh xem có phải học thêm phần trình bày không. *Vì tiếng Anh giao tiếp ít quan trọng trong ngành kỹ thuật hơn nên dù tiếng Anh nói còn kém, thầy vẫn nhận tôi vào lab.* Kết quả là Yuelong chỉ phải học thêm một khóa, trong khi tôi phải học ba khóa trình bày và một khóa viết học thuật – con số tối đa cho một sinh viên quốc tế tại Penn State. Ngoài môn tiếng Anh, kỳ đầu tiên tôi lấy thêm khóa Đại số tuyến tính và khóa Xác suất Thống kê. Yuelong cũng học cùng lớp với tôi cả hai lớp này và điểm quá trình rất tốt, thường nhỉnh hơn tôi đôi chút. Sau bao năm không học toán, tôi lại cảm thấy niềm đam mê trở lại khi được học hai môn này. Trên lớp tôi phát biểu rất nhiều dù tiếng Anh còn tệ. Tôi gần như là ngôi sao trong lớp Xác suất Thống kê vì nhiều lần là người duy nhất có thể trả lời câu hỏi của thầy. Trong kỳ đầu tiên này, tôi được thầy hướng dẫn nhắc nhiều tới chuyện chuẩn bị cho một kỳ thi quan trọng tên là *candidacy exam*. Tôi chỉ có thể tiếp tục học PhD nếu vượt qua kỳ thi này. Khoa cho phép tôi thi hai lần nhưng thầy chỉ cho một lần. Thầy luôn nhắc rằng các bạn trước trong lab không những thi qua mà còn thường đạt kết quả cao nhất khoa, rằng chúng tôi phải chuẩn bị thực sự nghiêm túc. Kỳ thi candidacy có nội dung lấy chủ yếu từ khóa Xác suất thống kê nên trong quá trình ôn thi cuối kỳ môn học này, tôi cũng đã tích lũy được khá nhiều kiến thức. Rất tiếc đây là một trong hai môn đạt điểm A-. Kỳ nghỉ đông năm 2013, sau khi đi du lịch cùng nhóm GRE về (nhóm GRE của tôi được đi Mỹ gần hết năm đó, có hai anh chị còn lại đi năm 2014), tôi tập trung ôn tập cho kỳ thi candidacy. Tôi được 49.5/50, đứng thứ nhất khoa và nhiều hơn Yuelong 0.5 điểm (điều đầu tiên tôi nhỉnh hơn Yuelong). Kết quả kỳ thi này khiến tôi tự tin hơn nhiều. Tôi dường như đã tìm lại được đam mê bị mất hồi đại học của mình. Tôi chính thức trở thành ứng viên PhD (PhD candidate). Việc còn lại của PhD là kỳ thi *comprehensive* và ba bài tạp chí khoa học (transaction papers) để có thể tốt nghiệp. Đây là một nhiệm vụ khó khăn nhưng tôi luôn tin rằng mình có thể làm được.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-6",
        "source": "0.main.md",
        "section": "2.2. Một năm rưỡi tiếp theo",
        "content": "Kỳ mùa xuân năm 2014 tôi học môn *Nhận dạng vật thể* (Pattern Recognition) và bắt đầu thấy thích machine learning. Tôi tự tìm học thêm khóa Machine Learning của Andrew Ng và sau đó là khóa Tối ưu lồi của Stephen Boyd. Tôi chọn machine leanring vì yêu thích, và chọn học Tối ưu lồi vì đó là thế mạnh của lab. Các công trình nghiên cứu của lab đều có phần tối ưu. Lúc đó lab tôi chủ yếu giải quyết các bài toán phân loại dựa trên việc xây dựng *mô hình thưa* (sparse model). Các thuật toán đó thường không yêu cầu *học* nhưng yêu cầu giải một bài toán tối ưu tương đối khó khi đưa ra quyết định. Tôi khá thích các mô hình thưa và các thuật toán học nên chọn hướng nghiên cứu về *học từ điển* (dictionary leanring). Hè 2014 tôi được giao đề tài đầu tiên về phân loại và dò tìm các tế bào ung thư trong ảnh y tế. Bài toán này đã được giải quyết phần nào bởi một anh trong lab đã tốt nghiệp. Tôi được giao nhiệm vụ cải thiện độ chính xác của thuât toán phân loại. Với kiến thức hạn chế của mình hồi đó, tôi chỉ nghĩ ra được một ý tưởng rất đơn giản. Ý tưởng đó đơn giản đến mức tôi không tin chưa có bài báo nào sử dụng. Đôi khi tôi không nghĩ có thể được viết thành một bài báo khoa học với ý tưởng này. Tôi cố gắng *biến ý tưởng đó phức tạp hơn* bằng nhiều cách khác nhau và lập trình tất cả các ý tưởng tôi có được. Tôi thay đổi thuật toán hàng ngày, đến mức đồng nghiệp gần như phải gắt lên: “Tại sao bạn lại luôn luôn thay đổi ý tưởng như vậy” (I don’t know why you keep changing ideas). Cuối cùng khi hạn nộp bài đến gần, tôi không còn cách nào khác phải quay lại ý tưởng đơn giản đầu tiên. Sau một vài thay đổi nhỏ, thuật toán đó làm việc rất tốt. Bài báo bốn trang đầu tiên được tôi viết rồi sửa đi sửa lại theo ý kiến đóng góp của thầy và đồng nghiệp trong hơn ba tuần. Tôi nộp bài mà trong lòng luôn lo lắng, đến mức tôi từng mơ thấy bài báo bị từ chối vì ý tưởng đó đã được sử dụng trước đó. Rất may, chuyện đó không xảy ra và tôi có bài báo hội nghị đầu tiên được chấp nhận. Sự tự tin trong tôi tăng lên một chút.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-7",
        "source": "0.main.md",
        "section": "2.3. Ba năm cuối",
        "content": "Như đã nhắc ở phần trên, có một quy tắc ở lab tôi là phải có ba bài báo ở các tạp chí lớn thì mới được tốt nghiệp. (Bạn có thể xem thêm [Quá trình viết và nhận xét các bài báo khoa học](https://machinelearningcoban.com/2017/08/05/phdlife/).) Thầy yêu cầu tôi chuẩn bị mọi thứ để mở rộng bài báo hội thảo vừa được nhận. Trong lab tôi, thường thì tại hội thảo chúng tôi sẽ trình bày các kết quả của bài tạp chí tương ứng. Vừa tự thúc mình có kết quả sớm, vừa trình bày và xin ý kiến của đồng nghiệp tại hội thảo. Sau khi dự hội thảo vào tháng 4/2015, tôi về viết bài và tới tháng 6/2015 nộp bản thảo đầu tiên cho một tạp chí khá lớn về xử lý ảnh y tế (Transaction on Medical Imaging). Thật may mắn, tôi nhận được phản hồi vào đầu tháng Tám, nộp bản sửa vào cuối tháng Chín và nhận email báo được chấp nhận vào cuối tháng Mười. Tổng thời gian xử lý là hơn bốn tháng – rất nhanh so với trung bình. Tôi cảm thấy PhD của mình có vẻ suôn sẻ hơn so với các bạn khác. Sau khi có bài tạp chí đầu tiên, tôi phải chuẩn bị cho kỳ thi thứ hai trong chương trình học – comprehensive exam. Trong kỳ thi này, tôi phải trình bày ý tưởng cho đề tài tốt nghiệp trước một hội đồng gồm bốn giáo sư. Mọi thứ diễn ra suôn sẻ vì tôi có một bài tạp chí và đề xuất một ý tưởng mới cũng cho bài toán phân loại. Khi có một công trình được chấp nhận, việc bảo vệ đề xuất này trở nên đơn giản hơn nhiều. Sau dấu mốc này, tôi nhận thấy sự thay đổi trong cách thầy hướng dẫn nói chuyện với mình và tôi cũng thấy tự tin hơn rất nhiều khi nói chuyện với thầy. Thực ra, tôi biết rằng nhiều ứng viên PhD có thể tốt nghiệp với chỉ một bài tạp chí khoa học. Tất nhiên, tôi không muốn dừng lại ở đó. Tháng 2/2016, sau khi nộp thêm một bài báo hội nghị, tôi thảnh thơi về Việt Nam ăn Tết. Trước đó tôi nhận được tin một học giả người Mỹ gốc Việt tại Phòng nghiên cứu lục quân Hoa Kỳ (U.S. Army Research Lab) – một người bạn của thầy hướng dẫn – đã nhận tôi vào làm thực tập mùa hè năm 2016. Tôi cũng quay lại thực tập lần hai vào năm 2017. Tới bây giờ, tôi thấy đáng tiếc vì lẽ ra nên tìm một chương trình thực tập tại một công ty công nghệ lớn … Sau kỳ thi comprehensive, tôi có thêm hai bài tạp chí nữa và đang viết thêm một bài. Tôi cũng có một vài bài hội nghị, trong đó có một bài được vào danh sách ‘Finalist for the best student paper award’ tại ICASSP 2017 (hội thảo này có hơn 1000 bài báo được chấp nhận, khoảng 20 trong số đó được đề xuất cho giải thưởng bài báo xuất sắc nhất). Thầy khá tự hào về tôi vì đây là hội thảo lớn trong ngành. Thấy thầy tự hào, tôi cũng tự hào lây. Với số lượng bài báo và trích dẫn cao, tôi được nhận giải luận án xuất sắc trong khoa vào tháng 4/2018 trước khi bảo vệ PhD thành công ngày 11/9/2018.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-8",
        "source": "0.main.md",
        "section": "2.4. Tôi làm gì ngoài thời gian nghiên cứu",
        "content": "PhD là một quá trình dài. Vì tôi chưa có bằng thạc sĩ khi bắt đầu nên chương trình sẽ kéo dài ít nhất năm năm. Trong thời gian này, tôi cần phải tìm cho mình nhiều thú vui khác ngoài việc nghiên cứu. Đầu tiên là phải tìm bạn. Tôi thấy may mắn vì Penn State có khá nhiều sinh viên Việt Nam. Có một số gia đình người Việt ở đây nên tôi cũng sớm tìm được người chơi. Những năm đầu, khi tuổi tôi gần với các bạn sinh viên đại học, tôi thường xuyên tham gia các hoạt động của hội sinh viên Việt Nam. Nhưng các bạn ấy tốt nghiệp dần và thay vào đó là các bạn trẻ hơn mình khoảng bảy tám tuổi. Tôi dần thấy mình không phù hợp với thế hệ đó nữa. Cũng may rằng tôi thuộc thế hệ cuối 8x nhưng vẫn nói chuyện được với các anh chị đầu 8x thậm chí cả 7x, và chơi rất thân. Tôi may mắn làm bạn với hai gia đình anh Quang chị Hằng và anh Long chị Duy. Những kỷ niệm đẹp cùng hai gia đình này tôi sẽ không bao giờ quên. Tiếp theo là việc nấu ăn. Việc này tôi đã làm nhiều vì sống xa nhà từ năm chín tuổi (xem thêm [Con đường học Toán của tôi](https://machinelearningcoban.com/lifesofar/)). Tuy nhiên, câu chuyện nấu ăn khi học PhD lại hoàn toàn khác. Ở Việt Nam, tôi có nhiều lựa chọn nếu không có thời gian nấu ăn. Ở Mỹ thì khác, vùng tôi ở đồ ăn Việt rất hạn chế. Đồ ăn nói chung đắt và một suất ăn thường không ngon và không đủ. Rất may trong thị trấn tôi ở có nhiều người châu Á nên có hai chợ châu Á nho nhỏ, có đủ đồ đề mình kho cá, nấu bún riêu hay bất cứ món gì mà tôi nhớ đến. Youtube, trí nhớ và trí tưởng tượng đã giúp tôi nấu được nhiều món ăn. Sau này tôi và vợ có thể thay nhau nấu ăn hàng ngày được. Tôi có khá nhiều thời gian rảnh trong những năm đầu. Thời gian đầu còn gọi điện về nói chuyện với bạn bè ở Việt Nam nhiều. Sau rồi các bạn bận việc gia đình và giờ giấc lệch nhau nên tôi ít nói chuyện dần. Tôi mua kindle và download các tiểu thuyết và sách lịch sử về đọc. Tôi quay lại niềm vui đọc sách như hồi cấp ba, có một năm tôi đọc được tới 30 cuốn sách. Thời gian cuối PhD tôi ít đọc hơn vì bận nhiều việc trong đó có việc viết blog này. Một thú vui quan trọng khác là chơi thể thao. Sang bên này thấy ai cũng chơi thể thao, nhiều người đẹp trong khi mình hồi đầu thì hơi còi. Tôi chơi rất nhiều môn: chạy, đá bóng, đạp xe, bơi, leo núi, trèo tường (bouldering). Có thể chất tốt rồi tinh thần cũng thoải mái hơn và có sức chạy đường dài PhD. *Đừng để mình bị ốm ở nước Mỹ*. Bạn phải tự chăm sóc vì ai cũng có việc riêng của mình. Thuốc lại rất đắt và bạn vẫn phải đi làm khi bị ốm nhẹ. Hè năm 2016 khi đang thực tập tại Phòng nghiên cứu lục quân Hoa Kỳ, tôi có khá nhiều thời gian rảnh vì đã nộp bài tạp chí thứ hai. Tôi tạo một kênh Youtube [Hướng dẫn LaTex cơ bản](https://www.youtube.com/playlist?list=PLlsF2nDmyL7msihnebzII_KVWy6URxDfp). Vì lab tôi yêu cầu các báo cáo, bài báo và slide phải được làm bằng LaTex, sau ba năm làm việc, tôi tự tin với kỹ năng sử dụng LaTex của mình. Tất cả các hình vẽ trong PhD của tôi cũng được vẽ bằng LaTex với chất lượng cao. Vì vậy tôi muốn chia sẽ những gì mình biết thông qua kênh Youtube này. Tuy nhiên, tôi sớm nhận ra rằng việc tạo các clip tốn quá nhiều thời gian và rất khó khăn nếu muốn chỉnh sửa về sau. Lượng khán giả cũng ít vì LaTex kén người học. Tôi dừng việc ra clip sau khoảng hai tháng. Kỳ nghỉ đông cuối năm 2016, lúc đó tôi đang ở năm thứ tư của chương trình PhD, tôi bắt đầu lên kế hoạch chuẩn bị cho xin việc sau khi ra trường. Lúc đó machine leanring/deep learning đã nở rộ và nhà nhà người người nói về nó. Tôi thấy rằng mình cần phải chuẩn bị kỹ các kiến thức về lĩnh vực này. Tôi có tham gia một nhóm nhỏ ở Việt Nam dịch cuốn [Deep learning](https://deeplearningbook.org) nhưng sớm rời nhóm. Tôi nhận thấy nhóm này làm việc chưa hiệu quả và nhiều thành viên chưa nắm vững các khái niệm cơ bản. Tôi bắt đầu nhen nhóm ý tưởng tự viết lại các thuật toán theo cách hiểu của mình. Và blog ‘Machine Learning cơ bản’ ra đời. Sau đó là facebook page, facebook group, fundaml, ebook, sách giấy (đang in) và gần đây nhất là diễn đàn Machine Learning cơ bản.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-9",
        "source": "0.main.md",
        "section": "3. Khó khăn xuất hiện cuối chặng đường",
        "content": "Năm cuối cùng của chương trình PhD tôi gần như không có công trình khoa học nào mới. Phần vì tôi dành khá nhiều thời gian cho Machine Learning cơ bản, phần vì tôi biết mình đã đủ điều kiện để tốt nghiệp, phần còn lại là tôi phải tập trung xin việc. Không giống các thành viên khác trong lab, việc xuất bản các bài báo của tôi khá suôn sẻ. Tất cả các bài có tên tôi đều được chấp nhận. Và cũng không giống những bạn đã tốt nghiệp trước đó, quá trình xin việc của tôi trắc trở hơn rất nhiều. Trước tôi, các bạn tốt nghiệp xin được việc ở Apple, Microsoft và nhiều phòng nghiên cứu khác. Tôi tự tin cho rằng mình cũng có thể xin được việc trong hai ba tháng và có thể tốt nghiệp vào mùa hè năm 2018. Những năm trước khi xin thầy hướng dẫn đi thực tập ở các công ty, thầy hướng dẫn luôn nói rằng tôi không nên lo quá sớm về công việc, rằng tôi cần bình tĩnh, rằng khả năng của tôi tốt nên sẽ có việc tốt. Quá trình xin việc của tôi kéo dài nửa năm, từ cuối tháng Hai đến cuối tháng Tám năm 2018. Tôi thực hiện khoảng 50 cuộc phỏng vấn qua điện thoại, đi phỏng vấn onsite tại tám công ty. Bay khoảng hai ba chục chuyến và lái xe hàng ngàn dặm trong mùa hè. Tôi rất thích Seattle nhưng ba công ty mời tôi đến phỏng vấn đều cho rằng tôi thiếu kinh nghiệm thực tế. Điều tương tự xảy ra với hai công ty ở bờ Đông nước Mỹ. Tới tận gần ngày bảo vệ tốt nghiệp tôi mới nhận được hai thư chấp nhận tại hai công ty khởi nghiệp tại Sillicon Valley. Sau khi hỏi ý kiến nhiều bạn bè, tôi quyết định nhận vị trí ‘Deep Learning and Computer Vision Researcher’ của một công ty làm về xe tự lái. Tôi là nhân viên thứ 13 của công ty. Thầy tôi nói vui rằng không ai có nhiều phỏng vấn onsite như tôi, và luôn động viên tôi tự tin vì có nhiều công ty gọi phỏng vấn như thế. Theo tôi chuyện này dễ hiểu vì những người khác có việc sau khi phỏng vấn với hai hoặc ba công ty nên họ dừng lại. Tôi có buồn sau khi nhận được những email từ chối đầu nhưng sau tôi không còn thời gian để mà buồn vì còn phải lo quá nhiều việc, cả việc cá nhân, trong mùa hè năm 2018. Tôi buồn nhưng không bao giờ mất hy vọng.",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-10",
        "source": "0.main.md",
        "section": "4. Kết luận",
        "content": "Lịch bảo vệ của tôi là cuối tháng Năm nhưng phải lùi lại tới đầu tháng Chín. Tôi không thể bảo vệ khi chưa có việc vì visa không cho phép tôi ở lại quá lâu mà không có việc. Tôi phải lên lịch bảo vệ trước khi có việc vì lúc đó đã quá muộn. Từ tháng Tám tôi không còn được nhận lương, tháng Chín phải nộp học phí và bảo hiểm cho kỳ mùa thu. Tôi biết mình không còn nhiều thời gian và số tiền tiết kiệm chỉ có thể giúp tôi sống ba tháng ở Mỹ. Thật may mắn, mọi chuyện tốt đẹp cuối cùng xảy đến cùng nhau. Luôn hy vọng, nhưng đừng kỳ vọng quá cao. Phải hy vọng và lạc quan vì suy nghĩ tiêu cực không bao giờ khiến vấn đề tốt lên. Đừng kỳ vọng cao để khi kết quả không như ý muốn mình không bị suy sụp. Nước Mỹ dạy tôi phải luôn cố gắng, phải giữ niềm tin và sức khỏe cho những mục tiêu dài hơi. *Best things come to those who wait.*",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "0.main-11",
        "source": "0.main.md",
        "section": "5. Các bài viết liên quan",
        "content": "[1] [Con đường học Toán của tôi](https://machinelearningcoban.com/lifesofar/) [2] [Học PhD để làm gì](https://www.facebook.com/machinelearningbasicvn/posts/480159092343927) [3] [Viết và nhận xét các bài báo khoa học](https://machinelearningcoban.com/2017/08/05/phdlife/) [4] [Chúng tôi đã apply và học tiến sĩ như thế nào?](http://thepresentwriter.com/chung-toi-da-apply-va-hoc-tien-si-nhu-the-nao-phan-1/)",
        "url": "https://machinelearningcoban.com/lifesofar2/"
    },
    {
        "id": "25.main-1",
        "source": "25.main.md",
        "section": "Introduction",
        "content": "Bạn sẽ hiểu rõ hơn nếu đã đọc các bài: * [Bài 11: Feature Engineering](https://machinelearningcoban.com/general/2017/02/06/featureengineering/) * [Bài 12: Binary Classifiers](https://machinelearningcoban.com/2017/02/11/binaryclassifiers/) * [Bài 13: Softmax Regression](https://machinelearningcoban.com/2017/02/17/softmax/) * [Bài 20: Soft Margin SVM](https://machinelearningcoban.com/2017/04/13/softmarginsmv/) **Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) + [1.1.Từ Binary classification tới multi-class classification](#tu-binary-classification-toi-multi-class-classification) + [1.2. Mô hình end-to-end](#-mo-hinh-end-to-end) + [1.3. Bộ cơ sở dữ liệu CIFAR10](#-bo-co-so-du-lieu-cifar) + [1.4. Image data preprocessing](#-image-data-preprocessing) + [1.5. Bias trick](#-bias-trick) * [2. Xây dựng hàm mất mát cho Multi-class Support Vector Machine](#-xay-dung-ham-mat-mat-cho-multi-class-support-vector-machine) + [2.1. Nhắc lại Softmax Regression.](#-nhac-lai-softmax-regression) + [2.3. Hinge losss tổng quát cho Multi-class SVM](#-hinge-losss-tong-quat-cho-multi-class-svm) + [2.4. Regularization](#-regularization) + [2.5. Chọn giá trị \\(\\Delta\\)](#-chon-gia-tri-\\\\\\delta\\\\) + [2.6. Soft Margin SVM là một trường hợp đặc biệt của Multi-class SVM](#-soft-margin-svm-la-mot-truong-hop-dac-biet-cua-multi-class-svm) * [3. Tinh toán hàm mất mát và đạo hàm của nó](#-tinh-toan-ham-mat-mat-va-dao-ham-cua-no) + [3.1. Tính hàm mất mát và đạo hàm của nó bằng cách *naive*](#-tinh-ham-mat-mat-va-dao-ham-cua-no-bang-cach-naive) + [3.2. Tính hàm mất mát và đạo hàm của nó bằng cách *vectorized*](#-tinh-ham-mat-mat-va-dao-ham-cua-no-bang-cach-vectorized) + [3.3. Gradient Descent cho Multi-class SVM](#-gradient-descent-cho-multi-class-svm) + [3.4. Minh họa nghiệm tìm được](#-minh-hoa-nghiem-tim-duoc) * [4. Thảo luận](#-thao-luan) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/04/28/multiclasssmv/"
    },
    {
        "id": "25.main-2",
        "source": "25.main.md",
        "section": "1.1.Từ Binary classification tới multi-class classification",
        "content": "Các phương pháp Support Vector Machine đã đề cập (Hard Margin, Soft Margin, Kernel) đều được xây dựng nhằm giải quyết bài toán [Binary Classification](/2017/02/11/binaryclassifiers/), tức bài toán phân lớp với chỉ hai classes. Việc này cũng tương tự như [Percetron Learning Algorithm](/2017/01/21/perceptron/) hay [Logistic Regression](/2017/01/27/logisticregression/) vậy. Các mô hình làm việc với bài toán có 2 classes còn được gọi là Binary classifiers. Một cách tự nhiên để mở rộng các mô hình này áp dụng cho các bài toán multi-class classification, tức có nhiều classes dữ liệu khác nhau, là [sử dụng nhiều binary classifiers và các kỹ thuật như one-vs-one hoặc one-vs-rest](/2017/02/11/binaryclassifiers/#-binary-classifiers-cho-multi-class-classification-problems). Cách làm này có những hạn chế như đã trình bày trong bài [Softmax Regression](/2017/02/17/softmax/).",
        "url": "https://machinelearningcoban.com/2017/04/28/multiclasssmv/"
    },
    {
        "id": "25.main-3",
        "source": "25.main.md",
        "section": "1.2. Mô hình end-to-end",
        "content": "Softmax Regression là mở rộng của Logistic Regression cho bài toán multi-class classification, có thể được coi là một layer của Neural Networks. Nhờ đó, Softmax Regression thường đươc sử dụng rất nhiều trong các bộ phân lớp hiện nay. Các bộ phân lớp cho kết quả cao nhất thường là một Neural Network với rất nhiều layers và layer cuối là một softmax regression, đặc biệt là các Convolutional Neural Networks. Các layer trước thường là kết hợp của các Convolutional layers và các nonlinear activation functions và pooling, các bạn tạm thời chưa cần quan tâm đến các layers phía trước này, tôi sẽ giới thiệu khi có dịp. Có thể coi các layer trước layer cuối là một công cụ giúp trích chọn đặc trưng của dữ liệu (Feature extraction), layer cuối là softmax regression, là một bộ phân lớp tuyến tính đơn giản nhưng rất hiệu quả. Bằng cách này, ta có thể coi là nhiều one-vs-rest classifers được huấn luyện cùng nhau, hỗ trợ lẫn nhau, vì vậy, một cách tự nhiên, sẽ có thể tốt hơn là huấn luyện từng classifier riêng lẻ. Sự hiệu quả của Softmax Regression nói riêng và Convolutional Neural Networks nói chung là cả *bộ trích chọn đặc trưng* (feature extractor) và *bộ phân lớp* (classifier) được *huấn luyện* đồng thời. Điều này nghĩa là hai *bộ phận* này bổ trợ cho nhau trong quá trình huấn luyện. Classifier giúp tìm ra các hệ số hợp lý phù hợp với feature vector tìm được, ngược lại, feature extractor lại điều chỉnh các hệ số của các convolutional layer sao cho feature thu được là tuyến tính, phù hợp với classifier ở layer cuối cùng. Tôi viết đến đây không phải là để giới thiệu về Softmax Regression, mà là đang nói chung đến các mô hình phân lớp *hiện đại*. Đặc điểm chung của chúng là feature extractor và classifier được huấn luyện một cách đồng thời. Những mô hình như thế này còn được gọi là *end-to-end*. Cùng xem lại mô hình chung cho các bài toán Machine Learning mà tôi đã đề cập trong Bài 11: --- ![](\\assets\\FeatureEngineering\\ML_models.png) Hình 1: Mô hình chung cho các bài toán Machine Learning. ---",
        "url": "https://machinelearningcoban.com/2017/04/28/multiclasssmv/"
    },
    {
        "id": "35.main-1",
        "source": "35.main.md",
        "section": "Introduction",
        "content": "Cho tới bây giờ, ngoài *thuật toán lười* [K-nearest neighbors](/2017/01/08/knn/), tôi đã giới thiệu với bạn đọc hai thuật toán cho các bài toán Classification: [Perceptron Learning Algorithm](/2017/01/21/perceptron/) và [Logistic Regression](/2017/01/27/logisticregression/). Hai thuật toán này được xếp vào loại Binary Classifiers vì chúng được xây dựng dựa trên ý tưởng về các bài toán classification với chỉ hai classes. Trong bài viết này, tôi sẽ cùng các bạn làm một vài ví dụ nhỏ về ứng dụng đơn giản (nhưng thú vị) của các binary classifiers, và cách mở rộng chúng để áp dụng cho các bài toán với nhiều classes (multi-class classification problems). Vì Logistic Regression chỉ yêu cầu các classes là [*nearly linearly separable*](/2017/01/21/perceptron/#bai-toan-perceptron) (tức có thể có vài điểm làm phá vỡ tính linear separability), tôi sẽ sử dụng Logistic Regression để đại diện cho các binary classifiers. *Chú ý rằng, có rất nhiều các thuật toán cho binary classification nữa mà tôi chưa giới thiệu. Tạm thời, với những gì đã viết, tôi chỉ sử dụng Logistic Regression cho các ví dụ với code mẫu. Các kỹ thuật trong bài viết này hoàn toàn có thể áp dụng cho các binary classifiers khác.* **Trong trang này:** * [1. Bài toán phân biệt giới tính dựa trên ảnh khuôn mặt](#-bai-toan-phan-biet-gioi-tinh-dua-tren-anh-khuon-mat) + [Làm việc với Python](#lam-viec-voi-python) * [2. Bài toán phân biệt hai chữ số viết tay](#-bai-toan-phan-biet-hai-chu-so-viet-tay) * [3. Binary Classifiers cho Multi-class Classification problems](#-binary-classifiers-cho-multi-class-classification-problems) + [One-vs-one](#one-vs-one) + [Hierarchical (phân tầng)](#hierarchical-phan-tang) + [Binary coding](#binary-coding) + [one-vs-rest hay one-hot coding](#one-vs-rest-hay-one-hot-coding) * [4. Thảo luận](#-thao-luan) + [Kết hợp các phương pháp trên](#ket-hop-cac-phuong-phap-tren) + [Biểu diễn dưới dạng Neural Networks](#bieu-dien-duoi-dang-neural-networks) + [Hạn chế của one-vs-rest](#han-che-cua-one-vs-rest) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-2",
        "source": "35.main.md",
        "section": "1. Bài toán phân biệt giới tính dựa trên ảnh khuôn mặt",
        "content": "Chúng ta cùng bắt đầu với bài toán phân biệt giới tính dựa trên ảnh khuôn mặt. Về ảnh khuôn mặt, bộ cơ sở dữ liệu [AR Face Database](http://www2.ece.ohio-state.edu/~aleix/ARdatabase.html) được sử dụng rộng rãi. Bộ cơ sở dữ liệu này bao gồm hơn 4000 ảnh màu tương ứng với khuôn mặt của 126 người (70 nam, 56 nữ). Với mỗi người, 26 bức ảnh được chụp ở các điều kiện ánh sáng khác nhau, sắc thái biểu cảm khuôn mặt khác nhau, và bị che mắt (bởi kính râm) hoặc miệng (bởi khăn); và được chụp tại hai thời điểm khác nhau cách nhau 2 tuần. Để cho đơn giản, tôi sử dụng bộ cơ sử AR Face thu gọn (có thể tìm thấy trong cùng trang web phía trên, mục *Other (relevant) downloads*). Bộ cơ sở dữ liệu thu gọn này bao gồm 2600 bức ảnh từ 50 nam và 50 nữ. Hơn nữa, các khuôn mặt cũng đã được xác định chính xác và được *cropped* với kích thước 165 x 120 (pixel) bằng phương pháp được mô tả trong bài báo [PCA veus LDA](http://lectures.molgen.mpg.de/networkanalysis13/PCAversusLDA_eigenfaces.pdf). Tôi xin bỏ qua phần xử lý này và trực tiếp sử dụng ảnh đã cropped như một số ví dụ dưới đây: ![](\\assets\\LogReg2\\ARgender.png) Hình 1: Các ví dụ mẫu trong AR Face database thu gọn. **Lưu ý:** * *Vì lý do bản quyền, tôi không được phép chia sẻ với các bạn bộ dữ liệu này. Các bạn muốn sở hữu có thể liên lạc với tác giả như hướng dẫn ở trong website [AR Face Database](http://www2.ece.ohio-state.edu/~aleix/ARdatabase.html). Một khi các bạn đã có tài khoản để download, tôi mong các bạn tôn trọng tác giả và không chia sẻ trực tiếp với bạn bè.* * *Có một cách đơn giản và nhanh hơn để lấy được các feature vector (sau bước [Feature Engineering](/general/2017/02/06/featureengineering/)) của cơ sở dữ liệu này mà không cần liên lạc với tác giả. Các bạn có thể tìm [tại đây](https://www.umiacs.umd.edu/~zhuolin/projectlcksvd.html), phần **Downloads**, mục **Random face features for AR database**.* Mỗi bức ảnh trong AR Face thu gọn được đặt tên dưới dạng `G-xxx-yy.bmp` Trong đó: `G` nhận một trong hai giá trị `M` (man) hoặc `W` (woman); `xxx` là id của người, nhận gía trị từ `001` đến `050`; `yy` là điều kiện chụp, nhận giá trị từ `01` đến `26`, trong đó các điều kiện có số thứ tự từ `01` đến `07` và từ `14` đến `20` là các khuôn mặt không bị che bởi kính hoặc khăn. Tôi tạm gọi mỗi *điều kiện* này là một *view*. Để làm ví dụ cho thuật toán Logistic Regression, tôi lấy ảnh của 25 nam và 25 nữ đầu tiên làm tập training set; 25 nam và 25 nữ còn lại làm test set. Với mỗi người, tôi chỉ lấy các khuôn mặt không bị che bởi kính và khăn. **Feature Extraction**: vì mỗi bức ảnh có kích thước `3x165x120` (số channels `3`, chiều cao `165`, chiều rộng `120`) là một số khá lớn nên ta sẽ làm thực hiện Feature Extraction bằng hai bước đơn giản sau (*bạn đọc được khuyến khích đọc bài [Giới thiệu về Feature Engineering](/general/2017/02/06/featureengineering/)*): * Chuyển ảnh màu về ảnh xám theo công thức `Y' = 0.299 R + 0.587 G + 0.114 B`  (Xem thêm tại [Grayscale - wiki](https://en.wikipedia.org/wiki/Grayscale#Luma_coding_in_video_systems)). * *Kéo dài* ảnh xám thu được thành 1 vector hàng có số chiều `165x120`, sau đó sử dụng một *random projection matrix* để giảm số chiều về `500`. Bạn đọc có thể thay giá trị này bằng các số khác nhỏ hơn `1000`. Chúng ta có thể bắt đầu làm việc với Python ngay bây giờ. Tôi sẽ sử dụng hàm [sklearn.linear\\_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) trong thư viện `sklearn` cho các ví dụ trong bài này. Nếu không muốn đọc phần này, bạn có thể lấy [source code ở dây](/assets/LogReg2/ARGender.ipynb). **Chú ý:** Hàm [sklearn.linear\\_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) nhận dữ liệu ở dạng vector hàng.",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-3",
        "source": "35.main.md",
        "section": "Làm việc với Python",
        "content": "Khai báo thư viện ``` import numpy as np from sklearn import linear_model           # for logistic regression from sklearn.metrics import accuracy_score # for evaluation from scipy import misc                     # for loading image np.random.seed(1)                          # for fixing random values ``` Phân chia training set và test set, lựa chọn các *views*. ``` path = '../data/AR/' # path to the database train_ids = np.arange(1, 26) test_ids = np.arange(26, 50) view_ids = np.hstack((np.arange(1, 8), np.arange(14, 21))) ``` Tạo *random projection matrix*. ``` D = 165*120 # original dimension d = 500 # new dimension",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-4",
        "source": "35.main.md",
        "section": "generate the projection matrix",
        "content": "ProjectionMatrix = np.random.randn(D, d) ``` Xây dựng danh sách các tên files. ``` def build_list_fn(pre, img_ids, view_ids): \"\"\" INPUT: pre = 'M-' or 'W-' img_ids: indexes of images view_ids: indexes of views OUTPUT: a list of filenames \"\"\" list_fn = [] for im_id in img_ids: for v_id in view_ids: fn = path + pre + str(im_id).zfill(3) + '-' + \\ str(v_id).zfill(2) + '.bmp' list_fn.append(fn) return list_fn ``` **Feature Extraction:** Xây dựng dữ liệu cho training set và test set. ``` def rgb2gray(rgb):",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-5",
        "source": "35.main.md",
        "section": "Y' = 0.299 R + 0.587 G + 0.114 B",
        "content": "return rgb[:,:,0]*.299 + rgb[:, :, 1]*.587 + rgb[:, :, 2]*.114",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-6",
        "source": "35.main.md",
        "section": "feature extraction",
        "content": "def vectorize_img(filename):",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-7",
        "source": "35.main.md",
        "section": "load image",
        "content": "rgb = misc.imread(filename)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-8",
        "source": "35.main.md",
        "section": "convert to gray scale",
        "content": "gray = rgb2gray(rgb)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-9",
        "source": "35.main.md",
        "section": "vectorization each row is a data point",
        "content": "im_vec = gray.reshape(1, D) return im_vec def build_data_matrix(img_ids, view_ids): total_imgs = img_ids.shape[0]*view_ids.shape[0]*2 X_full = np.zeros((total_imgs, D)) y = np.hstack((np.zeros((total_imgs/2, )), np.ones((total_imgs/2, )))) list_fn_m = build_list_fn('M-', img_ids, view_ids) list_fn_w = build_list_fn('W-', img_ids, view_ids) list_fn = list_fn_m + list_fn_w for i in range(len(list_fn)): X_full[i, :] = vectorize_img(list_fn[i]) X = np.dot(X_full, ProjectionMatrix) return (X, y) (X_train_full, y_train) = build_data_matrix(train_ids, view_ids) x_mean = X_train_full.mean(axis = 0) x_var  = X_train_full.var(axis = 0) def feature_extraction(X): return (X - x_mean)/x_var X_train = feature_extraction(X_train_full) X_train_full = None ## free this variable (X_test_full, y_test) = build_data_matrix(test_ids, view_ids) X_test = feature_extraction(X_test_full) X_test_full = None ``` **Chú ý:** Trong đoạn code trên tôi có sử dụng phương pháp chuẩn hóa dữ liệu [Standardization](/general/2017/02/06/featureengineering/#standardization). Trong đó `x_mean` và `x_var` lần lượt là vector kỳ vọng và phương sai của toàn bộ dữ liệu training. `X_train_full`, `X_test_full` là các ma trận dữ liệu đã được giảm số chiều nhưng chưa được chuẩn hóa. Hàm `feature_extraction` giúp chuẩn hóa dữ liệu dựa vào `x_mean` và `x_var` của `X_train_full`. Đoạn code dưới đây thực hiện thuật toán Logistic Regression, dự đoán output của test data và đánh giá kết quả. Một chú ý nhỏ, hàm Logistic Regression trong thư viện sklearn có nhiều biến thể khác nhau. Để sử dụng thuật toán Logistic Regression *thuần* mà tôi đã giới thiệu trong bài [Logistic Regression](/2017/01/27/logisticregression/), chúng ta cần đặt giá trị cho `C` là một số lớn (để nghịch đảo của nó gần với 0. Tạm thời các bạn chưa cần quan tâm tới điều này, chỉ cần chọn `C` lớn là được). ``` logreg = linear_model.LogisticRegression(C=1e5) # just a big number logreg.fit(X_train, y_train) y_pred = logreg.predict(X_test) print \"Accuracy: %.2f %%\" %(100*accuracy_score(y_test, y_pred)) ``` ``` Accuracy: 90.33 % ``` 90.33%, tức là cứ 10 bức ảnh trong test set thì có trung bình hơn 9 bức được nhận dạng đúng. Không tệ, nhất là khi chúng ta vẫn chưa phải làm gì nhiều! Để xác định *nhãn* của một ảnh, đầu ra của hàm [sigmoid](/2017/01/27/logisticregression/#sigmoid-function) được so sánh với 0.5. Nếu giá trị đó lớn hơn 0.5, ta kết luận đó là ảnh của nam, ngược lại, đó là ảnh của nữ. Để xem giá trị sau hàm sigmoid (tức xác suất để ảnh đó là nam), chúng ta sử dụng hàm `predict_proba` như sau: ``` def feature_extraction_fn(fn): \"\"\" extract feature from filename \"\"\"",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-10",
        "source": "35.main.md",
        "section": "vectorize",
        "content": "im = vectorize_img(fn)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-11",
        "source": "35.main.md",
        "section": "project",
        "content": "im1 = np.dot(im, ProjectionMatrix)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-12",
        "source": "35.main.md",
        "section": "standardization",
        "content": "return feature_extraction(im1) fn1 = path + 'M-036-18.bmp' fn2 = path + 'W-045-01.bmp' fn3 = path + 'M-048-01.bmp' fn4 = path + 'W-027-02.bmp' x1 = feature_extraction_fn(fn1) p1 = logreg.predict_proba(x1) print(p1) x2 = feature_extraction_fn(fn2) p2 = logreg.predict_proba(x2) print(p2) x3 = feature_extraction_fn(fn3) p3 = logreg.predict_proba(x3) print(p3) x4 = feature_extraction_fn(fn4) p4 = logreg.predict_proba(x4) print(p4) ``` ``` [[ 0.87940218  0.12059782]] [[ 0.0172217  0.9827783]] [[ 0.30458761  0.69541239]] [[ 0.83989242  0.16010758]] ``` Kết quả thu được là xác suất để bức ảnh đó là ảnh của nam (cột thứ nhất) và của nữ (cột thứ hai). Dưới đây là hình minh họa: ![](\\assets\\LogReg2\\ARgenderResult.png) Hình 2: Ví dụ về kết quả tìm được bằng Logistic Regression Hàng trên gồm các hình được phân loại đúng, hàng dưới gồm các hình bị phân loại sai. Có một vài nhận xét về hàng dưới. Từ hai bức ảnh hàng dưới, chúng ta có thể đoán rằng Logistic Regression quan tâm đến tóc phía sau gáy nhiều hơn là râu! Việc thuật toán dựa trên những đặc trưng nào của mỗi class phụ thuộc rất nhiều vào training data. Nếu trong training data, hầu hết nam không có râu và hầu hết nữ có tóc dài thì kết quả này là có thể lý giải được. **Trong Machine Learning, thuật toán là quan trọng, nhưng thuật toán tốt mà dữ liệu không tốt thì sẽ dẫn đến những tác dụng ngược!** (Source code cho ví dụ này có thể tìm thấy [ở dây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/LogReg2/ARGender.ipynb).)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-13",
        "source": "35.main.md",
        "section": "2. Bài toán phân biệt hai chữ số viết tay",
        "content": "Chúng ta cùng sang ví dụ thứ hai về phân biệt hai chữ số trong [bộ cơ sở dữ liệu MNIST](/2017/01/04/kmeans2/#bo-co-so-du-lieu-mnist). Cụ thể, tôi sẽ làm việc với hai chữ số 0 và 1. Bạn đọc hoàn toàn có thể thử với các chữ số khác bằng cách thay đổi một dòng lệnh. Khác với AR Face, bộ dữ liệu này có thể dễ dàng được download về từ [trang chủ](http://yann.lecun.com/exdb/mnist/) của nó. Chúng ta có thể bắt tay vào làm luôn. Khai báo thư viện: ```",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-14",
        "source": "35.main.md",
        "section": "%reset",
        "content": "import numpy as np from mnist import MNIST import matplotlib.pyplot as plt from sklearn import linear_model from sklearn.metrics import accuracy_score from display_network import * ``` Load toàn bộ dữ liệu: ``` mntrain = MNIST('../MNIST/') mntrain.load_training() Xtrain_all = np.asarray(mntrain.train_images) ytrain_all = np.array(mntrain.train_labels.tolist()) mntest = MNIST('../MNIST/') mntest.load_testing() Xtest_all = np.asarray(mntest.test_images) ytest_all = np.array(mntest.test_labels.tolist()) ``` Sau bưóc này, toàn bộ dữ liệu training data và test data được lưu ở hai ma trận `X_train_all` và `X_test_all`, mỗi hàng của các ma trận này chứa một điểm dữ liệu, tức một bức ảnh đã được *vector hóa*. Để lấy các hàng tương ứng với chữ số 0 và chữ số 1, ta khai báo biến sau: ``` cls = [[0], [1]] ``` Nếu bạn muốn thử với cặp `3` và `4`, chỉ cần thay dòng này bằng `cls = [[3], [4]]`. Nếu bạn muốn phân loại `(4, 7)` và `(5, 6)`, chỉ cần thay dòng này bằng `cls = [[4, 7], [5, 6]]`. Các cặp bất kỳ khác đều có thể thực hiện bằng cách thay chỉ một dòng này. Đoạn code dưới đây thực hiện việc *extract* toàn bộ dữ liệu cho các chữ số `0` và `1` trong tập training data và test data. ``` def extract_data(X, y, classes): \"\"\" X: numpy array, matrix of size (N, d), d is data dim y: numpy array, size (N, ) cls: two lists of labels. For example: cls = [[1, 4, 7], [5, 6, 8]] return: X: extracted data y: extracted label (0 and 1, corresponding to two lists in cls) \"\"\" y_res_id = np.array([]) for i in cls[0]: y_res_id = np.hstack((y_res_id, np.where(y == i)[0])) n0 = len(y_res_id) for i in cls[1]: y_res_id = np.hstack((y_res_id, np.where(y == i)[0])) n1 = len(y_res_id) - n0 y_res_id = y_res_id.astype(int) X_res = X[y_res_id, :]/255.0 y_res = np.asarray([0]*n0 + [1]*n1) return (X_res, y_res)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-15",
        "source": "35.main.md",
        "section": "extract data for training",
        "content": "(X_train, y_train) = extract_data(Xtrain_all, ytrain_all, cls)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-16",
        "source": "35.main.md",
        "section": "extract data for test",
        "content": "(X_test, y_test) = extract_data(Xtest_all, ytest_all, cls) ``` Vì mỗi điểm dữ liệu có số phần tử là 784 (28x28), là một số khá nhỏ, nên ta không cần thêm bước giảm số chiều dữ liệu nữa. Tuy nhiên, tôi có thực hiện thêm một bước chuẩn hóa để đưa dữ liệu về đoạn `[0, 1]` bằng cách chia toàn bộ hai ma trận dữ liệu cho `255.0`. Tới đây ta có thể *train* mô hình Logistic Regression và đánh giá mô hình này. ```",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-17",
        "source": "35.main.md",
        "section": "train the logistic regression model",
        "content": "logreg = linear_model.LogisticRegression(C=1e5) # just a big number logreg.fit(X_train, y_train)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-18",
        "source": "35.main.md",
        "section": "predict",
        "content": "y_pred = logreg.predict(X_test) print \"Accuracy: %.2f %%\" %(100*accuracy_score(y_test, y_pred.tolist())) ``` ``` Accuracy: 99.95 % ``` Tuyệt vời, gần như 100% được phân loại chính xác. Điều này là dễ hiểu vì hai chữ số 0 và 1 khác nhau quá nhiều. Bộ cơ sở dữ liệu này với toàn bộ 10 classes hiện nay đã được phân loại với độ chính xác trên 99.7%. Chúng ta cùng đi tìm những ảnh bị phân loại sai: ```",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-19",
        "source": "35.main.md",
        "section": "display misclassified image(s)",
        "content": "mis = np.where((y_pred - y_test) != 0)[0] Xmis = X_test[mis, :] plt.axis('off') A = display_network(Xmis.T) f2 = plt.imshow(A, interpolation='nearest' ) plt.gray() plt.show() ``` ![](\\assets\\LogReg2\\0.png) Hình 3: Chữ số bị phân loại sai trong bài toán phân loại ảnh chữ số 0 và 1 Như vậy là chỉ có một ảnh bị phân loại sai. Ảnh này là chữ số 0 nhưng bị misclassified thành chữ số 1, có thể vì nét đậm nhất của nó rất giống với chữ số 1. Source code cho ví dụ này có thể được tìm thấy [ở đây](/assets/LogReg2/LogReg2.ipynb).",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-20",
        "source": "35.main.md",
        "section": "3. Binary Classifiers cho Multi-class Classification problems",
        "content": "Có lẽ nhiều bạn đang đặt câu hỏi: Các ví dụ trên đây đều làm với bài toán có hai classes. Vậy nếu có nhiều hơn hai classes, ví dụ như 10 classes của MNIST, thì làm thế nào? Có nhiều thuật toán khác được xây dựng riêng cho các bài toán với nhiều classes (multi-class classification problems), tôi sẽ giới thiệu sau. Còn bây giờ, chúng ta vẫn có thể sử dụng các *binary classifiers* để thực hiện công việc này, với một chút thay đổi. Có *ít nhất* bốn cách để áp dụng *binary classifiers* vào các bài toán multi-class classification:",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-21",
        "source": "35.main.md",
        "section": "One-vs-one",
        "content": "Xây dựng rất nhiều bộ binary classifiers cho từng cặp classes. Bộ thứ nhất phân biệt class 1 và class 2, bộ thứ hai phân biệt class 1 và class 3, … Khi có một dữ liệu mới vào, đưa nó vào toàn bộ các bộ binary classifiers trên. Kết quả cuối cùng có thể được xác định bằng cách xem class nào mà điểm dữ liệu đó được phân vào nhiều nhất (major voting). Hoặc với Logistic Regression thì ta có thể tính *tổng các xác suất* tìm được sau mỗi bộ binary classifier. Như vậy, nếu có \\(C\\) classes thì tổng số binary classifiers phải dùng là \\(\\frac{n(n-1)}{2}\\). Đây là một con số lớn, cách làm này không lợi về tính toán. Hơn nữa, nếu một chữ số thực ra là chữ số `1`, nhưng lại được đưa vào bộ phân lớp giữa các chữ số `5` và `6`, thì cả hai khả năng tìm được (là `5` hoặc `6`) đều không hợp lý!",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-22",
        "source": "35.main.md",
        "section": "Hierarchical (phân tầng)",
        "content": "Các làm như **one-vs-one** sẽ mất rất nhiều thời gian training vì có quá nhiều bộ phân lớp cần được xây dựng. Một cách khác giúp *tiết kiệm* số binary classifiers hơn đó là **hierarchical**. Ý tưởng như sau: Ví dụ với MNIST với 4 chữ số `4, 5, 6, 7`. Vì ta thấy chữ số `4` và `7` khá giống nhau, chữ số `5` và `6` khá giống nhau nên trước tiên chúng ta xây dựng bộ phân lớp `[4, 7] vs [5, 6]`. Sau đó xây dựng thêm hai bộ `4 vs 7` và `5 vs 6` nữa. Tổng cộng, ta cần 3 bộ binary classifiers. Chú ý rằng có nhiều cách chia khác nhau, ví dụ `[4, 5, 6] vs 7`, `[4, 5] vs 6`, rồi `4 vs 5`. Ưu điểm của phương pháp này là sử dụng ít bộ binary classifiers hơn **one-vs-one**. Hạn chế lớn nhất của nó là việc nếu chỉ một binary classifier cho kết quả sai thì kết quả cuối cùng chắc chắn sẽ sai. Ví dụ, nếu 1 ảnh chứa chữ số `5`, nhưng ngay bước đầu tiên đã bị misclassifed sang nhánh `[4, 7]` thì kết quả cuối cùng sẽ là `4` hoặc `7`, cả hai đều sai.",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-23",
        "source": "35.main.md",
        "section": "Binary coding",
        "content": "Có một cách giảm số binary classifiers hơn nữa là **binary coding**, tức *mã hóa* output của mỗi class bằng một số nhị phân. Ví dụ, nếu có 4 classes thì class thứ nhất được mã hóa là `00`, ba class kia được mã hóa lần lượt là `01, 10` và `11`. Với cách làm này, số bộ binary classifiers phải thực hiện chỉ là \\(m = \\left\\lceil\\log\\_2(C)\\right\\rceil\\) trong đó \\(C\\) là số lượng class, \\(\\left\\lceil a \\right\\rceil\\) là *số nguyên nhỏ nhất không nhỏ hơn* \\(a\\). Class thứ nhất sẽ đi tìm bit đầu tiên của output (đã được mã hóa nhị phân), class thứ hai sẽ đi tìm bit thứ hai, … Cách làm này sử dụng một số lượng nhỏ nhất các bộ *binary classifiers*. Nhưng nó có một hạn chế rất lớn là chỉ cần một bit bị phân loại sai sẽ dẫn đến dữ liệu bị phân loại sai. Hơn nữa, nếu số classes không phải là lũy thừa của hai, mã nhị phân nhận được có thể là một giá trị không tương ứng với class nào!",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-24",
        "source": "35.main.md",
        "section": "one-vs-rest hay one-hot coding",
        "content": "Phương pháp được sử dụng nhiều nhất là **one-vs-rest** (một số tài liệu gọi là **ove-vs-all**, **one-against-rest**, hoặc **one-against-all**) . Cụ thể, nếu có \\(C\\) classes thì ta sẽ xây dựng \\(C\\) classifiers, mỗi classifier tương ứng với một class. Classifier thứ nhất giúp phân biệt `class 1` vs `not class 1`, tức xem một điểm có thuộc class 1 hay không, hoặc xác suất để một điểm rơi vào class 1 là bao nhiêu. Tương tự như thế, classifier thứ hai sẽ phân biệt `class 2` vs `not class 2`, … Kết quả cuối cùng có thể được xác định bằng cách xác định class mà một điểm rơi vào với xác suất cao nhất. Phương pháp này còn được gọi là **one-hot coding** (được sử dụng nhiều nên có rất nhiều tên) vì với cách mã hóa trên, giả sử có 4 classes, class 1, 2, 3, 4 sẽ lần lượt được mã hóa dưới dạng nhị phân bởi `1000, 0100, 0010` hoặc `0001`. One-hot vì chỉ có *one* bit là *hot* (bằng `1`). Hàm Logistic Regression trong thư viện sklearn có thể được dùng trực tiếp để áp dụng vào các bài toán multi-class classification với phương pháp **one-vs-rest**. Với bài toán MNIST như nêu ở phần 2, ta có thể thêm ba dòng lệnh sau để chạy trên toàn bộ 10 classes: ``` logreg.fit(Xtrain_all, ytrain_all) y_pred = logreg.predict(Xtest_all) print \"Accuracy: %.2f %%\" %(100*accuracy_score(ytest_all, y_pred.tolist())) ``` Kết quả thu được khoảng 91% sau hơn 20 phút chạy (tùy thuộc vào máy). Đây vẫn là một kết quả quá thấp so với con số 99.7%. Thậm chí phương pháp học máy *không học gì* như [K-neareast neighbors cũng đã đạt hơn 96%](/2017/01/08/knn/#try-this-yourself) với thời gian chạy ngắn hơn một chút. Một chú ý nhỏ: phương pháp mặc định cho các bài toán multi-class của hàm này được xác định bởi biến `multi_class`. Có hai lựa chọn cho biến này, trong đó lựa chọn mặc định là `ovr` tức **one-vs-rest**, lựa chọn còn lại sẽ được tôi đề cập trong một bài gần đây. Lựa chọn thứ hai không phải cho binary classifiers nên tôi không đề cập trong bài này, có thể sau một vài bài nữa (Xem thêm [`sklearn.linear_model.LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html))",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-25",
        "source": "35.main.md",
        "section": "Kết hợp các phương pháp trên",
        "content": "Nhắc lại rằng các linear binary classifiers tôi đã trình bày yêu cầu dữ liệu là *linearly separable* hoặc *nearly linearly separable*. Ta cũng có thể mở rộng định nghĩa này cho các bài toán multi-class. Nếu hai class bất kỳ là *linearly separable* thì ta coi dữ liệu đó là *linearly separable*. Thế nhưng, có những loại dữ liệu *linearly separable* mà chỉ một số trong 4 phương pháp trên đây là phù hợp, hoặc có những loại dữ liệu yêu cầu phải kết hợp nhiều phương pháp mới thực hiện được. Xét ba ví dụ sau: ![](\\assets\\LogReg2\\dist.png) Hình 4: Một số ví dụ về phân phối của các classes trong bài toàn multi-class * Hình 4a): cả 4 phương pháp trên đây đều có thể áp dụng được. * Hình 4b): one-vs-rest không phù hợp vì class màu xanh lục và class *rest* (hợp của xanh lam và đỏ) là không *linearly separable*. Lúc này, one-vs-one hoặc hierarchical phù hợp hơn. * Hình 4c): Tương tự như trên, ba class lam, lục, đỏ thẳng hàng nên sẽ không dùng được one-vs-rét. one-vs-one vẫn làm việc vì từng đôi class một là *linearly separable*. Tương tự hierarchical cũng làm việc nếu ta phân chia các nhóm một cách hợp lý. Hoặc chúng ta có thể kết hợp nhiều phương pháp. Ví dụ: dùng one-vs-rest để tìm *đỏ* vs *không đỏ*. Nếu một điểm dữ liệu là *không đỏ*, với 3 class còn lại, chúng ta lại quay lại trường hợp Hình 4a) và có thể dùng các phương pháp khác. Nhưng khó khăn vẫn nằm ở việc phân nhóm như thế nào, liệu rằng những class nào có thể cho vào cùng một nhóm? Với những dữ liệu đơn giản, [K-means clustering](/2017/01/01/kmeans/) có thể là một giải pháp! Bạn đọc có thể xem thêm ví dụ áp dụng Logistic Regression cho cơ sở dữ liệu [Iris](/2017/01/08/knn/#bo-co-so-du-lieu-iris-iris-flower-dataset) trong [link này](http://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html) ![](http://scikit-learn.org/stable/_images/sphx_glr_plot_iris_logistic_001.png) Hình 5: Logistic Regression với Iris database. (Nguồn: [Logistic Regression 3-class Classifier](http://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html))",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-26",
        "source": "35.main.md",
        "section": "Biểu diễn dưới dạng Neural Networks",
        "content": "Lấy ví dụ với bài toán có 4 classes 1, 2, 3, 4; ta có thể biểu diễn các mô hình được đề cập trong phần 3 dưới dạng sau đây (giả sử input có số chiều là 7 và node output màu đỏ biểu diễn chung cho cả PLA, Logistic Regression và các networks với activation function khác): ![](\\assets\\LogReg2\\binaryclassifiers.png) Hình 6: Mô hình neural networks cho các phương pháp đề cập trong bài Lúc này, thay vì chỉ có 1 node output như [các phương pháp tôi đề cập trước đây](/2017/01/27/logisticregression/#-thao-luan) (Linear Regression, Perceptron Learning Algorithm, Logistic Regression), chúng ta thấy rằng các networks này đều có nhiều outputs. Và một vector trọng số \\(\\mathbf{w}\\) bây giờ đã trở thành *ma trận trọng số* \\(\\mathbf{W}\\) mà mỗi cột của nó tương ứng với vector trọng số của một node output. Việc tối ưu đồng thời các binary classifiers trong mỗi network cũng được tổng quát lên nhớ các phép tính với ma trận. Lấy ví dụ với công thức cập nhật của [logistic sigmoid regression](/2017/01/27/logisticregression/#cong-thuc-cap-nhat-cho-logistic-sigmoid-regression) : \\[ \\mathbf{w} = \\mathbf{w} + \\eta(y\\_i - z\\_i)\\mathbf{x}\\_i \\] Có thể tổng quát thành: \\[ \\mathbf{W} = \\mathbf{W} + \\eta\\mathbf{x}\\_i(\\mathbf{y}\\_i - \\mathbf{z}\\_i)^T \\] Với \\(\\mathbf{W}, \\mathbf{y}\\_i, \\mathbf{z}\\_i\\) lần lượt là ma trận trọng số, vector (cột) output *thật* với toàn bộ các binary classifiers tương ứng với điểm dữ liệu \\(\\mathbf{x}\\_i\\), và vector output tìm được của networks tại thời điểm đang xét nếu đầu vào mỗi network là \\(\\mathbf{x}\\_i\\). Chú ý rằng với Logistic Regression, vector \\(\\mathbf{y}\\_i\\) là một binary vector, vector \\(\\mathbf{z}\\_i\\) gồm các phần tử nằm trong khoảng \\((0, 1)\\).",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-27",
        "source": "35.main.md",
        "section": "Hạn chế của one-vs-rest",
        "content": "Xem xét lại phương pháp one-vs-rest theo góc nhìn xác suất, một điểm dữ liệu có thể được dự đoán thuộc vào class \\(1, 2, \\dots, C\\) với xác suất lần lượt là \\(p\\_1, p\\_2, \\dots, p\\_C\\). Tuy nhiên, tổng các xác suất này có thể không bằng 1! Có một phương pháp có thể làm cho nó *hợp lý hơn*, tức *ép* tổng các xác suất này bằng 1. Khi đó, với 1 điểm dữ liệu ta có thể nói xác suất nó rơi vào mỗi class là bao nhiêu. Phương pháp hấp dẫn này sẽ được đề cập trong bài [Softmax Regression](/2017/02/16/softmax/). Mời bạn đón đọc.",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "35.main-28",
        "source": "35.main.md",
        "section": "5. Tài liệu tham khảo",
        "content": "[1] [Multiclass classification - wiki](https://en.wikipedia.org/wiki/Multiclass_classification) [2] [Logistic Regression 3-class Classifier](http://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html)",
        "url": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/"
    },
    {
        "id": "9.main-1",
        "source": "9.main.md",
        "section": "Introduction",
        "content": "**Tất cả các bài tập trong bài viết này có thể được thực hiện trực tiếp trên trình duyệt qua trang web [FundaML](https://fundaml.com)** * [2.0. Mảng nhiều chiều](#-mang-nhieu-chieu) * [2.1. Khởi tạo một ma trận](#-khoi-tao-mot-ma-tran) + [2.1.1. Khởi tạo một ma trận](#-khoi-tao-mot-ma-tran-1) * [2.2. Ma trận đơn vị và ma trận đường chéo](#-ma-tran-don-vi-va-ma-tran-duong-cheo) + [2.2.1. Ma trận đơn vị](#-ma-tran-don-vi) + [2.2.2. Ma trận đường chéo](#-ma-tran-duong-cheo) * [2.3. Kích thước của ma trận](#-kich-thuoc-cua-ma-tran) * [2.4. Truy cập vào từng phần tử của ma trận](#-truy-cap-vao-tung-phan-tu-cua-ma-tran) + [2.4.1. Truy cập vào từng phần tử](#-truy-cap-vao-tung-phan-tu) - [2.4.1.1. Cách 1: giống với list](#-cach--giong-voi-list) - [2.4.1.2. Cách 2: giống như Matlab](#-cach--giong-nhu-matlab) + [2.4.2. Truy cập vào hàng/cột](#-truy-cap-vao-hangcot) * [2.5. Truy cập vào nhiều phần tử của ma trận](#-truy-cap-vao-nhieu-phan-tu-cua-ma-tran) + [2.5.1. Nhiều phần tử trong cùng một hàng](#-nhieu-phan-tu-trong-cung-mot-hang) + [2.5.2. Nhiều phần tử trong cùng một cột](#-nhieu-phan-tu-trong-cung-mot-cot) + [2.5.3. Nhiều hàng, nhiều cột](#-nhieu-hang-nhieu-cot) + [2.5.4. Cặp các toạ độ](#-cap-cac-toa-do) * [2.6. np.sum, np.min, np.max, np.mean cho mảng nhiều chiều](#-npsum-npmin-npmax-npmean-cho-mang-nhieu-chieu) + [`keepdims = True`](#keepdims--true) * [2.7. Các phép toán tác động đến mọi phần tử của ma trận](#-cac-phep-toan-tac-dong-den-moi-phan-tu-cua-ma-tran) + [2.7.1. Tính toán giữa một mảng hai chiều và một số vô hướng](#-tinh-toan-giua-mot-mang-hai-chieu-va-mot-so-vo-huong) + [2.7.2. np.abs, np.sin, np.exp, …](#-npabs-npsin-npexp-) * [2.8. Các phép toán giữa hai ma trận I](#-cac-phep-toan-giua-hai-ma-tran-i) * [2.9. Chuyện vị ma trận, Reshape ma trận](#-chuyen-vi-ma-tran-reshape-ma-tran) + [2.9.1 Chuyển vị ma trận](#-chuyen-vi-ma-tran) + [2.9.2. Reshape](#-reshape) + [2.9.3. Thứ tự của phép toán reshape](#-thu-tu-cua-phep-toan-reshape) * [2.10. Các phép toán giữa ma trận và vector](#-cac-phep-toan-giua-ma-tran-va-vector) * [2.11. Tích giữa hai ma trận, tích giữa ma trận và vector](#-tich-giua-hai-ma-tran-tich-giua-ma-tran-va-vector) + [2.11.1. Tích giữa hai ma trận](#-tich-giua-hai-ma-tran) + [2.11.2. Tích giữa một ma trận và một vector](#-tich-giua-mot-ma-tran-va-mot-vector) * [2.12. Softmax III - Phiên bản tổng quát](#-softmax-iii---phien-ban-tong-quat)",
        "url": "https://machinelearningcoban.com/2017/10/20/fundaml_matrices/"
    },
    {
        "id": "9.main-2",
        "source": "9.main.md",
        "section": "2.0. Mảng nhiều chiều",
        "content": "Trong Numpy, người ta thường dùng mảng numpy hai chiều để thể hiện một ma trận. Mảng hai chiều có thể coi là một mảng của các mảng một chiều. Trong đó, mỗi *mảng nhỏ một chiều* tương ứng với một hàng của ma trận. Nói cách khác, ma trận có thể được coi là mảng của các vector hàng - mỗi vector hàng được biểu diễn bằng một mảng numpy một chiều. --- ![](/assets/fundaml/matrix.png) ---",
        "url": "https://machinelearningcoban.com/2017/10/20/fundaml_matrices/"
    },
    {
        "id": "46.main-1",
        "source": "46.main.md",
        "section": "Introduction",
        "content": "Những năm gần đây, AI - Artificial Intelligence (Trí Tuệ Nhân Tạo), và cụ thể hơn là Machine Learning (Học Máy hoặc Máy Học) nổi lên như một bằng chứng của cuộc cách mạng công nghiệp lần thứ tư (1 - động cơ hơi nước, 2 - năng lượng điện, 3 - công nghệ thông tin). Trí Tuệ Nhân Tạo đang len lỏi vào mọi lĩnh vực trong đời sống mà có thể chúng ta không nhận ra. Xe tự hành của Google và Tesla, hệ thống tự tag khuôn mặt trong ảnh của Facebook, trợ lý ảo Siri của Apple, hệ thống gợi ý sản phẩm của Amazon, hệ thống gợi ý phim của Netflix, máy chơi cờ vây AlphaGo của Google DeepMind, …, chỉ là một vài trong vô vàn những ứng dụng của AI/Machine Learning. (Xem thêm [Jarvis - trợ lý thông minh cho căn nhà của Mark Zuckerberg](https://www.facebook.com/zuck/posts/10103351073024591)) Machine Learning là một tập con của AI. Theo định nghĩa của Wikipedia, *Machine learning is the subfield of computer science that “gives computers the ability to learn without being explicitly programmed”*. Nói đơn giản, Machine Learning là một lĩnh vực nhỏ của Khoa Học Máy Tính, nó có khả năng tự học hỏi dựa trên dữ liệu đưa vào mà không cần phải được lập trình cụ thể. Bạn Nguyễn Xuân Khánh tại đại học Maryland đang viết một cuốn sách về Machine Learning bằng tiếng Việt khá thú vị, các bạn có thể tham khảo bài [Machine Learning là gì?](https://khanh-personal.gitbook.io/ml-book-vn/machine-learning-la-gi). Những năm gần đây, khi mà khả năng tính toán của các máy tính được nâng lên một tầm cao mới và lượng dữ liệu khổng lồ được thu thập bởi các hãng công nghệ lớn, Machine Learning đã tiến thêm một bước dài và một lĩnh vực mới được ra đời gọi là Deep Learning (Học Sâu - *thực sự tôi không muốn dịch từ này ra tiếng Việt*). Deep Learning đã giúp máy tính thực thi những việc tưởng chừng như không thể vào 10 năm trước: phân loại cả ngàn vật thể khác nhau trong các bức ảnh, tự tạo chú thích cho ảnh, bắt chước giọng nói và chữ viết của con người, giao tiếp với con người, hay thậm chí cả sáng tác văn hay âm nhạc (Xem thêm [8 Inspirational Applications of Deep Learning](http://machinelearningmastery.com/inspirational-applications-deep-learning/)) --- ![](/assets/introduce/aimldl.png) Mối quan hệ giữa AI, Machine Learning và Deep Learning. (Nguồn: [What’s the Difference Between Artificial Intelligence, Machine Learning, and Deep Learning?](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)) ---",
        "url": "https://machinelearningcoban.com/2016/12/26/introduce/"
    },
    {
        "id": "34.main-1",
        "source": "34.main.md",
        "section": "Introduction",
        "content": "Các bài toán classification thực tế thường có rất nhiều classes (multi-class), các [binary classifiers mặc dù có thể áp dụng cho các bài toán multi-class](/2017/02/11/binaryclassifiers/#-binary-classifiers-cho-multi-class-classification-problems), chúng vẫn có những hạn chế nhất định. Với binary classifiers, kỹ thuật được sử dụng nhiều nhất [**one-vs-rest**](/2017/02/11/binaryclassifiers/#one-vs-rest-hay-one-hot-coding) có [một hạn chế về tổng các xác suất](/2017/02/11/binaryclassifiers/#han-che-cua-one-vs-rest). Trong post này, một phương pháp mở rộng của Logistic Regression sẽ được giới thiệu giúp khắc phục hạn chế trên. Một lần nữa, dù là Softmax **Regression**, phương pháp này được sử dụng rộng rãi như một phương pháp classification. **Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Softmax function](#-softmax-function) + [2.1. Công thức của Softmax function](#-cong-thuc-cua-softmax-function) + [2.2. Softmax function trong Python](#-softmax-function-trong-python) + [2.3. Một vài ví dụ](#-mot-vai-vi-du) + [2.4. Phiên bản ổn định hơn của softmax function](#-phien-ban-on-dinh-hon-cua-softmax-function) * [3. Hàm mất mát và phương pháp tối ưu](#-ham-mat-mat-va-phuong-phap-toi-uu) + [3.1. One hot coding](#-one-hot-coding) + [3.2. Cross Entropy](#-cross-entropy) + [3.3. Hàm mất mát cho Softmax Regression](#-ham-mat-mat-cho-softmax-regression) + [3.4. Tối ưu hàm mất mát](#-toi-uu-ham-mat-mat) + [3.5. Logistic Regression là một trường hợp đặt biệt của Softmax Regression](#-logistic-regression-la-mot-truong-hop-dat-biet-cua-softmax-regression) * [4. Một vài lưu ý khi lập trình với Python](#-mot-vai-luu-y-khi-lap-trinh-voi-python) + [4.1. Bắt đầu với dữ liệu nhỏ](#-bat-dau-voi-du-lieu-nho) + [4.2. Ma trận one-hot coding](#-ma-tran-one-hot-coding) + [4.3. Kiểm tra đạo hàm](#-kiem-tra-dao-ham) + [4.4. Hàm chính cho training Softmax Regression](#-ham-chinh-cho-training-softmax-regression) + [4.5. Hàm dự đoán class cho dữ liệu mới](#-ham-du-doan-class-cho-du-lieu-moi) * [5. Ví dụ với Python](#-vi-du-voi-python) + [5.1. Simulated data](#-simulated-data) + [5.2. Softmax Regression cho MNIST](#-softmax-regression-cho-mnist) * [6. Thảo luận](#-thao-luan) + [6.1 Boundary tạo bởi Softmax Regression là linear](#-boundary-tao-boi-softmax-regression-la-linear) + [6.2. Softmax Regression là một trong hai classifiers phổ biến nhất](#-softmax-regression-la-mot-trong-hai-classifiers-pho-bien-nhat) + [6.3. Source code](#-source-code) * [Tài liệu tham khảo](#tai-lieu-tham-khao) **Một lưu ý nhỏ:** Hàm mất mát của Softmax Regression trông có vẻ khá phức tạp, nhưng nếu kiên trì đọc đến phần phương pháp tối ưu, các bạn sẽ thấy vẻ đẹp ẩn sau sự phức tạp đó. Gradient của hàm mất mát và công thức cập nhật ma trận trọng số là rất đơn giản. (Đơn giản sau vài bước biến đổi toán học *trông có vẻ* phức tạp). Nếu có điểm nào khó hiểu, bạn đọc được khuyến khích đọc lại các bài trước, trong đó quan trọng nhất là [Bài 10: Logistic Regression](/2017/01/27/logisticregression/).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-2",
        "source": "34.main.md",
        "section": "1. Giới thiệu",
        "content": "Tôi xin phép được bắt đầu từ mô hình [**one-vs-rest**](/2017/02/11/binaryclassifiers/#one-vs-rest-hay-one-hot-coding) được trình bày trong bài trước. Output layer (màu đỏ nhạt) có thể phân tách thành hai *sublayer* như hình dưới đây: ![](\\assets\\13_softmax\\onevsrest.png) Hình 1: Multi-class classification với Logistic Regression và one-vs-rest. Dữ liệu \\(\\mathbf{x}\\) có số chiều là \\((d +1)\\) vì có phần tử 1 được thêm vào phía trước, thể hiện hệ số tự do trong hàm tuyến tính. Hệ số tự do \\(w\\_{0j}\\) còn được gọi là bias. Giả sử số classes là \\(C\\). Với one-vs-rest, chúng ta cần xây dựng \\(C\\) Logistic Regression khác nhau. Các *đầu ra dự đoán* được tính theo hàm sigmoid: \\[ a\\_i = \\text{sigmoid}(z\\_i) = \\text{sigmoid}(\\mathbf{w}\\_i^T\\mathbf{x}) \\] Trong kỹ thuật này, các phần tử \\(a\\_i, i = 1, 2, \\dots, C\\) được suy ra trực tiếp chỉ với \\(z\\_i\\). Vì vậy, không có mối quan hệ chặt chẽ nào giữa các \\(a\\_i\\), tức tổng của chúng có thể nhỏ hơn hoặc lớn hơn 1. Nếu ta có thể khai thác được mỗi quan hệ giữa các \\(z\\_i\\) thì kết quả của bài toán classification có thể tốt hơn. Chú ý rằng các mô hình Linear Regression, PLA, Logistic Regression chỉ có 1 node ở output layer. Trong các trường hợp đó, tham số mô hình chỉ là 1 vector \\(\\mathbf{w}\\). Trong trường hợp output layer có nhiều hơn 1 node, tham số mô hình sẽ là tập hợp tham số \\(\\mathbf{w}\\_i\\) ứng với từng node. Lúc này, ta có *ma trận trọng số* \\(\\mathbf{W} = [\\mathbf{w}\\_1, \\mathbf{w}\\_2, \\dots, \\mathbf{w}\\_C]\\).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-3",
        "source": "34.main.md",
        "section": "2.1. Công thức của Softmax function",
        "content": "Chúng ta cần một mô hình xác suất sao cho với mỗi input \\(\\mathbf{x}\\), \\(a\\_i\\) thể hiện xác suất để input đó rơi vào class \\(i\\). Vậy điều kiện cần là các \\(a\\_i\\) phải dương và tổng của chúng bằng 1. Để có thể thỏa mãn điều kiện này, chúng ta cần *nhìn vào* mọi giá trị \\(z\\_i\\) và dựa trên quan hệ giữa các \\(z\\_i\\) này để tính toán giá trị của \\(a\\_i\\). Ngoài các điều kiện \\(a\\_i\\) lớn hơn 0 và có tổng bằng 1, chúng ta sẽ thêm một điều kiện cũng rất tự nhiên nữa, đó là: giá trị \\(z\\_i = \\mathbf{w}\\_i^T\\mathbf{x}\\) càng lớn thì xác suất dữ liệu rơi vào class \\(i\\) càng cao. Điều kiện cuối này chỉ ra rằng chúng ta cần một hàm đồng biến ở đây. Chú ý rằng \\(z\\_i \\) có thể nhận giá trị cả âm và dương. Một hàm số *mượt* đơn giản có thể chắc chắn biến \\(z\\_i \\) thành một giá trị dương, và hơn nữa, đồng biến, là hàm \\(\\exp(z\\_i) = e^{z\\_i}\\). Điều kiện *mượt* để thuận lợi hơn trong việc tính đạo hàm sau này. Điều kiện cuối cùng, tổng các \\(a\\_i\\) bằng 1 có thể được đảm bảo nếu: \\[ a\\_i = \\frac{\\exp(z\\_i)}{\\sum\\_{j=1}^C \\exp(z\\_j)}, ~~ \\forall i = 1, 2, \\dots, C \\] Hàm số này, tính tất cả các \\(a\\_i\\) dựa vào tất cả các \\(z\\_i\\), thõa mãn tất cả các điều kiện đã xét: dương, tổng bằng 1, giữ được *thứ tự* của \\(z\\_i\\). Hàm số này được gọi là *softmax function*. Chú ý rằng với cách định nghĩa này, không có xác suất \\(a\\_i\\) nào tuyệt đối bằng 0 hoặc tuyệt đối bằng 1, mặc dù chúng có thể rất gần 0 hoặc 1 khi \\(z\\_i\\) rất nhỏ hoặc rất lớn khi so sánh với các \\(z\\_j, j \\neq i\\). Lúc này, ta có thể giả sử rằng: \\[ P(y\\_k = i | \\mathbf{x}\\_k; \\mathbf{W}) = a\\_i \\] Trong đó, \\(P(y = i | \\mathbf{x}; \\mathbf{W})\\) được hiểu là xác suất để một điểm dữ liệu \\(\\mathbf{x}\\) rơi vào class thứ \\(i\\) nếu biết tham số mô hình (ma trận trọng số) là \\(\\mathbf{W}\\). Hình vẽ dưới đây thể hiện mạng Softmax Regression dưới dạng neural network: ![](\\assets\\13_softmax\\softmax_nn.png) Hình 2: Mô hình Softmax Regression dưới dạng Neural network. Ở phần bên phải, hàm tuyến tính \\(\\Sigma\\) và hàm softmax (activation function) được tách riêng ra để phục vụ cho mục đích minh họa. Dạng *short form* ở bên phải là dạng hay được sử dụng trong các Neural Networks, lớp \\(\\mathbf{a}\\) được ngầm hiểu là bao gồm cả lớp \\(\\mathbf{z}\\).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-4",
        "source": "34.main.md",
        "section": "2.2. Softmax function trong Python",
        "content": "Dưới đây là một đoạn code viết hàm softmax. Đầu vào là một ma trận với mỗi cột là một vector \\(\\mathbf{z}\\), đầu ra cũng là một ma trận mà mỗi cột có giá trị là \\(\\mathbf{a} = \\text{softmax}(\\mathbf{z})\\). Các giá trị của \\(\\mathbf{z}\\) còn được gọi là **scores**. ``` import numpy as np def softmax(Z): \"\"\" Compute softmax values for each sets of scores in V. each column of V is a set of score. \"\"\" e_Z = np.exp(Z) A = e_Z / e_Z.sum(axis = 0) return A ```",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-5",
        "source": "34.main.md",
        "section": "2.3. Một vài ví dụ",
        "content": "Hình 3 dưới đây là một vài ví dụ về mối quan hệ giữa đầu vào và đầu ra của hàm softmax. Hàng trên màu xanh nhạt thể hiện các scores \\(z\\_i\\) với giả sử rằng số classes là 3. Hàng dưới màu đỏ nhạt thể hiện các giá trị đầu ra \\(a\\_i\\) của hàm softmax. ![](\\assets\\13_softmax\\softmax_ex.png) Hình 3: Một số ví dụ về đầu vào và đầu ra của hàm softmax. Có một vài quan sát như sau: * Cột 1: Nếu các \\(z\\_i\\) bằng nhau, thì các \\(a\\_i\\) cũng bằng nhau và bằng 1/3. * Cột 2: Nếu giá trị lớn nhất trong các \\(z\\_i\\) là \\(z\\_1\\) vẫn bằng 2, nhưng các giá trị khác thay đổi, thì mặc dù xác suất tương ứng \\(a\\_1\\) vẫn là lớn nhất, nhưng nó đã thay đổi lên hơn 0.5. Đây chính là một lý do mà tên của hàm này có từ *soft*. (*max* vì phẩn từ lớn nhất vẫn là phần tử lớn nhất). * Cột 3: Khi các giá trị \\(z\\_i\\) là âm thì các giá trị \\(a\\_i\\) vẫn là dương và thứ tự vẫn được đảm bảo. * Cột 4: Nếu \\(z\\_1 = z\\_2\\), thì \\(a\\_1 = a\\_2\\). Bạn đọc có thể thử với các giá trị khác trực tiếp trên trình duyệt trong [link này](http://neuralnetworksanddeeplearning.com/chap3.html), kéo xuống phần Softmax.",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-6",
        "source": "34.main.md",
        "section": "2.4. Phiên bản ổn định hơn của softmax function",
        "content": "Khi một trong các \\(z\\_i\\) quá lớn, việc tính toán \\(\\exp(z\\_i)\\) có thể gây ra hiện tượng tràn số (overflow), ảnh hưởng lớn tới kết quả của hàm softmax. Có một cách khắc phục hiện tượng này bằng cách dựa trên quan sát sau: \\[ \\begin{eqnarray} \\frac{\\exp(z\\_i)}{\\sum\\_{j=1}^C \\exp(z\\_j)} &=& \\frac{\\exp(-c)\\exp(z\\_i)}{\\exp(-c)\\sum\\_{j=1}^C \\exp(z\\_j)}\\newline &=& \\frac{\\exp(z\\_i-c)}{\\sum\\_{j=1}^C \\exp(z\\_j-c)} \\end{eqnarray} \\] với \\(c\\) là một hằng số bất kỳ. Vậy một phương pháp đơn giản giúp khắc phục hiện tượng overflow là trừ tất cả các \\(z\\_i\\) đi một giá trị đủ lớn. Trong thực nghiệm, giá trị đủ lớn này thường được chọn là \\(c = \\max\\_i z\\_i\\). Vậy chúng ta có thể sửa đoạn code cho hàm `softmax` phía trên bằng cách trừ mỗi cột của ma trận đầu vào `Z` đi giá trị lớn nhất trong cột đó. Ta có phiên bản ổn định hơn là `softmax_stable`: ``` def softmax_stable(Z): \"\"\" Compute softmax values for each sets of scores in Z. each column of Z is a set of score. \"\"\" e_Z = np.exp(Z - np.max(Z, axis = 0, keepdims = True)) A = e_Z / e_Z.sum(axis = 0) return A ``` trong đó `axis = 0` nghĩa là lấy `max` theo cột (`axis = 1` sẽ lấy max theo hàng), `keepdims = True` để đảm bảo phép trừ giữa ma trận `Z` và vector thực hiện được.",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-7",
        "source": "34.main.md",
        "section": "3.1. One hot coding",
        "content": "Với cách biểu diễn network như trên, mỗi output sẽ không còn là một giá trị tương ứng với mỗi class nữa mà sẽ là một vector có đúng 1 phần tử bằng 1, các phần tử còn lại bằng 0. Phần tử bằng 1 năm ở vị trí tương ứng với class đó, thể hiện rằng điểm dữ liệu đang xét rơi vào class này với xác suất bằng 1 (*sự thật* là như thế, không cần dự đoán). Cách *mã hóa* output này chính là *one-hot coding* mà tôi đã đề cập trong bài [K-means clustering](/2017/01/01/kmeans/) và [bài trước](/2017/02/11/binaryclassifiers/#one-vs-rest-hay-one-hot-coding). Khi sử dụng mô hình Softmax Regression, với mỗi đầu vào \\(\\mathbf{x}\\), ta sẽ có *đầu ra dự đoán* là \\(\\mathbf{a} = \\text{softmax}(\\mathbf{W}^T\\mathbf{x})\\). Trong khi đó, *đầu ra thực sự* chúng ta có là vector \\(\\mathbf{y}\\) được biểu diễn dưới dạng one-hot coding. Hàm mất mát sẽ được xây dựng để tối thiểu sự khác nhau giữa *đầu ra dự đoán* \\(\\mathbf{a}\\) và *đầu ra thực sự* \\(\\mathbf{y}\\). Một lựa chọn đầu tiên ta có thể nghĩ tới là: \\[ J(\\mathbf{W}) = \\sum\\_{i=1}^N ||\\mathbf{a}\\_i - \\mathbf{y}\\_i||\\_2^2 \\] **Tuy nhiên đây chưa phải là một lựa chọn tốt**. Khi đánh giá sự khác nhau (hay khoảng cách) giữa hai phân bố xác suất (probability distributions), chúng ta có một đại lượng đo đếm khác hiệu quả hơn. Đại lượng đó có tên là [**cross entropy**](https://en.wikipedia.org/wiki/Cross_entropy).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-8",
        "source": "34.main.md",
        "section": "3.2. Cross Entropy",
        "content": "Cross entropy giữa hai phân phối \\(\\mathbf{p}\\) và \\(\\mathbf{q}\\) được định nghĩa là: \\[ H(\\mathbf{p}, \\mathbf{q}) = \\mathbf{E\\_p}[-\\log \\mathbf{q}] \\] Với \\(\\mathbf{p}\\) và \\(\\mathbf{q}\\) là rời rạc (như \\(\\mathbf{y}\\) và \\(\\mathbf{a}\\) trong bài toán của chúng ta), công thức này được viết dưới dạng: \\[ H(\\mathbf{p}, \\mathbf{q}) =-\\sum\\_{i=1}^C p\\_i \\log q\\_i ~~~ (1) \\] Để hiểu rõ hơn ưu điểm của hàm cross entropy và hàm bình phương khoảng cách thông thường, chúng ta cùng xem Hình 4 dưới đây. Đây là ví dụ trong trường hợp \\(C = 2\\) và \\(p\\_1\\) lần lượt nhận các giá trị \\(0.5, 0.1\\) và \\(0.8\\). |  |  |  | | --- | --- | --- | |  |  |  | Hình 4: So sánh giữa hàm cross entropy và hàm bình phương khoảng cách. Các điểm màu xanh lục thể hiện các giá trị nhỏ nhất của mỗi hàm. Có hai nhận xét quan trọng sau đây: * Giá trị nhỏ nhất của cả hai hàm số đạt được khi \\(q = p\\) tại hoành độ của các điểm màu xanh lục. * Quan trọng hơn, hàm cross entropy nhận giá trị rất cao (tức loss rất cao) khi \\(q\\) ở xa \\(p\\). Trong khi đó, sự chênh lệch giữa các loss ở gần hay xa nghiệm của hàm bình phương khoảng cách \\((q - p)^2\\) là không đáng kể. Về mặt tối ưu, hàm cross entropy sẽ cho nghiệm *gần* với \\(p\\) hơn vì những nghiệm ở xa bị *trừng phạt* rất nặng. Hai tính chất trên đây khiến cho cross entropy được sử dụng rộng rãi khi tính khoảng cách giữa hai phân phối xác suất. **Chú ý:** Hàm cross entropy không có tính đối xứng \\(H(\\mathbf{p}, \\mathbf{q}) \\neq H(\\mathbf{q}, \\mathbf{p})\\). Điều này có thể dễ dàng nhận ra ở việc các thành phần của \\(\\mathbf{p}\\) trong công thức \\((1)\\) có thể nhận giá trị bằng 0, trong khi đó các thành phần của \\(\\mathbf{q}\\) phải là dương vì \\(\\log(0)\\) không xác định. Chính vì vậy, khi sử dụng cross entropy trong các bài toán supervised learning, \\(\\mathbf{p}\\) thường là *đầu ra thực sự* vì đầu ra thực sự chỉ có 1 thành phần bằng 1, còn lại bằng 0 (one-hot), \\(\\mathbf{q}\\) thường là *đầu ra dự đoán*, khi mà không có xác suất nào tuyệt đối bằng 1 hoặc tuyệt đối bằng 0 cả. Trong [Logistic Regression](/2017/01/27/logisticregression/), chúng ta cũng có hai phân phối đơn giản. (i) *Đầu ra thực sự* của điểm dữ liệu đầu vào \\(\\mathbf{x}\\_i\\) có phân phối xác suất là \\([y\\_i; 1 - y\\_i]\\) với \\(y\\_i\\) là xác suất để điểm dữ liệu đầu vào rơi vào class thứ nhất (bằng 1 nếu \\(y\\_i = 1\\), bằng 0 nếu \\(y\\_i = 0\\)). (ii). *Đầu ra dự đoán* của điểm dữ liệu đó là \\(a\\_i = \\text{sigmoid}(\\mathbf{w}^T\\mathbf{x})\\) là xác suất để điểm đó rơi vào class thứ nhất. Xác suất để điểm đó rơi vào class thứ hai có thể được dễ dàng suy ra lf \\(1 - a\\_i\\). Vì vậy, hàm mất mát trong Logistic Regression: \\[ J(\\mathbf{w}) = -\\sum\\_{i=1}^N(y\\_i \\log {a}\\_i + (1-y\\_i) \\log (1 - {a}\\_i)) \\] chính là một trường hợp đặc biệt của Cross Entropy. (\\(N\\) được dùng để thể hiện số điểm dữ liệu trong tập training). Với Softmax Regression, trong trường hợp có \\(C\\) classes, *loss* giữa đầu ra dự đoán và đầu ra thực sự của một điểm dữ liệu \\(\\mathbf{x}\\_i\\) được tính bằng: \\[ J(\\mathbf{W};\\mathbf{x}\\_i, \\mathbf{y}\\_i) = -\\sum\\_{j=1}^C y\\_{ji}\\log(a\\_{ji}) \\] Với \\(y\\_{ji}\\) và \\( a\\_{ji}\\) lần lượt là là phần tử thứ \\(j\\) của vector (xác suất) \\(\\mathbf{y}\\_i\\) và \\(\\mathbf{a}\\_i\\). Nhắc lại rằng đầu ra \\(\\mathbf{a}\\_i\\) phụ thuộc vào đầu vào \\(\\mathbf{x}\\_i\\) và ma trận trọng số \\(\\mathbf{W}\\).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-9",
        "source": "34.main.md",
        "section": "3.3. Hàm mất mát cho Softmax Regression",
        "content": "Kết hợp tất cả các cặp dữ liệu \\(\\mathbf{x}\\_i, \\mathbf{y}\\_i, i = 1, 2, \\dots, N\\), chúng ta sẽ có hàm mất mát cho Softmax Regression như sau: \\[ \\begin{eqnarray} J(\\mathbf{W}; \\mathbf{X}, \\mathbf{Y}) = -\\sum\\_{i = 1}^N \\sum\\_{j = 1}^C y\\_{ji}\\log(a\\_{ji}) \\newline = -\\sum\\_{i = 1}^N \\sum\\_{j = 1}^C y\\_{ji}\\log\\left(\\frac{\\exp(\\mathbf{w}\\_j^T\\mathbf{x}\\_i)}{\\sum\\_{k=1}^C \\exp(\\mathbf{w}\\_k^T\\mathbf{x}\\_i)}\\right) \\end{eqnarray} \\] Với ma trận trọng số \\(\\mathbf{W}\\) là biến cần tối ưu. Hàm mất mát này trông *có vẻ đáng sợ*, nhưng đừng sợ, đọc tiếp các bạn sẽ thấy đạo hàm của nó rất đẹp (*và đáng yêu*).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-10",
        "source": "34.main.md",
        "section": "3.4. Tối ưu hàm mất mát",
        "content": "Một lần nữa, chúng ta lại sử dụng [Stochastic Gradient Descent (SGD)](/2017/01/16/gradientdescent2/#-stochastic-gradient-descent) ở đây. Với chỉ một cặp dữ liệu \\((\\mathbf{x}\\_i, \\mathbf{y}\\_i)\\), ta có: \\[ J\\_i(\\mathbf{W}) \\triangleq J(\\mathbf{W}; \\mathbf{x}\\_i, \\mathbf{y}\\_i) = \\] \\[ \\begin{eqnarray} &=& -\\sum\\_{j = 1}^C y\\_{ji}\\log\\left(\\frac{\\exp(\\mathbf{w}\\_j^T\\mathbf{x}\\_i)}{\\sum\\_{k=1}^C \\exp(\\mathbf{w}\\_k^T\\mathbf{x}\\_i)}\\right) \\newline &=& -\\sum\\_{j=1}^C\\left(y\\_{ji} \\mathbf{w}\\_j^T\\mathbf{x}\\_i - y\\_{ji}\\log\\left(\\sum\\_{k=1}^C \\exp(\\mathbf{w}\\_k^T\\mathbf{x}\\_i)\\right)\\right) \\newline &=& -\\sum\\_{j=1}^C y\\_{ji} \\mathbf{w}\\_j^T\\mathbf{x}\\_i + \\log\\left(\\sum\\_{k=1}^C \\exp(\\mathbf{w}\\_k^T\\mathbf{x}\\_i)\\right) ~~ (3) \\end{eqnarray} \\] trong biến đổi ở dòng cuối cùng, tôi đã sử dụng quan sát: \\(\\sum\\_{j=1}^C y\\_{ji} = 1\\) vì nó là tổng các xác suất. Tiếp theo ta sử dụng công thức: \\[ \\frac{\\partial J\\_i(\\mathbf{W})}{\\partial \\mathbf{W}} = \\left[\\frac{\\partial J\\_i(\\mathbf{W})}{\\partial \\mathbf{w}\\_1}, \\frac{\\partial J\\_i(\\mathbf{W})}{\\partial \\mathbf{w}\\_2}, \\dots, \\frac{\\partial J\\_i(\\mathbf{W})}{\\partial \\mathbf{w}\\_C} \\right]~~(4) \\] Trong đó, gradient theo từng cột có thể tính được dựa theo \\((3)\\): \\[ \\begin{eqnarray} \\frac{\\partial J\\_i(\\mathbf{W})}{\\partial \\mathbf{w}\\_j} &=& -y\\_{ji}\\mathbf{x}\\_i + \\frac{\\exp(\\mathbf{w}\\_j^T\\mathbf{x}\\_i)}{\\sum\\_{k = 1}^C \\exp(\\mathbf{w}\\_k^T\\mathbf{x}\\_i)}\\mathbf{x}\\_i \\newline &=& -y\\_{ji}\\mathbf{x}\\_i + a\\_{ji} \\mathbf{x}\\_i = \\mathbf{x}\\_i (a\\_{ji} - y\\_{ji}) \\newline &=& e\\_{ji}\\mathbf{x}\\_{i} ~(\\text{where}~ e\\_{ji} = a\\_{ji} - y\\_{ji}) ~~(5) \\end{eqnarray} \\] Giá trị \\(e\\_{ji} = a\\_{ji} - y\\_{ji} \\) có thể được coi là *sai số dự đoán*. Đến đây ta đã được biểu thức rất đẹp rồi. Kết hợp \\((4)\\) và \\((5)\\) ta có: \\[ \\frac{\\partial J\\_i(\\mathbf{W})}{\\partial \\mathbf{W}} = \\mathbf{x}\\_i [e\\_{1i}, e\\_{2i}, \\dots, e\\_{Ci}] = \\mathbf{x}\\_i\\mathbf{e}\\_i^T \\] Từ đây ta cũng có thể suy ra rằng: \\[ \\frac{\\partial J(\\mathbf{W})}{\\partial \\mathbf{W}} = \\sum\\_{i=1}^N \\mathbf{x}\\_i\\mathbf{e}\\_i^T = \\mathbf{X}\\mathbf{E}^T \\] với \\(\\mathbf{E} = \\mathbf{A - Y}\\). Công thức tính gradient đơn giản thế này giúp cho cả [Batch Gradient Descent, Stochastic Gradient Descent (SGD), và Mini-batch Gradient Descent](/2017/01/16/gradientdescent2/#-bien-the-cua-gradient-descent) đều có thể dễ dàng được áp dụng. Giả sử rằng chúng ta sử dụng SGD, công thức cập nhật cho ma trận trọng số \\(\\mathbf{W}\\) sẽ là: \\[ \\mathbf{W} = \\mathbf{W} +\\eta \\mathbf{x}\\_{i}(\\mathbf{y}\\_i - \\mathbf{a}\\_i)^T \\] Bạn có thấy công thức này giống với [công thức cập nhật của Logistic Regression](/2017/01/27/logisticregression/#cong-thuc-cap-nhat-cho-logistic-sigmoid-regression) không! Thực ra:",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-11",
        "source": "34.main.md",
        "section": "3.5. Logistic Regression là một trường hợp đặt biệt của Softmax Regression",
        "content": "Khi \\(C = 2\\), Softmax Regression và Logistic Regression là giống nhau. Thật vậy, đầu ra dự đoán của Softmax Regression với \\(C= 2\\) có thể được viết dưới dạng: \\[ \\begin{eqnarray} a\\_1 &=& \\frac{\\exp(\\mathbf{w}\\_1^T\\mathbf{x})} {\\exp(\\mathbf{w}\\_1^T\\mathbf{x}) + \\exp(\\mathbf{w}\\_2^T\\mathbf{x})} \\newline &=& \\frac{1}{1 + \\exp((\\mathbf{w}\\_2 - \\mathbf{w}\\_1)^T\\mathbf{x})} \\end{eqnarray} \\] Đây chính là [sigmoid function](/2017/01/27/logisticregression/#sigmoid-function), là đầu ra dự đoán theo Logistic Regression. Khi \\(C = 2\\), bạn đọc cũng có thể thấy rằng hàm mất mát của Logistic và Softmax Regression đều là cross entropy. Hơn nữa, mặc dù có 2 outputs, Softmax Regression có thể rút gọn thành 1 output vì tổng 2 outputs luôn luôn bằng 1. Softmax Regression còn có các tên gọi khác là Multinomial Logistic Regression, Maximum Entropy Classifier, hay rất nhiều tên khác nữa. Xem thêm [Multinomial logistic regression - Wikipedia](https://en.wikipedia.org/wiki/Multinomial_logistic_regression)",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-12",
        "source": "34.main.md",
        "section": "4.1. Bắt đầu với dữ liệu nhỏ",
        "content": "Các bài toán Machine Learning thường có độ phức tạp cao với lượng dữ liệu lớn và nhiều chiều. Để có thể áp dụng một thuật toán vào một bài toán cụ thể, trước tiên chúng ta cần áp dụng thuật toán đó vào *simulated data* (dữ liệu giả) với số chiều và số điểm dữ liệu nhỏ hơn. *Simulated data* này thường được tạo ngẫu nhiên (có thể thêm vài ràng buộc tùy vào đặc thù của dữ liệu). Với *simulated data* nhỏ, chúng ta có thể debug nhanh hơn và thử với nhiều trường hợp *simulated data* khác nhau. Khi nào thấy thuật toán chạy đúng chúng ta mới đưa *dữ liệu thật* vào. Với Softmax Regression, tôi tạo *simulated data* như sau: ``` import numpy as np",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-13",
        "source": "34.main.md",
        "section": "randomly generate data",
        "content": "N = 2 # number of training sample d = 2 # data dimension C = 3 # number of classes X = np.random.randn(d, N) y = np.random.randint(0, 3, (N,)) ``` Trong ví dụ đơn giản này, số điểm dữ liệu chỉ là `N = 2`, số chiều dữ liệu `d = 2`, và số classes `C = 3`. Những giá trị đủ nhỏ này giúp cho việc kiểm tra có thể được thực hiện một cách tức thì. Sau khi thuật toán chạy đúng với những giá trị nhỏ này, ta có thể thay `N, d, C` bằng vài giá trị khác trước khi sử dụng dữ liệu thật.",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-14",
        "source": "34.main.md",
        "section": "4.2. Ma trận one-hot coding",
        "content": "Có một bước quan trọng nữa trong Softmax Regression là phải chuyển đổi mỗi label \\(y\\_i\\) thành một vector \\(\\mathbf{y}\\_i\\) dưới dạng one-hot coding. Trong đó, chỉ có đúng một phần tử của \\(\\mathbf{y}\\_i\\) bằng 1, các phần tử còn lại bằng 0. Như vậy, với \\(N\\) điểm dữ liệu và \\(C\\) classes, chúng ta sẽ có một ma trận có kích thước \\(C \\times N\\) trong đó mỗi cột chỉ có đúng 1 phần tử bằng 1, còn lại bằng 0. Nếu chúng ta lưu toàn bộ dữ liệu này thì sẽ bị lãng phí bộ nhớ. Một cách thường được sử dụng là lưu ma trận output \\(\\mathbf{Y}\\) dưới dạng *sparse matrix*. Về cơ bản, cách làm này chỉ lưu các **vị trí** khác 0 của ma trận và **giá trị** khác 0 đó. Python có hàm [scipy.sparse.coo\\_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html) giúp chúng ta thực hiện việc này. Với one-hot coding, tôi thực hiện như sau: ```",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-15",
        "source": "34.main.md",
        "section": "One-hot coding",
        "content": "from scipy import sparse def convert_labels(y, C = C): \"\"\" convert 1d label to a matrix label: each column of this matrix coresponding to 1 element in y. In i-th column of Y, only one non-zeros element located in the y[i]-th position, and = 1 ex: y = [0, 2, 1, 0], and 3 classes then return [[1, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0]] \"\"\" Y = sparse.coo_matrix((np.ones_like(y), (y, np.arange(len(y)))), shape = (C, len(y))).toarray() return Y Y = convert_labels(y, C) ```",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-16",
        "source": "34.main.md",
        "section": "4.3. Kiểm tra đạo hàm",
        "content": "Điều cốt lõi trong cách tối ưu hàm mất mát là tính gradient. Với biểu thức toán trông *khá rối mắt* như trên, rất dễ để các bạn nhầm lẫn ở một bước nào đó. Softmax Regression vẫn là một thuật toán đơn giản, sau này các bạn sẽ thấy nhưng biểu thức phức tạp hơn nhiều. Rất khó để có thể tính toán đúng gradient ở ngay lần thử đầu tiên. Trong thực nghiệm, một cách thường được làm là so sánh gradient tính được với *numeric gradient*, tức gradient tính theo định nghĩa. Bạn đọc được khuyến khích đọc cách [Kiểm tra đạo hàm](/2017/01/12/gradientdescent/#kiem-tra-dao-ham). Việc kiểm tra đạo hàm được thực hiện như sau: ```",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-17",
        "source": "34.main.md",
        "section": "cost or loss function",
        "content": "def cost(X, Y, W): A = softmax(W.T.dot(X)) return -np.sum(Y*np.log(A)) W_init = np.random.randn(d, C) def grad(X, Y, W): A = softmax((W.T.dot(X))) E = A - Y return X.dot(E.T) def numerical_grad(X, Y, W, cost): eps = 1e-6 g = np.zeros_like(W) for i in range(W.shape[0]): for j in range(W.shape[1]): W_p = W.copy() W_n = W.copy() W_p[i, j] += eps W_n[i, j] -= eps g[i,j] = (cost(X, Y, W_p) - cost(X, Y, W_n))/(2*eps) return g g1 = grad(X, Y, W_init) g2 = numerical_grad(X, Y, W_init, cost) print(np.linalg.norm(g1 - g2)) ``` ``` 2.70479295591e-10 ``` Như vậy, sự khác biệt giữa hai đạo hàm là rất nhỏ. Nếu các bạn thử vài trường hợp khác nữa của `N, C, d`, chúng ta sẽ thấy sự sai khác vẫn là nhỏ. Điều này chứng tỏ đạo hàm chúng ta tính được coi là chính xác. (Vẫn có thể có bug, chỉ khi nào kết quả cuối cùng với dữ liệu thật là chấp nhận được thì ta mới có thể bỏ cụm từ ‘có thể coi’ đi). Chú ý rằng, nếu `N, C, d` quá lớn, việc tính toán `numerical_grad` trở nên cực kỳ tốn thời gian và bộ nhớ. Chúng ta chỉ nên kiểm tra với những dữ liệu nhỏ.",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-18",
        "source": "34.main.md",
        "section": "4.4. Hàm chính cho training Softmax Regression",
        "content": "Sau khi đã có những hàm cần thiết và gradient được tính đúng, chúng ta có thể viết hàm chính có training Softmax Regression (theo SGD) như sau: ``` def softmax_regression(X, y, W_init, eta, tol = 1e-4, max_count = 10000): W = [W_init] C = W_init.shape[1] Y = convert_labels(y, C) it = 0 N = X.shape[1] d = X.shape[0] count = 0 check_w_after = 20 while count < max_count:",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-19",
        "source": "34.main.md",
        "section": "mix data",
        "content": "mix_id = np.random.permutation(N) for i in mix_id: xi = X[:, i].reshape(d, 1) yi = Y[:, i].reshape(C, 1) ai = softmax(np.dot(W[-1].T, xi)) W_new = W[-1] + eta*xi.dot((yi - ai).T) count += 1",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-20",
        "source": "34.main.md",
        "section": "stopping criteria",
        "content": "if count%check_w_after == 0: if np.linalg.norm(W_new - W[-check_w_after]) < tol: return W W.append(W_new) return W eta = .05 d = X.shape[0] W_init = np.random.randn(d, C) W = softmax_regression(X, y, W_init, eta)",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-21",
        "source": "34.main.md",
        "section": "W[-1] is the solution, W is all history of weights",
        "content": "```",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-22",
        "source": "34.main.md",
        "section": "4.5. Hàm dự đoán class cho dữ liệu mới",
        "content": "Sau khi train Softmax Regression và tính được ma trận hệ số `W`, class của một dữ liệu mới có thể tìm được bằng cách xác định vị trí của giá trị lớn nhất ở đầu ra dự đoán (tương ứng với xác suất điểm dữ liệu rơi vào class đó là lớn nhất). Chú ý rằng, các class được đánh số là `0, 1, 2, ..., C`. ``` def pred(W, X): \"\"\" predict output of each columns of X Class of each x_i is determined by location of max probability Note that class are indexed by [0, 1, 2, ...., C-1] \"\"\" A = softmax_stable(W.T.dot(X)) return np.argmax(A, axis = 0) ```",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-23",
        "source": "34.main.md",
        "section": "5.1. Simulated data",
        "content": "Để minh họa cách áp dụng Softmax Regression, tôi tiếp tục làm trên *simulated data*. **Tạo ba cụm dữ liệu** ``` means = [[2, 2], [8, 3], [3, 6]] cov = [[1, 0], [0, 1]] N = 500 X0 = np.random.multivariate_normal(means[0], cov, N) X1 = np.random.multivariate_normal(means[1], cov, N) X2 = np.random.multivariate_normal(means[2], cov, N)",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-24",
        "source": "34.main.md",
        "section": "each column is a datapoint",
        "content": "X = np.concatenate((X0, X1, X2), axis = 0).T",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-25",
        "source": "34.main.md",
        "section": "extended data",
        "content": "X = np.concatenate((np.ones((1, 3*N)), X), axis = 0) C = 3 original_label = np.asarray([0]*N + [1]*N + [2]*N).T ``` Phân bố của các dữ liệu được cho như hình dưới: ![](\\assets\\13_softmax\\ex1_1.png) Hình 5: Phân bố dữ liệu của các class. **Thực hiện Softmax Regression** ``` W_init = np.random.randn(X.shape[0], C) W = softmax_regression(X, original_label, W_init, eta) print(W[-1]) ``` ``` [[ 8.45809734 -3.88415491 -3.44660294] [-1.11205751  1.50441603 -0.76358758] [ 0.24484886  0.26085383  3.3658872 ]] ``` **Kết quả thu được** ![](\\assets\\13_softmax\\ex1_2.png) Hình 6: Ranh giới giữa các class tìm được bằng Softmax Regression. Ta thấy rằng Softmax Regression đã tạo ra các vùng cho mỗi class. Kết quả này là chấp nhận được. Từ hình trên ta cũng thấy rằng *đường ranh giới* giữa các classes là đường thẳng. Tôi sẽ chứng minh điều này ở phần sau.",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-26",
        "source": "34.main.md",
        "section": "5.2. Softmax Regression cho MNIST",
        "content": "Các ví dụ trên đây được trình bày để giúp bạn đọc hiểu rõ Softmax Regression hoạt động như thế nào. Khi làm việc với các bài toán thực tế, chúng ta nên sử dụng các thư viện có sẵn, trừ khi bạn có thêm bớt vài số hạng nữa trong hàm mất mat. Softmax Regression cũng được tích hợp trong hàm [sklearn.linear\\_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) của thư viện [sklearn](http://scikit-learn.org/stable/index.html). Để sử dụng Softmax Regression, ta cần thêm một vài thuộc tính nữa: ``` linear_model.LogisticRegression(C=1e5, solver = 'lbfgs', multi_class = 'multinomial') ``` Với Logistic Regression, `multi_class = 'ovr'` là giá trị mặc định, tương ứng với **one-vs-rest**. `solver = 'lbfgs'` là một phương pháp tối ưu cũng dựa trên gradient nhưng hiệu quả hơn và phức tạp hơn Gradient Descent. Bạn đọc có thể [đọc thêm ở đây](https://en.wikipedia.org/wiki/Limited-memory_BFGS). ```",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-27",
        "source": "34.main.md",
        "section": "%reset",
        "content": "import numpy as np from mnist import MNIST import matplotlib.pyplot as plt from sklearn import linear_model from sklearn.metrics import accuracy_score mntrain = MNIST('../MNIST/') mntrain.load_training() Xtrain = np.asarray(mntrain.train_images)/255.0 ytrain = np.array(mntrain.train_labels.tolist()) mntest = MNIST('../MNIST/') mntest.load_testing() Xtest = np.asarray(mntest.test_images)/255.0 ytest = np.array(mntest.test_labels.tolist())",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-28",
        "source": "34.main.md",
        "section": "train",
        "content": "logreg = linear_model.LogisticRegression(C=1e5, solver = 'lbfgs', multi_class = 'multinomial') logreg.fit(Xtrain, ytrain)",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-29",
        "source": "34.main.md",
        "section": "test",
        "content": "y_pred = logreg.predict(Xtest) print \"Accuracy: %.2f %%\" %(100*accuracy_score(ytest, y_pred.tolist())) ``` ``` Accuracy: 92.59 % ``` So với kết quả hơn 91% của one-vs-rest Logistic Regression thì Softmax Regression đã cải thiện được một chút. Kết quả thấp như thế này là có thể dự đoán được vì thực ra Softmax Regression vẫn chỉ tạo ra các đường biên là các đường tuyến tính (phẳng).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-30",
        "source": "34.main.md",
        "section": "6.1 Boundary tạo bởi Softmax Regression là linear",
        "content": "Thật vậy, dựa vào hàm softmax thì một điểm dữ liệu \\(\\mathbf{x}\\) được dự đoán là rơi vào class \\(j\\) nếu \\(a\\_{j} \\geq a\\_{k}, ~\\forall k \\neq j\\). Bạn đọc có thể chứng minh được rằng \\(a\\_{j} \\geq a\\_{k} \\Leftrightarrow z\\_{j} \\geq z\\_{k}\\), hay nói cách khác: \\[ \\mathbf{w}\\_j^T \\mathbf{x} \\geq \\mathbf{w}\\_k^T\\mathbf{x} \\ \\Leftrightarrow (\\mathbf{w}\\_j - \\mathbf{w}\\_k)^T\\mathbf{x} \\geq 0 \\] Đây chính là một biểu thức tuyến tính. Vậy boundary tạo bởi Softmax Regression có dạng tuyến tính. (Xem thêm [boundary tạo bởi Logistic Regression](/2017/01/27/logisticregression/#boundary-tao-boi-logistic-regression-co-dang-tuyen-tinh))",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-31",
        "source": "34.main.md",
        "section": "6.2. Softmax Regression là một trong hai classifiers phổ biến nhất",
        "content": "Softmax Regression cùng với Support Vector Machine (tôi sẽ trình bày sau vài bài nữa) là hai classifier phổ biến nhất được dùng hiện nay. Softmax Regression đặc biệt được sử dụng nhiều trong các mạng Neural có nhiều lớp (Deep Neural Networks hay DNN). Những lớp phía trước có thể được coi như một bộ [Feature Extractor](/general/2017/02/06/featureengineering/#feature-extractor), lớp cuối cùng của DNN cho bài toán classification thường là Softmax Regression.",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-32",
        "source": "34.main.md",
        "section": "6.3. Source code",
        "content": "Các bạn có thể tìm thấy source code trong [jupyter notebook này](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/13_softmax/Softmax%20Regression.ipynb).",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "34.main-33",
        "source": "34.main.md",
        "section": "Tài liệu tham khảo",
        "content": "[1] [Softmax Regression](http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/) [2] [sklearn.linear\\_model.LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) [3] [Softmax function - Wikipedia](https://en.wikipedia.org/wiki/Softmax_function) [4] [Improving the way neural networks learn](http://neuralnetworksanddeeplearning.com/chap3.html)",
        "url": "https://machinelearningcoban.com/2017/02/17/softmax/"
    },
    {
        "id": "24.main-1",
        "source": "24.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * 1. Giới thiệu + 1.1. Hiện tượng *Long Tail* trong thương mại + 1.2. Hai nhóm chính của Recommendation Systems * 1. Utility matrix + 2.1. Ví dụ về Utility matrix + 2.2. Xây dựng Utility Matrix * 1. Content-Based Recommendations + 3.1. Item profiles + 3.2. Xây dựng hàm mất mát + 3.3. Ví dụ về hàm mất mát cho user E * 1. Bài toán với cơ sở dữ liệu MovieLens 100k + 4.1. Cơ sở dữ liệu MovieLens 100k + 4.2. Xây dựng item profiles + 4.3. Tìm mô hình cho mỗi user + 4.4. Đánh giá mô hình * 1. Thảo luận * 1. Tài liệu tham khảo",
        "url": "https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/"
    },
    {
        "id": "24.main-2",
        "source": "24.main.md",
        "section": "1. Giới thiệu",
        "content": "Các bạn có lẽ đã gặp những hiện tượng này nhiều lần: * Youtube tự động chuyển các clip liên quan đến clip bạn đang xem. Youtube cũng tự gợi ý những clip mà có thể bạn sẽ thích. * Khi bạn mua một món hàng trên Amazon, hệ thống sẽ tự động gợi ý “Frequently bought together”, hoặc nó biết bạn có thể thích món hàng nào dựa trên lịch sử mua hàng của bạn. * Facebook hiển thị quảng cáo những sản phẩm có liên quan đến từ khoá bạn vừa tìm kiếm. * Facebook gợi ý kết bạn. * Netflix tự động gợi ý phim cho người dùng. Và rất nhiều ví dụ khác mà hệ thống có khả năng tự động gợi ý cho ngừời dùng những sản phẩm họ *có thể thích*. Bằng cách *quảng cáo hướng đúng đội tượng* như thế này, hiệu quả của việc marketing cũng sẽ tăng lên. Những thuật toán đằng sau những ứng dụng này là những thuật toán Machine Learning có tên gọi chung là *Recommender Systems* hoặc *Recommendation Systems*, tức *Hệ thống gợi ý*. Recommendation Systems là một mảng khá rộng của Machine Learning và có *tuổi đời* ít hơn so với Classification vì internet mới chỉ thực sự bùng nổ khoảng 10-15 năm đổ lại đây. Có hai thực thể chính trong Recommendation Systems là *users* và *items*. *Users* là người dùng. *Items* là sản phẩm, ví dụ như các bộ phim, bài hát, cuốn sách, clip, hoặc cũng có thể là các *users* khác trong bài toán gợi ý kết bạn. Mục đích chính của các Recommender Systems là dự đoán *mức độ quan tâm* của một *user* tới một *item* nào đó, qua đó có chiến lược *recommend* phù hợp.",
        "url": "https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/"
    },
    {
        "id": "24.main-3",
        "source": "24.main.md",
        "section": "1.1. Hiện tượng *Long Tail* trong thương mại",
        "content": "Chúng ta cùng đi vào việc so sánh điểm khác nhau căn bản giữa các *cửa hàng thực* và *cửa hàng điện tử*, xét trên khía cạnh lựa chọn sản phẩm để quảng bá. Có thể các bạn đã biết tới [Nguyên lý Pareto (hay quy tắc 20/80)](https://en.wikipedia.org/wiki/Pareto_principle): *phần lớn kết quả được gây ra bởi phẩn nhỏ nguyên nhân*. Phần lớn số từ sử dụng hàng ngày chỉ là một phần nhỏ số từ trong bộ từ điển. Phần lớn của cải được sở hữu bởi phần nhỏ số người. Khi làm thương mại cũng vậy, những sản phẩm bán chạy nhất chỉ chiếm phần nhỏ tổng số sản phẩm. Các *cửa hàng thực* thường có hai khu vực, một là khu trưng bày, hai là kho. Nguyên tắc dễ thấy để đạt doanh thu cao là trưng ra các sản phẩm phổ biến nhất ở những nơi dễ nhìn thấy và những sản phẩm ít phổ biến hơn được cất trong kho. Cách làm này có một hạn chế rõ rệt: những sản phẩm được trưng ra mang tính phổ biến chứ chưa chắc đã phù hợp với một khách hàng cụ thể. Một cửa hàng có thể có món hàng một khách hàng tìm kiếm nhưng có thể không bán được vì khách hàng không nhìn thấy sản phẩm đó trên giá; việc này dẫn đến việc khách hàng không tiếp cận được sản phẩm ngay cả khi chúng đã được trưng ra. Ngoài ra, vì không gian có hạn, cửa hàng không thể trưng ra tất cả các sản phẩm mà mỗi loại chỉ đưa ra một số lượng nhỏ. Ở đây, phần lớn doanh thu (80%) đến từ phần nhỏ số sản phẩm phổ biến nhất (20%). Nếu sắp xếp các sản phẩm của cửa hàng theo doanh số từ cao đến thấp, ta sẽ nhận thấy có thể phần nhỏ các sản phẩm tạo ra phần lớn doanh số; và một danh sách dài phía sau chỉ tạo ra một lượng nhỏ đóng góp. Hiện tượng này còn được gọi là *long tail phenomenon*, tức phần *đuôi dài* của những sản phẩm ít phổ biến. Với các *cửa hàng online*, nhược điểm trên hoàn toàn có thể tránh được. Vì *gian trưng bày* của các *cửa hàng online* gần như là vô tận, mọi sản phẩm đều có thể được trưng ra. Hơn nữa, việc sắp xếp online là linh hoạt, tiện lợi với chi phí chuyển đổi gần như bằng 0 khiến việc mang đúng sản phẩm tới khách hàng trở nên thuận tiện hơn. Doanh thu, vì thế có thể được tăng lên. (*Ở đây, chúng ta tạm quên đi khía cạnh **có cảm giác thật chạm vào sản phẩm** của các cửa hàng thực. Hãy cùng tập trung vào phần làm thế nào để quảng bá đúng sản phẩm tới đúng khách hàng*)",
        "url": "https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/"
    },
    {
        "id": "24.main-4",
        "source": "24.main.md",
        "section": "1.2. Hai nhóm chính của Recommendation Systems",
        "content": "Các Recommendation Systems thường được chia thành hai nhóm lớn: 1. *Content-based systems*: đánh giá đặc tính của *items* được *recommended*. Ví dụ: một *user* xem rất nhiều các bộ phim về cảnh sát hình sự, vậy thì gơi ý một bộ phim trong cơ sở dữ liệu có chung đặc tính *hình sự* tới *user* này, ví dụ phim *Người phán xử*. Cách tiếp cận này yêu cầu việc sắp xếp các *items* vào từng nhóm hoặc đi tìm các đặc trưng của từng *item*. Tuy nhiên, có những *items* không có nhóm cụ thể và việc xác định nhóm hoặc đặc trưng của từng *item* đôi khi là bất khả thi. 2. *Collaborative filtering*: hệ thống gợi ý *items* dựa trên sự tương quan (similarity) giữa các *users* và/hoặc *items*. Có thể hiểu rằng ở nhóm này một *item* được *recommended* tới một *user* dựa trên những *users* có *hành vi* tương tự. Ví dụ: *users A, B, C* đều thích các bài hát của Noo Phước Thịnh. Ngoài ra, hệ thống biết rằng *users B, C* cũng thích các bài hát của Bích Phương nhưng chưa có thông tin về việc liệu *user A* có thích Bích Phương hay không. Dựa trên thông tin của những *users* tương tự là *B và C*, hệ thống có thể dự đoán rằng *A* cũng thích Bích Phương và gợi ý các bài hát của ca sĩ này tới *A*. Trong bài viết này, chúng ta sẽ làm quen với nhóm thứ nhất: *Content-based systems*. Tôi sẽ nói về *Collaborative filtering* trong bài viết tiếp theo.",
        "url": "https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/"
    },
    {
        "id": "24.main-5",
        "source": "24.main.md",
        "section": "2.1. Ví dụ về Utility matrix",
        "content": "Như đã đề cập, có hai thực thể chính trong các Recommendation Systems là *users* và *items*. Mỗi *user* sẽ có *mức độ quan tâm* (*degree of preference*) tới từng *item* khác nhau. Mức độ quan tâm này, *nếu đã biết trước*, được gán cho một giá trị ứng với mỗi cặp *user-item*. Giả sử rằng *mức độ quan tâm* được đo bằng giá trị *user* rate cho *item*, ta tạm gọi giá trị này là *rating*. Tập hợp tất cả các *ratings*, bao gồm cả những giá trị chưa biết cần được dự đoán, tạo nên một ma trận gọi là *utility matrix*. Xét ví dụ sau: --- |  |  | | --- | --- | |  | Hình 1: Ví dụ về utility matrix với hệ thống Gợi ý bài hát. Các bài hát được người dùng đánh giá theo mức độ từ 0 đến 5 sao. Các dấu '?' nền màu xám ứng với việc dữ liệu chưa tồn tại trong cơ sở dữ liệu. Recommendation Systems cần phải *tự điền* các giá trị này. | ---",
        "url": "https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/"
    },
    {
        "id": "8.main-1",
        "source": "8.main.md",
        "section": "Introduction",
        "content": "**Tất cả các bài tập trong bài viết này có thể được thực hiện trực tiếp trên trình duyện qua trang web [FundaML](https://fundaml.com)** Các số ngẫu nhiên đóng một vài trò cực kỳ quan trọng trong lập trình nói chung và lập trình Machine Learning nói riêng. Trong bài học này, chúng ta cùng làm quen với các hàm tạo các số ngẫu nhiên cơ bản.",
        "url": "https://machinelearningcoban.com/2017/10/20/fundaml_vectors/"
    },
    {
        "id": "8.main-2",
        "source": "8.main.md",
        "section": "3.1. Mảng ngẫu nhiên các số tuân theo phân bố đều",
        "content": "Một trong những điều quan trọng nhất khi lập trình một ngôn ngữ bất kỳ là cách sử dụng các hàm ngẫu nhiên. Trong bài này, chúng ta sẽ làm quen tới các hàm ngẫu nhiên trong Numpy và các cách sử dụng chúng trong các bài toán Machine Learning.",
        "url": "https://machinelearningcoban.com/2017/10/20/fundaml_vectors/"
    },
    {
        "id": "8.main-3",
        "source": "8.main.md",
        "section": "3.1.1. Hàm [`numpy.random.rand`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.rand.html)",
        "content": "Hàm `numpy.random.rand` trả về một mảng các số ngẫu nhiên mà mỗi phần tử là một số ngẫu nhiên có *phân bố đều* (*uniform distribution*) trong nửa đoạn `[0, 1)`: ``` >>> import numpy as np >>> np.random.rand() 0.38919680466308004 >>> np.random.rand(3) array([ 0.48677611,  0.70819795,  0.32393605]) >>> np.random.rand(3, 2) array([[ 0.29713565,  0.57377171], [ 0.0365262 ,  0.04146013], [ 0.63039945,  0.8643891 ]]) ``` * Nếu số lượng input là 0, hàm trả về một số vô hướng. * Nếu có inputs (là các số nguyên dương), hàm này trả về một mảng ngẫu nhiên có số chiều bằng với số inputs, kích thước mỗi chiều bằng với giá trị của các inputs.",
        "url": "https://machinelearningcoban.com/2017/10/20/fundaml_vectors/"
    },
    {
        "id": "8.main-4",
        "source": "8.main.md",
        "section": "3.1.2. Hàm [`np.random.seed`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.seed.html)",
        "content": "Các ngôn ngữ lập trình nói chung không tạo ra các giá trị ‘thực sự ngẫu nhiên’. Thật vậy, nếu bạn mở python và bắt đầu với: ``` >>> import numpy as np >>> np.random.rand() ``` thì kết quả luôn là các số giống nhau ở mỗi lần thử (bạn hãy thoát python và thử lại nhiều lần xem). Như trên máy tính của tôi, kết quả lúc nào cũng là `0.38919680466308004`. *Như vậy, hàm ngẫu nhiên không thực sự sinh ra các giá trị ngẫu nhiên.* Tuy nhiên, nếu thực hiện hàm này rất nhiều lần, chúng ta sẽ thu được các các số nằm trong khoảng `[0, 1)` mà xác suất để một điểm nằm trong đoạn `[a, b]` với `0 <= a < b < 1` bằng `b - a`. Hàm `np.random.seed()` là một hàm được coi như giúp khởi tạo các bộ sinh số ngẫu nhiên (random generator). Biến số trong seed thường là một số nguyên không âm 32 bit. Với các giá trị của biến số khác nhau thì sẽ cho ra các số ngẫu nhiên khác nhau. Hàm số này được dùng để đối chiều kết quả trong các lần chạy khác nhau trong các bài toán Machine Learning. Rất nhiều các thuật toán Machine Learning chạy dựa trên việc tính toán ngẫu nhiên (ví dụ, [Stochastic Gradient Descent](https://machinelearningcoban.com/2017/01/16/gradientdescent2/#-stochastic-gradient-descent) được sử dụng rất nhiều trong các thuật toán tối ưu Neural Networks). Để đối chiếu kết quả trong nhiều lần chạy trên, người ta thường khởi tạo các random generator với các `seed` như nhau. Các bạn có thể để ý thấy rằng trong các bài trước tôi thường dùng `np.random.seed()`. Việc đó để đảm bảo rằng kết quả bạn tìm được giống với kết quả trong code mẫu. --- **Bài tập:** Cho các số `a, b, m, n` trong đó `a < b` là hai số thực bất kỳ; `m`, `n` là các số nguyên dương. Viết hàm số tạo một mảng hai chiều có `shape = (m, n)`, các phần tử là các số ngẫu nhiên phân bố đều trong nửa đoạn `[a, b)`. **Chú ý:** 1. Để kiểm tra mảng trả về có đúng là mảng ngẫu nhiên các phần tử trong nửa đoạn \\([a, b)\\) hay không, tôi sẽ tính kỳ vọng (mean) và phương sai (variance) của các phần tử trong mảng đó. Tôi biết rằng nếu \\(X\\) là một biến ngẫu nhiên tuân theo phân phối chuẩn trong nửa đoạn \\([a, b)\\) thì nó sẽ có kỳ vọng và phương sai lần lượt là: \\[ \\frac{b+a}{2}; \\quad \\frac{(b-a)^2}{12} \\] **Lưu ý rằng đây chỉ là điều kiện cần, không phải điều kiện đủ.** 1. Nếu `X` là một biến ngẫu nhiên tuân theo phân phối chuẩn trong nửa đoạn `[0, 1)` thì `Y = aX + b` là một biến ngẫu nhiên tuân theo phân phối chuẩn trong nửa đoạn `[b, a + b)` nếu `a` là một số dương, hoặc `[a+b, b)` nếu `a` là một số âm. ---",
        "url": "https://machinelearningcoban.com/2017/10/20/fundaml_vectors/"
    },
    {
        "id": "12.main-1",
        "source": "12.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * 1. Naive Bayes Classifier * 1. Các phân phối thường dùng cho \\(p(x\\_i | c)\\) + 2.1 Gaussian Naive Bayes + 2.2. Multinomial Naive Bayes + 2.3. Bernoulli Naive Bayes * 1. Ví dụ + 3.1. Bắc hay Nam + 3.2. Bắc hay Nam với sklearn + 3.3. Naive Bayes Classifier cho bài toán Spam Filtering * 1. Tóm tắt * 1. Tài liệu tham khảo *Bạn được khuyến khích đọc [Bài 31: Maximum Likelihood và Maximum A Posteriori estimation](/2017/07/17/mlemap/) trước khi đọc bài này*",
        "url": "https://machinelearningcoban.com/2017/08/08/nbc/"
    },
    {
        "id": "12.main-2",
        "source": "12.main.md",
        "section": "1. Naive Bayes Classifier",
        "content": "Xét bài toán classification với \\(C\\) classes \\(1, 2, \\dots, C\\). Giả sử có một điểm dữ liệu \\(\\mathbf{x} \\in \\mathbb{R}^d\\). Hãy tính xác suất để điểm dữ liệu này rơi vào class \\(c\\). Nói cách khác, hãy tính: \\[ p(y = c |\\mathbf{x}) ~~~ (1) \\] hoặc viết gọn thành \\(p(c|\\mathbf{x})\\). Tức tính xác suất để đầu ra là class \\(c\\) biết rằng đầu vào là vector \\(\\mathbf{x}\\). Biểu thức này, nếu tính được, sẽ giúp chúng ta xác định được xác suất để điểm dữ liệu rơi vào mỗi class. Từ đó có thể giúp xác định class của điểm dữ liệu đó bằng cách chọn ra class có xác suất cao nhất: \\[ c = \\arg\\max\\_{c \\in \\{1, \\dots, C\\}} p(c | \\mathbf{x}) ~~~~ (2) \\] Biểu thức \\((2)\\) thường khó được tính trực tiếp. Thay vào đó, quy tắc Bayes thường được sử dụng: \\[ \\begin{eqnarray} c & = & \\arg\\max\\_c p(c | \\mathbf{x}) & (3) \\ & = & \\arg\\max\\_c \\frac{p(\\mathbf{x} | c) p(c)}{p(\\mathbf{x})} ~~~& 4)\\ & = & \\arg\\max\\_c p(\\mathbf{x} | c) p(c) & (5)\\ \\end{eqnarray} \\] Từ \\((3)\\) sang \\((4)\\) là vì quy tắc Bayes. Từ \\((4)\\) sang \\((5)\\) là vì mẫu số \\(p(\\mathbf{x})\\) không phụ thuộc vào \\(c\\). Tiếp tục xét biểu thức \\((5)\\), \\(p(c)\\) có thể được hiểu là xác suất để một điểm rơi vào class \\(c\\). Giá trị này có thể được tính bằng [MLE](/2017/07/17/mlemap/#-maximum-likelihood-estimation), tức tỉ lệ số điểm dữ liệu trong tập training rơi vào class này chia cho tổng số lượng dữ liệu trong tập training; hoặc cũng có thể được đánh giá bằng [MAP estimation](/2017/07/17/mlemap/#-maximum-a-posteriori). Trường hợp thứ nhất thường được sử dụng nhiều hơn. Thành phần còn lại \\(p(\\mathbf{x} | c)\\), tức phân phối của các điểm dữ liệu trong class \\(c\\), thường rất khó tính toán vì \\(\\mathbf{x}\\) là một biến ngẫu nhiên nhiều chiều, cần rất rất nhiều dữ liệu training để có thể xây dựng được phân phối đó. Để giúp cho việc tính toán được đơn giản, người ta thường giả sử một cách đơn giản nhất rằng các thành phần của biến ngẫu nhiên \\(\\mathbf{x}\\) là [độc lập với nhau](/2017/07/09/prob/#-independence), nếu biết \\(c\\) (given \\(c\\)). Tức là: \\[ p(\\mathbf{x} | c) = p(x\\_1, x\\_2, \\dots, x\\_d | c) = \\prod\\_{i = 1}^d p(x\\_i | c) ~~~~~ (6) \\] Giả thiết các chiều của dữ liệu độc lập với nhau, nếu biết \\(c\\), là quá chặt và ít khi tìm được dữ liệu mà các thành phần hoàn toàn độc lập với nhau. Tuy nhiên, giả thiết *ngây ngô* này lại mang lại những kết quả tốt bất ngờ. Giả thiết về sự độc lập của các chiều dữ liệu này được gọi là *Naive Bayes* (xin không dịch). Cách xác định class của dữ liệu dựa trên giả thiết này có tên là *Naive Bayes Classifier (NBC)*. NBC, nhờ vào tính đơn giản một cách *ngây thơ*, có tốc độ training và test rất nhanh. Việc này giúp nó mang lại hiệu quả cao trong các bài toán large-scale. Ở bước **training**, các phân phối \\(p(c)\\) và \\(p(x\\_i | c), i = 1, \\dots, d\\) sẽ được xác định dựa vào training data. Việc xác định các giá trị này có thể dựa vào [Maximum Likelihood Estimation hoặc Maximum A Posteriori](/2017/07/17/mlemap/). Ở bước **test**, với một điểm dữ liệu mới \\(\\mathbf{x}\\), class của nó sẽ được xác đinh bởi: \\[ c = \\arg\\max\\_{c \\in \\{1, \\dots, C\\}} p(c) \\prod\\_{i=1}^d p(x\\_i | c) ~~~~~ (7) \\] Khi \\(d\\) lớn và các xác suất nhỏ, biểu thức ở vế phải của \\((7)\\) sẽ là một số rất nhỏ, khi tính toán có thể gặp sai số. Để giải quyết việc này, \\((7)\\) thường được viết lại dưới dạng tương đương bằng cách lấy \\(\\log\\) của vế phải: \\[ c = \\arg\\max\\_{c \\in \\{1, \\dots, C\\}} = \\log(p(c)) + \\sum\\_{i=1}^d \\log(p(x\\_i | c)) ~~~~ (7.1) \\] Việc này không ảnh hưởng tới kết quả vì \\(\\log\\) là một hàm đồng biến trên tập các số dương. Mặc dù giả thiết mà Naive Bayes Classifiers sử dụng là quá phi thực tế, chúng vẫn hoạt động khá hiệu quả trong nhiều bài toán thực tế, đặc biệt là trong các bài toán phân loại văn bản, ví dụ như lọc tin nhắn rác hay lọc email spam. Trong phần sau của bài viết, chúng ta cùng xây dựng một bộ lọc email spam tiếng Anh đơn giản. Cả việc training và test của NBC là cực kỳ nhanh khi so với các phương pháp classification phức tạp khác. Việc giả sử các thành phần trong dữ liệu là độc lập với nhau, nếu biết class, khiến cho việc tính toán mỗi phân phối \\(p(\\mathbf{x}\\_i|c)\\) trở nên cực kỳ nhanh. Mỗi giá trị \\(p(c), c = 1, 2, \\dots, C\\) có thể được xác định như là tần suất xuất hiện của class \\(c\\) trong training data. Việc tính toán \\(p(\\mathbf{x\\_i} | c) \\) phụ thuộc vào loại dữ liệu. [Có ba loại được sử dụng phổ biến](http://scikit-learn.org/dev/modules/classes.html#module-sklearn.naive_bayes) là: Gaussian Naive Bayes, Multinomial Naive Bayes, và Bernoulli Naive .",
        "url": "https://machinelearningcoban.com/2017/08/08/nbc/"
    },
    {
        "id": "12.main-3",
        "source": "12.main.md",
        "section": "2. Các phân phối thường dùng cho \\(p(x\\_i | c)\\)",
        "content": "*Mục này chủ yếu được dịch từ [tài liệu của thư viện sklearn](http://scikit-learn.org/dev/modules/naive_bayes.html#naive-bayes).*",
        "url": "https://machinelearningcoban.com/2017/08/08/nbc/"
    },
    {
        "id": "12.main-4",
        "source": "12.main.md",
        "section": "2.1 Gaussian Naive Bayes",
        "content": "Mô hình này được sử dụng chủ yếu trong loại dữ liệu mà các thành phần là các biến liên tục. Với mỗi chiều dữ liệu \\(i\\) và một class \\(c\\), \\(x\\_i\\) tuân theo một phân phối chuẩn có kỳ vọng \\(\\mu\\_{ci}\\) và phương sai \\(\\sigma\\_{ci}^2\\): \\[ p(x\\_i|c) = p(x\\_i | \\mu\\_{ci}, \\sigma\\_{ci}^2) = \\frac{1}{\\sqrt{2\\pi \\sigma\\_{ci}^2}} \\exp\\left(- \\frac{(x\\_i - \\mu\\_{ci})^2}{2 \\sigma\\_{ci}^2}\\right) ~~~~ (8) \\] Trong đó, bộ tham số \\(\\theta = \\{\\mu\\_{ci}, \\sigma\\_{ci}^2\\}\\) được xác định bằng Maximum Likelihood: \\[ (\\mu\\_{ci}, \\sigma\\_{ci}^2) = \\arg\\max\\_{\\mu\\_{ci}, \\sigma\\_{ci}^2} \\prod\\_{n = 1}^N p(x\\_i^{(n)} | \\mu\\_{ci}, \\sigma\\_{ci}^2) ~~~~ (9) \\] *Đây là cách tính của thư viện sklearn. Chúng ta cũng có thể đánh giá các tham số bằng MAP nếu biết trước priors của \\(\\mu\\_{ci}\\) và \\(\\sigma^2\\_{ci}\\)*",
        "url": "https://machinelearningcoban.com/2017/08/08/nbc/"
    },
    {
        "id": "12.main-5",
        "source": "12.main.md",
        "section": "2.2. Multinomial Naive Bayes",
        "content": "Mô hình này chủ yếu được sử dụng trong phân loại văn bản mà feature vectors được tính bằng [Bags of Words](https://machinelearningcoban.com/general/2017/02/06/featureengineering/#bag-of-words). Lúc này, mỗi văn bản được biểu diễn bởi một vector có độ dài \\(d\\) chính là số từ trong từ điển. Giá trị của thành phần thứ \\(i\\) trong mỗi vector chính là số lần từ thứ \\(i\\) xuất hiện trong văn bản đó. Khi đó, \\(p(x\\_i |c) \\) tỉ lệ với tần suất từ thứ \\(i\\) (hay feature thứ \\(i\\) cho trường hợp tổng quát) xuất hiện trong các văn bản của class \\(c\\). Giá trị này có thể được tính bằng cách: \\[ \\lambda\\_{ci} = p(x\\_i | c) = \\frac{N\\_{ci}}{N\\_c} ~~~~ (10) \\] Trong đó: * \\(N\\_{ci}\\) là tổng số lần từ thứ \\(i\\) xuất hiện trong các văn bản của class \\(c\\), nó được tính là tổng của tất cả các thành phần thứ \\(i\\) của các feature vectors ứng với class \\(c\\). * \\(N\\_c\\) là tổng số từ (kể cả lặp) xuất hiện trong class \\(c\\). Nói cách khác, nó bằng tổng độ dài của toàn bộ các văn bản thuộc vào class \\(c\\). Có thể suy ra rằng \\(N\\_c = \\sum\\_{i = 1}^d N\\_{ci}\\), từ đó \\(\\sum\\_{i=1}^d \\lambda\\_{ci} = 1\\). Cách tính này có một hạn chế là nếu có một từ mới chưa bao giờ xuất hiện trong class \\(c\\) thì biểu thức \\((10)\\) sẽ bằng 0, điều này dẫn đến vế phải của \\((7)\\) bằng 0 bất kể các giá trị còn lại có lớn thế nào. Việc này sẽ dẫn đến kết quả không chính xác (xem thêm ví dụ ở mục sau). Để giải quyết việc này, một kỹ thuật được gọi là *Laplace smoothing* được áp dụng: \\[ \\hat{\\lambda}\\_{ci} = \\frac{N\\_{ci} + \\alpha}{N\\_{c} + d\\alpha} ~~~~~~ (11) \\] Với \\(\\alpha\\) là một số dương, thường bằng 1, để tránh trường hợp tử số bằng 0. Mẫu số được cộng với \\(d\\alpha\\) để đảm bảo tổng xác suất \\(\\sum\\_{i=1}^d \\hat{\\lambda}\\_{ci} = 1\\). Như vậy, mỗi class \\(c\\) sẽ được mô tả bởi bộ các số dương có tổng bằng 1: \\(\\hat{\\lambda}\\_c = \\{\\hat{\\lambda}\\_{c1}, \\dots, \\hat{\\lambda}\\_{cd}\\}\\).",
        "url": "https://machinelearningcoban.com/2017/08/08/nbc/"
    },
    {
        "id": "12.main-6",
        "source": "12.main.md",
        "section": "2.3. Bernoulli Naive Bayes",
        "content": "Mô hình này được áp dụng cho các loại dữ liệu mà mỗi thành phần là một giá trị binary - bẳng 0 hoặc 1. Ví dụ: cũng với loại văn bản nhưng thay vì đếm tổng số lần xuất hiện của 1 từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không. Khi đó, \\(p(x\\_i | c) \\) được tính bằng: \\[ p(x\\_i | c) = p(i | c)^{x\\_i} (1 - p(i | c) ^{1 - x\\_i} \\] với \\(p(i | c)\\) có thể được hiểu là xác suất từ thứ \\(i\\) xuất hiện trong các văn bản của class \\(c\\).",
        "url": "https://machinelearningcoban.com/2017/08/08/nbc/"
    },
    {
        "id": "12.main-7",
        "source": "12.main.md",
        "section": "3.1. Bắc hay Nam",
        "content": "Giả sử trong tập training có các văn bản \\(\\text{d1, d2, d3, d4}\\) như trong bảng dưới đây. Mỗi văn bản này thuộc vào 1 trong 2 classes: \\(\\text{B}\\) (*Bắc*) hoặc \\(\\text{N}\\) (*Nam*). Hãy xác định class của văn bản \\(\\text{d5}\\). |  | Document | Content | Class | | --- | --- | --- | --- | | **Training** | \\(\\text{d1}\\) | \\(\\text{hanoi pho chaolong hanoi}\\) | \\(\\text{B}\\) | |  | \\(\\text{d2}\\) | \\(\\text{hanoi buncha pho omai}\\) | \\(\\text{B}\\) | |  | \\(\\text{d3}\\) | \\(\\text{pho banhgio omai}\\) | \\(\\text{B}\\) | |  | \\(\\text{d4}\\) | \\(\\text{saigon hutiu banhbo pho}\\) | \\(\\text{N}\\) | | **Test** | \\(\\text{d5}\\) | \\(\\text{hanoi hanoi buncha hutiu}\\) | ? | Ta có thể dự đoán rằng \\(\\text{d5}\\) thuộc class *Bắc*. Bài toán này có thể được giải quyết bởi hai mô hình: Multinomial Naive Bayes và Bernoulli Naive Bayes. Tôi sẽ làm ví dụ minh hoạ với mô hình thứ nhất và thực hiện code cho cả hai mô hình. Việc mô hình nào tốt hơn phụ thuộc vào mỗi bài toán. Chúng ta có thể thử cả hai để chọn ra mô hình tốt hơn. Nhận thấy rằng ở đây có 2 class \\(\\text{B}\\) và \\(\\text{N}\\), ta cần đi tìm \\(p(\\text{B})\\) và \\(p(\\text{N})\\). à dựa trên tần số xuất hiện của mỗi class trong tập training. Ta sẽ có: \\[ p(\\text{B}) = \\frac{3}{4}, ~~~~~ p(\\text{N}) = \\frac{1}{4} ~~~~~~ (8) \\] Tập hợp toàn bộ các từ trong văn bản, hay còn gọi là từ điển, là: \\(V = \\{\\text{hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\\}\\). Tổng cộng số phần tử trong từ điển là \\(|V| = 9\\). Hình dưới đây minh hoạ quá trình Training và Test cho bài toán này khi sử dụng Multinomial Naive Bayes, trong đó có sử dụng Laplace smoothing với \\(\\alpha = 1\\). --- ![](/assets/32_nbc/nbc.png) Hình 1: Minh hoạ Multinomial Naive Bayes. ---",
        "url": "https://machinelearningcoban.com/2017/08/08/nbc/"
    },
    {
        "id": "1.main-1",
        "source": "1.main.md",
        "section": "Introduction",
        "content": "* [1. Tích chập một chiều](#-tich-chap-mot-chieu) + [1.1. Định nghĩa](#-dinh-nghia) + [1.2. Thêm lề](#-them-le) + [1.3. Bước trượt](#-buoc-truot) * [2. Tích chập hai chiều](#-tich-chap-hai-chieu) + [2.1. Tín hiệu đơn kênh](#-tin-hieu-don-kenh) * [3. Tích chập hai chiều tổng quát](#-tich-chap-hai-chieu-tong-quat) * [4. Kết luận](#-ket-luan) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao) Tích chập đóng một vai trò quan trọng và xuất hiện từ sớm trong lịch sử xử lý tín hiệu số. Việc tìm ra các bộ lọc phù hợp cho mỗi loại tín hiệu và mỗi bài toán đã được nghiên cứu và giảng dạy rất nhiều trong các giáo trình kỹ thuật. Cuối những năm 1980s, Yann Lecunn đề xuất một mô hình tích chập hai chiều cho dữ liệu ảnh và thu lại thành công lớn trong bài toán phân loại chữ số viết tay. Bằng việc sử dụng rất nhiều dữ liệu và thay các *tầng nối kín* (fully connected layer) trong mạng perceptron đa tầng bởi tích chập hai chiều, các bộ lọc phù hợp với bài toán và dữ liệu có thể được *học* để mang lại kết quả phân lớp tốt nhất. Trong bài viết này, tôi sẽ trình bày cơ sở toán học của tích chập một chiều và tích chập hai chiều. Kiến trục mạng neuron tích chập sẽ được trình bày cụ thể trong bài tiếp theo.",
        "url": "https://machinelearningcoban.com/2018/10/03/conv2d"
    },
    {
        "id": "1.main-2",
        "source": "1.main.md",
        "section": "1.1. Định nghĩa",
        "content": "Xét tín hiệu một chiều `x_clean` có dạng hình sin như trong Hình 1a): ``` import numpy as np N = 200 x_clean = np.sin(np.arange(N)/20.) ``` --- ![](/assets/37_conv2d/python/conv1d.png) Hình 1: (a) Tín hiệu ban đầu. (b) Tín hiệu có nhiễu Gauss. (c) Tín hiệu sau khi khử nhiễu bằng tích chập với bộ lọc trung bình. ---",
        "url": "https://machinelearningcoban.com/2018/10/03/conv2d"
    },
    {
        "id": "26.main-1",
        "source": "26.main.md",
        "section": "Introduction",
        "content": "* [1. Giới thiệu](#-gioi-thieu) * [2. Cơ sở toán học](#-co-so-toan-hoc) * [3. Hàm số kernel](#-ham-so-kernel) + [3.1. Tính chất của các hàm kerrnel](#-tinh-chat-cua-cac-ham-kerrnel) + [3.2. Một số hàm kernel thông dụng](#-mot-so-ham-kernel-thong-dung) - [3.2.1. Linear](#-linear) - [3.2.2. Polynomial](#-polynomial) - [3.2.3. Radial Basic Function](#-radial-basic-function) - [3.2.4. Sigmoid](#-sigmoid) - [3.2.5. Bảng tóm tắt các kernel thông dụng](#-bang-tom-tat-cac-kernel-thong-dung) - [3.2.6. Kernel tự định nghĩa](#-kernel-tu-dinh-nghia) * [4. Ví dụ minh họa](#-vi-du-minh-hoa) + [4.1. Bài toán XOR](#-bai-toan-xor) + [4.2. Dữ liệu gần linearly separable](#-du-lieu-gan-linearly-separable) + [4.3. Bài toán phân biệt giới tính](#-bai-toan-phan-biet-gioi-tinh) * [5. Tóm tắt](#-tom-tat) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao) *Bạn đọc được khuyến khích đọc [Bài 19](https://machinelearningcoban.com/2017/04/09/smv/) và [Bài 20](https://machinelearningcoban.com/2017/04/13/softmarginsmv/) trước khi đọc bài này.*",
        "url": "https://machinelearningcoban.com/2017/04/22/kernelsmv/"
    },
    {
        "id": "26.main-2",
        "source": "26.main.md",
        "section": "1. Giới thiệu",
        "content": "Có một sự tương ứng thú vị giữa hai nhóm thuật toán phân lớp phổ biến nhất: Neural Network và Support Vector Machine. Chúng đều bắt đầu từ bài toán phân lớp với 2 *linearly separable classes*, tiếp theo đến 2 *almost linear separable classes*, đến bài toán có nhiều classes rồi các bài toán với biên không tuyến tính. Sự tương ứng được cho trong bảng dưới đây: --- | Neural Networks | Support Vector Machine | Tính chất chung | | --- | --- | --- | | [PLA](https://machinelearningcoban.com/2017/01/21/perceptron/) | [Hard Margin SVM](https://machinelearningcoban.com/2017/04/09/smv/) | Hai classes là *linearly separable* | | [Logistic Regression](https://machinelearningcoban.com/2017/01/27/logisticregression/) | [Soft Margin SVM](https://machinelearningcoban.com/2017/04/13/softmarginsmv/) | Hai classes là *gần linearly separable* | | [Softmax Regression](https://machinelearningcoban.com/2017/02/17/softmax/) | Multi-class SVM | Bài toán phân loại nhiều classes (biên là tuyến tính) | | [Multi-layer Perceptron](https://machinelearningcoban.com/2017/02/24/mlp/) | Kernel SVM | Bài toán với dữ liệu không *linearly separable* | ---",
        "url": "https://machinelearningcoban.com/2017/04/22/kernelsmv/"
    },
    {
        "id": "36.main-1",
        "source": "36.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Mô hình chung cho các bài toán Machine Learning](#-mo-hinh-chung-cho-cac-bai-toan-machine-learning) + [TRAINING PHASE](#training-phase) - [Feature Extractor](#feature-extractor) - [Main Algorithms](#main-algorithms) + [TESTING PHASE](#testing-phase) * [3. Một số ví dụ về Feature Engineering](#-mot-so-vi-du-ve-feature-engineering) + [Trực tiếp lấy raw data](#truc-tiep-lay-raw-data) + [Feature selection](#feature-selection) + [Dimensionality reduction](#dimensionality-reduction) + [Bag-of-words](#bag-of-words) + [Bag-of-Words trong Computer Vision](#bag-of-words-trong-computer-vision) + [Feature Scaling and Normalization](#feature-scaling-and-normalization) - [Rescaling](#rescaling) - [Standardization](#standardization) - [Scaling to unit length](#scaling-to-unit-length) * [4. Thảo luận](#-thao-luan) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-2",
        "source": "36.main.md",
        "section": "1. Giới thiệu",
        "content": "Cho tới lúc này, tôi đã trình bày 5 thuật toán Machine Learning cơ bản: [Linear Regression](/2016/12/28/linearregression/), [K-means Clusterning](/2017/01/01/kmeans/), [K-nearest neighbors](/2017/01/08/knn/), [Perceptron Learning Algorithm](/2017/01/21/perceptron/) và [Logistic Regression](/2017/01/27/logisticregression/). Trong tất cả các thuật toán này, tôi đều giả sử các điểm dữ liệu được biểu diễn bằng các vector, được gọi là *feature vector* hay *vector đặc trưng*, có độ dài bằng nhau, và cùng là vector cột hoặc vector hàng. Tuy nhiên, trong các bài toán thực tế, mọi chuyện không được tốt đẹp như vậy! Với các bài toán về Computer Vision, các bức ảnh là các ma trận có kích thước khác nhau. Thậm chí để nhận dạng vật thể trong ảnh, ta cần thêm một bước nữa là *object detection*, tức là tìm cái khung chứa vật thể chúng ta cần dự đoán. Ví dụ, trong bài toán nhận dạng khuôn mặt, chúng ta cần tìm được vị trí các khuôn mặt trong ảnh và *crop* các khuôn mặt đó trước khi làm các bước tiếp theo. Ngay cả khi đã xác định được các khung chứa các khuôn mặt (và có thể resize các khung đó về cùng một kích thước), ta vẫn phải làm rất nhiều việc nữa vì hình ảnh của khuôn mặt còn phụ thưộc vào góc chụp, ánh sáng, … và rất nhiều yếu tố khác nữa. Các bài toán NLP (Natural Language Processing - Xử lý ngôn ngữ tự nhiên) cũng có khó khăn tương tự khi độ dài của các văn bản là khác nhau, thậm chí có những từ rất hiếm gặp hoặc không có trong từ điển. Cũng có khi thêm một vài từ vào văn bản mà nội dung của văn bản không đổi hoặc hoàn toàn mang nghĩa ngược lại. Hoặc cùng là một câu nói nhưng tốc độ, âm giọng của mỗi người là khác nhau, thậm chí của cùng một người nhưng lúc ốm lúc khỏe cũng khác nhau. Khi làm việc với các bài toán Machine Learning thực tế, nhìn chung chúng ta chỉ có được dữ liệu thô (raw) chưa qua chỉnh sửa, chọn lọc. Chúng ta cần phải tìm một phép biến đổi để loại ra những dữ liệu nhiễu (noise), và để đưa dữ liệu thô với số chiều khác nhau về cùng một chuẩn (cùng là các vector hoặc ma trận). Dữ liệu chuẩn mới này phải đảm bảo giữ được những thông tin đặc trưng (features) cho dữ liệu thô ban đầu. Không những thế, tùy vào từng bài toán, ta cần *thiết kế* những phép biến đổi để có những features phù hợp. Quá trình quan trọng này được gọi là *Feature Extraction*, hoặc *Feature Engineering*, một số tài liệu tiếng Việt gọi nó là *trích chọn đặc trưng*. Tôi xin trích một câu nói của thầy Andrew Ng và xin phép thêm không dịch ra tiếng Việt (Nguồn [Feature Engineering - wiki](https://en.wikipedia.org/wiki/Feature_engineering)): > Coming up with features is difficult, time-consuming, requires expert knowledge. “Applied machine learning” is basically feature engineering. Để giúp các bạn có cái nhìn tổng quan hơn, trong phần tiếp theo tôi xin đặt bước Feature Engineering này trong một bức tranh lớn hơn.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-3",
        "source": "36.main.md",
        "section": "2. Mô hình chung cho các bài toán Machine Learning",
        "content": "Phần lớn các bài toán Machine Learning có thể được thể hiện trong hình vẽ dưới đây: ![](\\assets\\FeatureEngineering\\ML_models.png) Hình 1: Mô hình chung cho các bài toán Machine Learning. Có hai phases lớn là Training phase và Testing phase. Xin nhắc lại là với các bài toán Supervised learning, ta có các cặp dữ liệu (*input, output*), với các bài toán Unsupervised learing, ta chỉ có *input* mà thôi.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-4",
        "source": "36.main.md",
        "section": "TRAINING PHASE",
        "content": "Có hai khối có nền màu xanh lục chúng ta cần phải thiết kế:",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-5",
        "source": "36.main.md",
        "section": "Feature Extractor",
        "content": "**ĐẦU RA** Tôi xin đề cập đầu ra của khối này trước vì mục đích của Feature Engineering là tạo ra một Feature Extractor biến dữ liệu thô ban đầu thành dữ liệu phù hợp với từng mục đích khác nhau. **ĐẦU VÀO** * ***raw training input***. Raw input là tất cả các thông tin ta biết về dữ liệu. Ví dụ: với ảnh thì là giá trị của từng pixel; với văn bản thì là từng từ, từng câu; với file âm thanh thì nó là một đoạn tín hiệu; với cơ sở dữ liệu [Iris](/2017/01/08/knn/#bo-co-so-du-lieu-iris-iris-flower-dataset) thì nó là độ dài các cánh hoa và đài hoa, … Dữ liệu thô này thường không ở dạng vector, không có số chiều như nhau. Thậm chí có thể có số chiều như nhau nhưng số chiều quá lớn, như một bức ảnh màu 1000 pixel x 1000 pixel thì số *elements* đã là \\(3 \\times 10^6\\) (3 vì ảnh màu thường có 3 channels: Red, Green, Blue). Đây là một con số quá lớn, không lợi cho lưu trữ và tính toán. * **(optional) *output* của *training set***. Trong các bài toán Unsupervised learning, ta không biết *output* nên hiển nhiên sẽ không có đầu vào này. Trong các bài toán Supervised learning, có khi dữ liệu này cũng không được sử dụng. Ví dụ: nếu *raw input* đã có cùng số chiều rồi nhưng số chiều quá lớn, ta muốn giảm số chiều của nó thì cách đơn giản nhất là *chiếu* vector đó xuống một không gian có số chiều nhỏ hơn bằng cách lấy một ma trận ngẫu nhiên nhân với nó. Ma trận này thường là ma trận *béo* (số hàng ít hơn số cột, tiếng Anh - fat matrices) để đảm bảo số chiều thu được nhỏ hơn số chiều ban đầu. Việc làm này mặc dù làm mất đi thông tin, trong nhiều trường hợp vẫn mang lại hiệu quả vì đã giảm được lượng tính toán ở phần sau. Đôi khi *ma trận chiếu* không phải là ngẫu nhiên mà có thể được *học* dựa trên toàn bộ *raw input*, ta sẽ có bài toán tìm ma trận chiếu để lượng thông tin mất đi là ít nhất. Trong nhiều trường hợp, dữ liệu *output* của *training set* cũng được sử dụng để tạo ra Feature Extractor. Ví dụ: trong bài toán classification, ta không quan tâm nhiều đến việc mất thông tin hay không, ta chỉ quan tâm đến việc những thông tin còn lại có đặc trưng cho từng class hay không. Ví dụ, dữ liệu thô là các hình vuông và hình tam giác có màu đỏ và xanh. Trong bài toán phân loại đa giác, các output là *tam giác* và *vuông*, thì ta không quan tâm tới màu sắc mà chỉ quan tâm tới số cạnh của đa giác. Ngược lại, trong bài toán phân loại màu, các class là *xanh* và *đỏ*, ta không quan tâm tới số cạnh mà chỉ quan tâm đến màu sắc thôi. * **(optional) *Prior knowledge about data***: Đôi khi những giả thiết khác về dữ liệu cũng mang lại lợi ích. Ví dụ, trong bài toán classification, nếu ta biết dữ liệu là (gần như)  [*linearly separable*](/2017/01/21/perceptron/#bai-toan-perceptron) thì ta sẽ đi tìm một ma trận chiếu sao cho ở trong không gian mới, dữ liệu vẫn đảm bảo tính *linearly separable*, việc này thuận tiện hơn cho phần classification vì các thuật toán linear, nhìn chung, đơn giản hơn. Sau khi *học* được feature extractor thì ta cũng sẽ thu được *extracted features* cho *raw input data*. Những *extracted features* này được dùng để huấn luyện các thuật toán Classification, Clustering, Regression,… ở phía sau.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-6",
        "source": "36.main.md",
        "section": "Main Algorithms",
        "content": "Khi có được *extracted features* rồi, chúng ta sử dụng những thông tin này cùng với (optional) *training output* và (optional) *prior knowledge* để tạo ra các mô hình phù hợp, điều mà chúng ta đã làm ở những bài trước. **Chú ý:** Trong một số thuật toán cao cấp hơn, việc *huấn luyện* feature extractor và main algorithm được thực hiện cùng lúc với nhau chứ không phải từng bước như trên. **Một điểm rất quan trọng: khi xây dựng bộ *feature extractor* và *main algorithms*, chúng ta không được sử dụng bất kỳ thông tin nào trong tập *test data*. Ta phải giả sử rằng những thông tin trong *test data* chưa được nhìn thấy bao giờ. Nếu sử dụng thêm thông tin về *test data* thì rõ ràng ta đã *ăn gian*! Tôi từng đánh giá các bài báo khoa học quốc tế, rất nhiều tác giả xây dựng mô hình dùng cả dữ liệu *test data*, sau đó lại dùng chính mô hình đó để kiểm tra trên *test data* đó. Việc *ăn gian* này là lỗi rất nặng và hiển nhiên những bài báo đó bị từ chối (reject).**",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-7",
        "source": "36.main.md",
        "section": "TESTING PHASE",
        "content": "Bước này đơn giản hơn nhiều. Với *raw input* mới, ta sử dụng feature extractor đã tạo được ở trên (tất nhiên không được sử dụng *output* của nó vì *output* là cái ta đang đi tìm) để tạo ra feature vector tương ứng. Feature vector được đưa vào *main algorithm* đã được học ở training phase để dự đoán *output*.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-8",
        "source": "36.main.md",
        "section": "Trực tiếp lấy raw data",
        "content": "Với bài toán phân loại chữ số viết tay trong bộ cơ sở dữ liệu [MNIST](/2017/01/04/kmeans2/#bo-co-so-du-lieu-mnist), mỗi bức ảnh có số chiều là 28 pixel x 28 pixel (tất nhiên việc *crop* và chỉnh sửa mỗi bức ảnh đã được thực hiện từ trước rồi, đó đã là một phần của feature engineering rồi). Một cách đơn giản thường được dùng là *kéo dài* ma trận 28x28 này để được 1 vector có số chiều 784. Trong cách này, các cột (hoặc hàng) của ma trận ảnh được đặt chồng lên (hoặc cạnh nhau) để được 1 vector dài. Vector dài này được trực tiếp sử dụng làm feature đưa vào các bộ classifier/clustering/regression/… Lúc này, giá trị của mỗi pixel ảnh được coi là một feature. Rõ ràng việc làm đơn giản này đã làm mất thông tin về *không gian* (spatial information) giữa các điểm ảnh, tuy nhiên, trong nhiều trường hợp, nó vẫn mang lại kết quả khả quan.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-9",
        "source": "36.main.md",
        "section": "Feature selection",
        "content": "Giả sử rằng các điểm dữ liệu có số features khác nhau (do kích thước dữ liệu khác nhau hay do một số feature mà điểm dữ liệu này có nhưng điểm dữ liệu kia lại không thu thập được), và số lượng features là cực lớn. Chúng ta cần *chọn* ra một số lượng nhỏ hơn các feature phù hợp với bài toán. *Chọn thế nào* và *thế nào là phù hợp* lại là một bài toán khác, tôi sẽ không bàn thêm ở đây.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-10",
        "source": "36.main.md",
        "section": "Dimensionality reduction",
        "content": "Một phương pháp nữa tôi đã đề cập đó là làm giảm số chiều của dữ liệu để giảm bộ nhớ và khối lượng tính toán. Việc giảm số chiều này có thể được thực hiện bằng nhiều cách, trong đó *random projection* là cách đơn giản nhất. Tức chọn một *ma trận chiếu* (projection matrix) ngẫu nhiên (ma trận béo) rồi nhân nó với từng điểm dữ liệu (giả sử dữ liệu ở dạng vector cột) để được các vector có số chiều thấp hơn. Ví dụ, vector ban đầu có số chiều là 784, chọn *ma trận chiếu* có kích thước (100x784), khi đó nếu nhân ma trận chéo này với vector ban đầu, ta sẽ được một vector mới có số chiều là 100, nhỏ hơn số chiều ban đầu rất nhiều. Lúc này, có thể ta không có tên gọi cho mỗi feature nữa vì các feature ở vector ban đầu đã được trộn lẫn với nhau theo một tỉ lệ nào đó rồi lưu vào vector mới này. Mỗi thành phần của vector mới này được coi là một feature (không tên). Việc chọn một ma trận chiếu ngẫu nhiên đôi khi mang lại kết quả tệ không mong muốn vì thông tin bị mất đi quá nhiều. Một phương pháp được sử dụng nhiều để hạn chế lượng thông tin mất đi có tên là [Principle Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) sẽ được tôi trình bày sau đây khoảng 1-2 tháng. **Chú ý:** Feature learning không nhất thiết phải làm giảm số chiều dữ liệu, đôi khi feature vector còn có số chiều lớn hơn raw data. Random projection cũng có thể làm được việc này nếu ma trận chiếu là một ma trận *cao* (số cột ít hơn số hàng).",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-11",
        "source": "36.main.md",
        "section": "Bag-of-words",
        "content": "Hẳn rất nhiều bạn đã tự đặt câu hỏi: Với một văn bản thì feature vector sẽ có dạng như thế nào? Làm sao đưa các từ, các câu, đoạn văn ở dạng *text* trong các văn bản về một vector mà mỗi phần tử là một số? Có một phương pháp rất phổ biến giúp bạn trả lời những câu hỏi này. Phương pháp đó có tên là *Bag of Words (BoW)* (*Túi đựng Từ*). Vẫn theo thói quen, tôi bắt đầu bằng một ví dụ. Giả sử chúng ta có bài toán phân loại tin rác. Ta thấy rằng nếu một tin có chứa các từ *khuyến mại, giảm giá, trúng thưởng, miễn phí, quà tặng, tri ân, …* thì nhiều khả năng đó là một tin nhắn rác. Vậy phương pháp đơn giản nhất là *đếm* xem trong tin đó có bao nhiêu từ thuộc vào các từ trên, nếu nhiều hơn 1 ngưỡng nào đó thì ta quyết định đó là tin rác. (Tất nhiên bài toán thực tế phức tạp hơn nhiều khi các từ có thể được viết dưới dạng không dấu, hoặc bị cố tình viết sai chính tả, hoặc dùng ngôn ngữ teen). Với các loại văn bản khác nhau thì lượng từ liên quan tới từng chủ đề cũng khác nhau. Từ đó có thể dựa vào số lượng các từ trong từng loại để làm các vector đặc trưng cho từng văn bản. Tôi xin lấy ví dụ cụ thể hơn về cách tạo ra vector đặc trưng cho mỗi văn bản dựa trên BoW và xin được lấy tiếng Anh làm ví dụ (nguồn [Bag of Words wiki](https://en.wikipedia.org/wiki/Bag-of-words_model). Tiếng Việt khó hơn vì một từ có thể có nhiều âm tiết, tiếng Anh thì thường cứ gặp dấu cách là kết thúc một từ). Giả sử chúng ta có hai văn bản đơn giản: ``` (1) John likes to watch movies. Mary likes movies too. ``` và ``` (2) John also likes to watch football games. ``` Dựa trên hai văn bản này, ta có danh sách các từ được sử dụng, được gọi là *từ điển* với 10 *từ* như sau: ``` [\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"also\", \"football\", \"games\", \"Mary\", \"too\"] ``` Với mỗi văn bản, ta sẽ tạo ra một vector đặc trưng có số chiều bằng 10, mỗi phần tử đại diện cho số từ tương ứng xuất hiện trong văn bản đó. Với hai văn bản trên, ta sẽ có hai vector đặc trưng là: ``` (1) [1, 2, 1, 1, 2, 0, 0, 0, 1, 1] (2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0] ``` Văn bản (1) có 1 từ “John”, 2 từ “likes”, 0 từ “also”, 0 từ “football”, … nên ta thu được vector tương ứng như trên. Có một vài điều cần lưu ý trong BoW: * Với những ứng dụng thực tế, *từ điền* có nhiều hơn 10 từ rất nhiều, có thể đến một trăm nghìn hoặc cả triệu, như vậy vector đặc trưng thu được sẽ rất *dài*. Một văn bản chỉ có 1 câu, và 1 tiểu thuyết nghìn trang đều được biểu diễn bằng các vector có số chiều bằng 100 nghìn hoặc 1 triệu. * Có rất nhiều từ trong từ điển không xuất hiện trong một văn bản. Như vậy các vector đặc trưng thu được thường có rất nhiều phần tử bằng 0. Các vector có nhiều phần tử bằng 0 được gọi là *sparse vector* (sparse hiểu theo nghĩa là *thưa thớt, rải rác*, tôi xin phép chỉ sử dụng khái niệm này bằng tiếng Anh). Để việc lưu trữ được hiệu quả hơn, ta không lưu cả vector đó mà chỉ lưu *vị trí* của các phần tử khác 0 và *giá trị* tương ứng. Lưu ý: nếu có hơn 50% số phần tử khác 0, việc làm này lại phản tác dụng! * Thi thoảng có những từ hiếm gặp không nằm trong từ điển, vậy ta sẽ làm gì? Một cách thường được dùng là *mở rộng* vector đặc trưng thêm 1 phần tử, gọi là phẩn tử `<Unknown>`. Mọi từ không có trong từ điền đều được coi là `<Unknown>`. * Nghĩ kỹ một chút, những từ hiếm đôi khi lại mang những thông tin quan trọng nhất mà chỉ loại văn bản đó có. Đây là một nhược điểm của BoW. Có một phương pháp cải tiến khác giúp khắc phục nhược điểm này có tên là Term Frequency-Inverse Document Frequency (TF-IDF) dùng để xác định tầm quan trọng của một từ trong một văn bản dựa trên toàn bộ văn bản trong cơ sở dữ liệu (corpus). Bạn đọc muốn tìm hiểu thêm có thể xem [5 Algorithms Every Web Developer Can Use and Understand, section 5.](https://www.gitbook.com/book/lizrush/algorithms-for-webdevs-ebook/details) * Nhược điểm lớn nhất của BoW là nó không mang thông tin về thứ tự của các từ. Cũng như sự liên kết giữa các câu, các đoạn văn trong văn bản. Ví dụ, ba câu sau đây: “*Em yêu anh không?*”, “*Em không yêu anh*”, và “*Không, (nhưng) anh yêu em*” khi được trích chọn đặc trưng bằng BoW sẽ cho ra ba vector giống hệt nhau, mặc dù ý nghĩa khác hẳn nhau. **Bonus:** hình dưới đây là tần suất sử dụng các từ (coi mỗi âm tiết là một từ) trong Truyện Kiều ([theo bản này](https://bitbucket.org/tiepvupsu/vietnamese/src/c6f3af6050f8ca911ed0fa209220ce3c99010075/TruyenKieu2.txt?at=master&fileviewer=file-view-default)) nếu ta chỉ sử dụng 30 từ có tần suất cao nhất. : ![](\\assets\\FeatureEngineering\\truyenkieu.png) Hình 2: Bag of Words cho Truyện Kiều với 30 từ có tần suất cao nhất.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-12",
        "source": "36.main.md",
        "section": "Bag-of-Words trong Computer Vision",
        "content": "Bags of Words cũng được áp dụng trong Computer Vision với cách định nghĩa *words* và từ điển khác. Xét các ví dụ sau: **Ví dụ 1:** Có hai class ảnh, một class là ảnh các khu rừng, một class là ảnh các sa mạc. Phân loại một bức ảnh là rừng hay sa mạc (giả sử ta biết rằng nó thuộc một trong hai loại này) một cách trực quan nhất là dựa vào màu sắc. Màu xanh nhiều thì là rừng, màu đỏ và vàng nhiều thì là sa mạc. Vậy chúng ta có thể có một mô hình đơn giản để trích chọn đặc trưng như sau: * Với một bức ảnh, chuẩn bị một vector \\(\\mathbf{x}\\) có số chiều bằng 3, đại diện cho 3 màu xanh (\\(x\\_1\\)), đỏ (\\(x\\_2\\)), và vàng (\\(x\\_3\\)). * Với mỗi điểm ảnh trong bức ảnh đó, xem nó gần với màu xanh, đỏ hay vàng nhất dựa trên giá trị của pixel đó. Nếu nó gần điểm xanh nhất, tăng \\(x\\_1\\) lên 1; gần đỏ nhất, tăng \\(x\\_2\\) lên 1; gần vàng nhất, tăng \\(x\\_3\\) lên 1. * Sau khi xem xét tất cả các điểm ảnh, dù cho bức ảnh có kích thước thế nào, ta vẫn thu được một vector có độ dài bằng 3, mỗi phần tử thể hiện việc có bao nhiêu pixel trong bức ảnh có màu tương ứng. Vector cuối này còn được gọi là vector histogram của bức ảnh tương ứng với ba màu xanh, đỏ, vàng. Dựa vào vector này, ta có thể quyết định bức ảnh đó là ảnh rừng hay sa mạc. **Ví dụ 2:** Trên thực tế, các bài toán xử lý ảnh không đơn giản như ví dụ 1 trên đây. Mắt người thực ra nhạy với các đường nét, hình dáng hơn là màu sắc. Một cái (ảnh) cây dù không có màu vẫn là một cái (ảnh) cây! Vì vậy, xem xét giá trị từng điểm ảnh một không mang lại kết quả khả quan vì lượng thông tin bị mất quá nhiều. Có một cách khắc phục là thay vì xem xét một điểm ảnh, ta xem xét một *cửa sổ* nhỏ trong ảnh (trong Computer Vision, cửa sổ này được gọi là patch) là một hình chữ nhật chứa nhiều điểm ảnh gần nhau. Cửa sổ này đủ lớn để có thể chứa được các bộ phận có thể mô tả được vật thể trong ảnh. Ví dụ với mặt người, các patch nên đủ lớn để chứa được các phần của khuôn mặt như mắt, mũi, miệng như hình dưới đây. ![](\\assets\\FeatureEngineering\\bow_face.png) Hình 3: Bag of Words cho ảnh chứa mặt người. (Nguồn  [Bag of visual words model: recognizing object categories](http://www.robots.ox.ac.uk/~az/icvss08_az_bow.pdf)) Tương tự thế, với ảnh là ô tô, các patch thu được có thể là bánh xe, khung xe, cửa xe, … như hàng trên trong hình dưới đây. ![](\\assets\\FeatureEngineering\\bow_car.png) Hình 4: Bag of Words cho ảnh ô tô. (Nguồn: tôi cố gắng tìm nguồn cho hình này nhưng tất cả các tài liệu tôi tìm được đều ghi \"Source: B. Leibe\", tôi cũng xin được trích nguồn tương tự) Có một câu hỏi đặt ra là, trong xử lý văn bản, hai từ được coi là như nhau nếu nó được biểu diễn bởi các ký tự giống nhau. Vậy trong xử lý ảnh, hai patches được coi là như nhau khi nào? Khi mọi pixel trong hai patches có giá trị bằng nhau sao? Câu trả lời là không. Xác suất để hai patches giống hệt nhau từng pixel là rất thấp vì có thể một phần của vật thể trong một patch bị lệch đi vài pixel so với phần đó trong patch kia; hoặc phần vật thể trong patch bị méo, hoặc có độ sáng khác nhau, mặc dù ta vẫn nhìn thấy hai patches đó *rất giống nhau*. Vậy thì hai patch được coi là như nhau khi nào? Và *từ điển* ở đây được định nghĩa như thế nào? Câu trả lời ngắn: hai patches là gần giống nhau nếu khoảng cách Euclid giữa hai vector tạo bởi hai patches đó gần nhau. Từ điển (codebook) sẽ có số phần tử do ta tự chọn. Số phần tử càng cao thì độ sai lệch càng ít, nhưng sẽ nặng về tính toán hơn. Câu trả lời dài: chúng ta có thể áp dụng [K-means clustering](/2017/01/01/kmeans/). Với rất nhiều patches thu được, giả sử ta muốn xây dựng một *codebook* với chỉ khoảng 1000 *words*. Vậy thì ta cho \\(k = 1000\\) rồi thực hiện K-means clustering trên toàn bộ số patches thu được (từ tập training). Sau khi thực hiện K-means clustering, ta thu được 1000 clusters và 1000 centers tương ứng. Mỗi centers này được coi là một *words*, và tất cả những điểm rơi vào cùng một cluster được coi là cùng một bag. Với ảnh trong tập test data, ta cũng lấy các patches rồi xem chúng rơi vào những bags nào. Từ đó suy ra vector đặc trưng cho mỗi bức ảnh. Chú ý rằng với \\(k = 1000\\), mỗi bức ảnh sẽ được *mô tả* bởi một vector có số chiều 1000, tức là mỗi điểm dữ liệu bây giờ đã có số chiều bằng nhau, mặc dù ảnh thô đầu vào có thể có kích thước khác nhau.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-13",
        "source": "36.main.md",
        "section": "Feature Scaling and Normalization",
        "content": "(Tham khảo [Feature Scaling wiki](https://en.wikipedia.org/wiki/Feature_scaling)). Các điểm dữ liệu đôi khi được đo đạc với những đơn vị khác nhau, m và feet chẳng hạn. Hoặc có hai thành phần (của vector dữ liệu) chênh lệch nhau quá lớn, một thành phần có khoảng giá trị từ 0 đến 1000, thành phần kia chỉ có khoảng giá trị từ 0 đến 1 chẳng hạn. Lúc này, chúng ta cần chuẩn hóa dữ liệu trước khi thực hiện các bước tiếp theo. **Chú ý:** việc chuẩn hóa này chỉ được thực hiện khi vector dữ liệu đã có cùng chiều. Một vài phương pháp chuẩn hóa thường dùng:",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-14",
        "source": "36.main.md",
        "section": "Rescaling",
        "content": "Phương pháp đơn giản nhất là đưa tất cả các thành phần về cùng một khoảng, \\([0, 1]\\) hoặc \\([-1, 1]\\) chẳng hạn, tùy thuộc vào ứng dụng. Nếu muốn đưa một thành phần (feature) về khoảng \\([0, 1]\\), công thức sẽ là: \\[ x’ = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} \\] trong đó \\(x\\) là giá trị ban đầu, \\(x’\\) là giá trị sau khi chuẩn hóa. \\(\\min(x), \\max(x)\\) được tính trên toàn bộ dữ liệu training data ở cùng một thành phần. Việc này được thực hiện trên từng thành phần của vector dữ liệu \\(\\mathbf{x}\\).",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-15",
        "source": "36.main.md",
        "section": "Standardization",
        "content": "Một phương pháp nữa cũng hay được sử dụng là giả sử mỗi thành phần đều có phân phối chuẩn với kỳ vọng là 0 và phương sai là 1. Khi đó, công thức chuẩn hóa sẽ là: \\[ x’ = \\frac{x - \\bar{x}}{\\sigma} \\] với \\(\\bar{x}, \\sigma\\) lần lượt là kỳ vọng và phương sai (standard deviation) của thành phần đó trên toàn bộ training data.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-16",
        "source": "36.main.md",
        "section": "Scaling to unit length",
        "content": "Một lựa chọn khác nữa cũng được sử dụng rộng rãi là chuẩn hóa các thành phần của mỗi vector dữ liệu sao cho toàn bộ vector có độ lớn (Euclid, tức [norm 2](/math/#norm2)) bằng 1. Việc này có thể được thực hiện bằng: \\[ \\mathbf{x}’ = \\frac{\\mathbf{x}}{||\\mathbf{x}||\\_2} \\]",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-17",
        "source": "36.main.md",
        "section": "4. Thảo luận",
        "content": "Xem ra thế giới Machine Learning rất rộng lớn và có rất nhiều thứ chúng ta cần làm. Và vẫn có khá nhiều thứ tôi có thể viết được. Tuy nhiên, blog này sẽ không tập trung nhiều vào Feature Learning, mặc dù sẽ có một vài bài nói về Dimensionality Reduction. Tôi sẽ sử dụng các bộ dữ liệu có sẵn, và đã qua bước Feature Learning.",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "36.main-18",
        "source": "36.main.md",
        "section": "5. Tài liệu tham khảo",
        "content": "1. [Feature Enginieering - wiki](https://en.wikipedia.org/wiki/Feature_engineering) 2. [Feature Scaling wiki](https://en.wikipedia.org/wiki/Feature_scaling) 3. Csurka, Gabriella, et al. “[Visual categorization with bags of keypoints.](https://people.eecs.berkeley.edu/~efros/courses/AP06/Papers/csurka-eccv-04.pdf)” Workshop on statistical learning in computer vision, ECCV. Vol. 1. No. 1-22. 2004. 4. [Bag of Words model - wiki](https://en.wikipedia.org/wiki/Bag-of-words_model) 5. [Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words)",
        "url": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/"
    },
    {
        "id": "44.main-1",
        "source": "44.main.md",
        "section": "Introduction",
        "content": "Trong bài này, tôi sẽ giới thiệu một trong những thuật toán cơ bản nhất (và đơn giản nhất) của Machine Learning. Đây là một thuật toán *Supervised learning* có tên **Linear Regression** (Hồi Quy Tuyến Tính). Bài toán này đôi khi được gọi là *Linear Fitting* (trong thống kê) hoặc *Linear Least Square*. **Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) * [2. Phân tích toán học](#-phan-tich-toan-hoc) + [2.1. Dạng của Linear Regression](#-dang-cua-linear-regression) + [2.2. Sai số dự đoán](#-sai-so-du-doan) + [2.3. Hàm mất mát](#-ham-mat-mat) + [2.4. Nghiệm cho bài toán Linear Regression](#-nghiem-cho-bai-toan-linear-regression) * [3. Ví dụ trên Python](#-vi-du-tren-python) + [3.1. Bài toán](#-bai-toan) + [3.2. Hiển thị dữ liệu trên đồ thị](#-hien-thi-du-lieu-tren-do-thi) + [3.3. Nghiệm theo công thức](#-nghiem-theo-cong-thuc) + [3.4. Nghiệm theo thư viện scikit-learn](#-nghiem-theo-thu-vien-scikit-learn) * [4. Thảo luận](#-thao-luan) + [4.1. Các bài toán có thể giải bằng Linear Regression](#-cac-bai-toan-co-the-giai-bang-linear-regression) + [4.2. Hạn chế của Linear Regression](#-han-che-cua-linear-regression) + [4.3. Các phương pháp tối ưu](#-cac-phuong-phap-toi-uu) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-2",
        "source": "44.main.md",
        "section": "1. Giới thiệu",
        "content": "Quay lại [ví dụ đơn giản được nêu trong bài trước](/2016/12/27/categories/#regression-hoi-quy): một căn nhà rộng \\(x\\_1 ~ \\text{m}^2\\), có \\(x\\_2\\) phòng ngủ và cách trung tâm thành phố \\(x\\_3~ \\text{km}\\) có giá là bao nhiêu. Giả sử chúng ta đã có số liệu thống kê từ 1000 căn nhà trong thành phố đó, liệu rằng khi có một căn nhà mới với các thông số về diện tích, số phòng ngủ và khoảng cách tới trung tâm, chúng ta có thể dự đoán được giá của căn nhà đó không? Nếu có thì hàm dự đoán \\(y = f(\\mathbf{x}) \\) sẽ có dạng như thế nào. Ở đây \\(\\mathbf{x} = [x\\_1, x\\_2, x\\_3] \\) là một vector hàng chứa thông tin *input*, \\(y\\) là một số vô hướng (scalar) biểu diễn *output* (tức giá của căn nhà trong ví dụ này). **Lưu ý về ký hiệu toán học:** *trong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng không in đậm, có thể viết hoa, ví dụ \\(x\\_1, N, y, k\\). Các vector được biểu diễn bằng các chữ cái thường in đậm, ví dụ \\(\\mathbf{y}, \\mathbf{x}\\_1 \\). Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụ \\(\\mathbf{X, Y, W} \\).* Một cách đơn giản nhất, chúng ta có thể thấy rằng: i) diện tích nhà càng lớn thì giá nhà càng cao; ii) số lượng phòng ngủ càng lớn thì giá nhà càng cao; iii) càng xa trung tâm thì giá nhà càng giảm. Một hàm số đơn giản nhất có thể mô tả mối quan hệ giữa giá nhà và 3 đại lượng đầu vào là: \\[y \\approx f(\\mathbf{x}) = \\hat{y}\\] \\[f(\\mathbf{x}) =w\\_1 x\\_1 + w\\_2 x\\_2 + w\\_3 x\\_3 + w\\_0 ~~~~ (1)\\] trong đó, \\(w\\_1, w\\_2, w\\_3, w\\_0\\) là các hằng số, \\(w\\_0\\) còn được gọi là bias. Mối quan hệ \\(y \\approx f(\\mathbf{x})\\) bên trên là một mối quan hệ tuyến tính (linear). Bài toán chúng ta đang làm là một bài toán thuộc loại regression. Bài toán đi tìm các hệ số tối ưu \\( \\{w\\_1, w\\_2, w\\_3, w\\_0 \\}\\) chính vì vậy được gọi là bài toán Linear Regression. **Chú ý 1:** \\(y\\) là giá trị thực của *outcome* (dựa trên số liệu thống kê chúng ta có trong tập *training data*), trong khi \\(\\hat{y}\\) là giá trị mà mô hình Linear Regression dự đoán được. Nhìn chung, \\(y\\) và \\(\\hat{y}\\) là hai giá trị khác nhau do có sai số mô hình, tuy nhiên, chúng ta mong muốn rằng sự khác nhau này rất nhỏ. **Chú ý 2:** *Linear* hay *tuyến tính* hiểu một cách đơn giản là *thẳng, phẳng*. Trong không gian hai chiều, một hàm số được gọi là *tuyến tính* nếu đồ thị của nó có dạng một *đường thẳng*. Trong không gian ba chiều, một hàm số được goi là *tuyến tính* nếu đồ thị của nó có dạng một *mặt phẳng*. Trong không gian nhiều hơn 3 chiều, khái niệm *mặt phẳng* không còn phù hợp nữa, thay vào đó, một khái niệm khác ra đời được gọi là *siêu mặt phẳng* (*hyperplane*). Các hàm số tuyến tính là các hàm đơn giản nhất, vì chúng thuận tiện trong việc hình dung và tính toán. Chúng ta sẽ được thấy trong các bài viết sau, *tuyến tính* rất quan trọng và hữu ích trong các bài toán Machine Learning. Kinh nghiệm cá nhân tôi cho thấy, trước khi hiểu được các thuật toán *phi tuyến* (non-linear, không phẳng), chúng ta cần nắm vững các kỹ thuật cho các mô hình *tuyến tính*.",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-3",
        "source": "44.main.md",
        "section": "2.1. Dạng của Linear Regression",
        "content": "Trong phương trình \\((1)\\) phía trên, nếu chúng ta đặt \\(\\mathbf{w} = [w\\_0, w\\_1, w\\_2, w\\_3]^T = \\) là vector (cột) hệ số cần phải tối ưu và \\(\\mathbf{\\bar{x}} = [1, x\\_1, x\\_2, x\\_3]\\) (đọc là *x bar* trong tiếng Anh) là vector (hàng) dữ liệu đầu vào *mở rộng*. Số \\(1\\) ở đầu được thêm vào để phép tính đơn giản hơn và thuận tiện cho việc tính toán. Khi đó, phương trình (1) có thể được viết lại dưới dạng: \\[y \\approx \\mathbf{\\bar{x}}\\mathbf{w} = \\hat{y}\\] Chú ý rằng \\(\\mathbf{\\bar{x}}\\) là một vector hàng. ([Xem thêm về ký hiệu vector hàng và cột tại đây](/math/#luu-y-ve-ky-hieu))",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-4",
        "source": "44.main.md",
        "section": "2.2. Sai số dự đoán",
        "content": "Chúng ta mong muốn rằng sự sai khác \\(e\\) giữa giá trị thực \\(y\\) và giá trị dự đoán \\(\\hat{y}\\) (đọc là *y hat* trong tiếng Anh) là nhỏ nhất. Nói cách khác, chúng ta muốn giá trị sau đây càng nhỏ càng tốt: \\[ \\frac{1}{2}e^2 = \\frac{1}{2}(y - \\hat{y})^2 = \\frac{1}{2}(y - \\mathbf{\\bar{x}}\\mathbf{w})^2 \\] trong đó hệ số \\(\\frac{1}{2} \\) (*lại*) là để thuận tiện cho việc tính toán (khi tính đạo hàm thì số \\(\\frac{1}{2} \\) sẽ bị triệt tiêu). Chúng ta cần \\(e^2\\) vì \\(e = y - \\hat{y} \\) có thể là một số âm, việc nói \\(e\\) nhỏ nhất sẽ không đúng vì khi \\(e = - \\infty\\) là rất nhỏ nhưng sự sai lệch là rất lớn. Bạn đọc có thể tự đặt câu hỏi: **tại sao không dùng trị tuyệt đối \\( |e| \\) mà lại dùng bình phương \\(e^2\\) ở đây?** Câu trả lời sẽ có ở phần sau.",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-5",
        "source": "44.main.md",
        "section": "2.3. Hàm mất mát",
        "content": "Điều tương tự xảy ra với tất cả các cặp *(input, outcome)* \\( (\\mathbf{x}\\_i, y\\_i), i = 1, 2, \\dots, N \\), với \\(N\\) là số lượng dữ liệu quan sát được. Điều chúng ta muốn, tổng sai số là nhỏ nhất, tương đương với việc tìm \\( \\mathbf{w} \\) để hàm số sau đạt giá trị nhỏ nhất: \\[ \\mathcal{L}(\\mathbf{w}) = \\frac{1}{2}\\sum\\_{i=1}^N (y\\_i - \\mathbf{\\bar{x}\\_i}\\mathbf{w})^2 ~~~~~(2) \\] Hàm số \\(\\mathcal{L}(\\mathbf{w}) \\) được gọi là **hàm mất mát** (loss function) của bài toán Linear Regression. Chúng ta luôn mong muốn rằng sự mất mát (sai số) là nhỏ nhất, điều đó đồng nghĩa với việc tìm vector hệ số \\( \\mathbf{w} \\) sao cho giá trị của hàm mất mát này càng nhỏ càng tốt. Giá trị của \\(\\mathbf{w}\\) làm cho hàm mất mát đạt giá trị nhỏ nhất được gọi là *điểm tối ưu* (optimal point), ký hiệu: \\[ \\mathbf{w}^\\* = \\arg\\min\\_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w}) \\] Trước khi đi tìm lời giải, chúng ta đơn giản hóa phép toán trong phương trình hàm mất mát \\((2)\\). Đặt \\(\\mathbf{y} = [y\\_1; y\\_2; \\dots; y\\_N]\\) là một vector cột chứa tất cả các *output* của *training data*; \\( \\mathbf{\\bar{X}} = [\\mathbf{\\bar{x}}\\_1; \\mathbf{\\bar{x}}\\_2; \\dots; \\mathbf{\\bar{x}}\\_N ] \\) là ma trận dữ liệu đầu vào (mở rộng) mà mỗi hàng của nó là một điểm dữ liệu. Khi đó hàm số mất mát \\(\\mathcal{L}(\\mathbf{w})\\) được viết dưới dạng ma trận đơn giản hơn: \\[ \\mathcal{L}(\\mathbf{w}) = \\frac{1}{2}\\sum\\_{i=1}^N (y\\_i - \\mathbf{\\bar{x}}\\_i\\mathbf{w})^2 \\] \\[ = \\frac{1}{2} \\|\\mathbf{y} - \\mathbf{\\bar{X}}\\mathbf{w} \\|\\_2^2 ~~~(3) \\] với \\( \\| \\mathbf{z} \\|\\_2 \\) là Euclidean norm (chuẩn Euclid, hay khoảng cách Euclid), nói cách khác \\( \\| \\mathbf{z} \\|\\_2^2 \\) là tổng của bình phương mỗi phần tử của vector \\(\\mathbf{z}\\). Tới đây, ta đã có một dạng đơn giản của hàm mất mát được viết như phương trình \\((3)\\).",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-6",
        "source": "44.main.md",
        "section": "2.4. Nghiệm cho bài toán Linear Regression",
        "content": "**Cách phổ biến nhất để tìm nghiệm cho một bài toán tối ưu (chúng ta đã biết từ khi học cấp 3) là giải phương trình đạo hàm (gradient) bằng 0!** Tất nhiên đó là khi việc tính đạo hàm và việc giải phương trình đạo hàm bằng 0 không quá phức tạp. Thật may mắn, với các mô hình tuyến tính, hai việc này là khả thi. Đạo hàm theo \\(\\mathbf{w} \\) của hàm mất mát là: \\[ \\frac{\\partial{\\mathcal{L}(\\mathbf{w})}}{\\partial{\\mathbf{w}}} = \\mathbf{\\bar{X}}^T(\\mathbf{\\bar{X}}\\mathbf{w} - \\mathbf{y}) \\] Các bạn có thể tham khảo bảng đạo hàm theo vector hoặc ma trận của một hàm số trong [mục D.2 của tài liệu này](https://ccrma.stanford.edu/~dattorro/matrixcalc.pdf). *Đến đây tôi xin quay lại câu hỏi ở phần [Sai số dự đoán](#sai so du doan) phía trên về việc tại sao không dùng trị tuyệt đối mà lại dùng bình phương. Câu trả lời là hàm bình phương có đạo hàm tại mọi nơi, trong khi hàm trị tuyệt đối thì không (đạo hàm không xác định tại 0)*. Phương trình đạo hàm bằng 0 tương đương với: \\[ \\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}}\\mathbf{w} = \\mathbf{\\bar{X}}^T\\mathbf{y} \\triangleq \\mathbf{b} ~~~ (4) \\] (ký hiệu \\(\\mathbf{\\bar{X}}^T\\mathbf{y} \\triangleq \\mathbf{b} \\) nghĩa là *đặt* \\(\\mathbf{\\bar{X}}^T\\mathbf{y}\\) *bằng* \\(\\mathbf{b}\\) ). Nếu ma trận vuông \\( \\mathbf{A} \\triangleq \\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}}\\) khả nghịch (non-singular hay invertible) thì phương trình \\((4)\\) có nghiệm duy nhất: \\( \\mathbf{w} = \\mathbf{A}^{-1}\\mathbf{b} \\). Vậy nếu ma trận \\(\\mathbf{A} \\) không khả nghịch (có định thức bằng 0) thì sao? Nếu các bạn vẫn nhớ các kiến thức về hệ phương trình tuyến tính, trong trường hợp này thì hoặc phương trinh \\( (4) \\) vô nghiệm, hoặc là nó có vô số nghiệm. Khi đó, chúng ta sử dụng khái niệm [*giả nghịch đảo*](https://vi.wikipedia.org/wiki/Giả_nghịch_đảo_Moore–Penrose) \\( \\mathbf{A}^{\\dagger} \\) (đọc là *A dagger* trong tiếng Anh). (*Giả nghịch đảo (pseudo inverse) là trường hợp tổng quát của nghịch đảo khi ma trận không khả nghịch hoặc thậm chí không vuông. Trong khuôn khổ bài viết này, tôi xin phép được lược bỏ phần này, nếu các bạn thực sự quan tâm, tôi sẽ viết một bài khác chỉ nói về giả nghịch đảo. Xem thêm: [Least Squares, Pseudo-Inverses, PCA & SVD](http://www.sci.utah.edu/~gerig/CS6640-F2012/Materials/pseudoinverse-cis61009sl10.pdf).*) Với khái niệm giả nghịch đảo, điểm tối ưu của bài toán Linear Regression có dạng: \\[ \\mathbf{w} = \\mathbf{A}^{\\dagger}\\mathbf{b} = (\\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}})^{\\dagger} \\mathbf{\\bar{X}}^T\\mathbf{y} ~~~ (5) \\]",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-7",
        "source": "44.main.md",
        "section": "3.1. Bài toán",
        "content": "Trong phần này, tôi sẽ chọn một ví dụ đơn giản về việc giải bài toán Linear Regression trong Python. Tôi cũng sẽ so sánh nghiệm của bài toán khi giải theo phương trình \\((5) \\) và nghiệm tìm được khi dùng thư viện [scikit-learn](http://scikit-learn.org/stable/) của Python. (*Đây là thư viện Machine Learning được sử dụng rộng rãi trong Python*). Trong ví dụ này, dữ liệu đầu vào chỉ có 1 giá trị (1 chiều) để thuận tiện cho việc minh hoạ trong mặt phẳng. Chúng ta có 1 bảng dữ liệu về chiều cao và cân nặng của 15 người như dưới đây: | Chiều cao (cm) | Cân nặng (kg) | Chiều cao (cm) | Cân nặng (kg) | | --- | --- | --- | --- | | 147 | 49 | 168 | 60 | | 150 | 50 | 170 | 72 | | 153 | 51 | 173 | 63 | | 155 | 52 | 175 | 64 | | 158 | 54 | 178 | 66 | | 160 | 56 | 180 | 67 | | 163 | 58 | 183 | 68 | | 165 | 59 |  |  | Bài toán đặt ra là: liệu có thể dự đoán cân nặng của một người dựa vào chiều cao của họ không? (*Trên thực tế, tất nhiên là không, vì cân nặng còn phụ thuộc vào nhiều yếu tố khác nữa, thể tích chẳng hạn*). Vì blog này nói về các thuật toán Machine Learning đơn giản nên tôi sẽ giả sử rằng chúng ta có thể dự đoán được. Chúng ta có thể thấy là cân nặng sẽ tỉ lệ thuận với chiều cao (càng cao càng nặng), nên có thể sử dụng Linear Regression model cho việc dự đoán này. Để kiểm tra độ chính xác của model tìm được, chúng ta sẽ giữ lại cột 155 và 160 cm để kiểm thử, các cột còn lại được sử dụng để huấn luyện (train) model.",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-8",
        "source": "44.main.md",
        "section": "3.2. Hiển thị dữ liệu trên đồ thị",
        "content": "Trước tiên, chúng ta cần có hai thư viện [numpy](http://www.numpy.org/) cho đại số tuyến tính và [matplotlib](http://matplotlib.org/) cho việc vẽ hình. ```",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-9",
        "source": "44.main.md",
        "section": "To support both python 2 and python 3",
        "content": "from __future__ import division, print_function, unicode_literals import numpy as np import matplotlib.pyplot as plt ``` Tiếp theo, chúng ta khai báo và biểu diễn dữ liệu trên một đồ thị. ```",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-10",
        "source": "44.main.md",
        "section": "height (cm)",
        "content": "X = np.array([[147, 150, 153, 158, 163, 165, 168, 170, 173, 175, 178, 180, 183]]).T",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-11",
        "source": "44.main.md",
        "section": "weight (kg)",
        "content": "y = np.array([[ 49, 50, 51,  54, 58, 59, 60, 62, 63, 64, 66, 67, 68]]).T",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-12",
        "source": "44.main.md",
        "section": "Visualize data",
        "content": "plt.plot(X, y, 'ro') plt.axis([140, 190, 45, 75]) plt.xlabel('Height (cm)') plt.ylabel('Weight (kg)') plt.show() ``` ![](/assets/LR/output_3_0.png) Từ đồ thị này ta thấy rằng dữ liệu được sắp xếp gần như theo 1 đường thẳng, vậy mô hình Linear Regression nhiều khả năng sẽ cho kết quả tốt: (cân nặng) = `w_1`\\*(chiều cao) + `w_0`",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-13",
        "source": "44.main.md",
        "section": "3.3. Nghiệm theo công thức",
        "content": "Tiếp theo, chúng ta sẽ tính toán các hệ số `w_1` và `w_0` dựa vào công thức \\((5)\\). Chú ý: giả nghịch đảo của một ma trận `A` trong Python sẽ được tính bằng `numpy.linalg.pinv(A)`, `pinv` là từ viết tắt của *pseudo inverse*. ```",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-14",
        "source": "44.main.md",
        "section": "Building Xbar",
        "content": "one = np.ones((X.shape[0], 1)) Xbar = np.concatenate((one, X), axis = 1)",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-15",
        "source": "44.main.md",
        "section": "Calculating weights of the fitting line",
        "content": "A = np.dot(Xbar.T, Xbar) b = np.dot(Xbar.T, y) w = np.dot(np.linalg.pinv(A), b) print('w = ', w)",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-16",
        "source": "44.main.md",
        "section": "Preparing the fitting line",
        "content": "w_0 = w[0][0] w_1 = w[1][0] x0 = np.linspace(145, 185, 2) y0 = w_0 + w_1*x0",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-17",
        "source": "44.main.md",
        "section": "Drawing the fitting line",
        "content": "plt.plot(X.T, y.T, 'ro')     # data plt.plot(x0, y0)               # the fitting line plt.axis([140, 190, 45, 75]) plt.xlabel('Height (cm)') plt.ylabel('Weight (kg)') plt.show() ``` ``` w =  [[-33.73541021] [  0.55920496]] ``` ![](/assets/LR/output_5_1.png) Từ đồ thị bên trên ta thấy rằng các điểm dữ liệu màu đỏ nằm khá gần đường thẳng dự đoán màu xanh. Vậy mô hình Linear Regression hoạt động tốt với tập dữ liệu *training*. Bây giờ, chúng ta sử dụng mô hình này để dự đoán cân nặng của hai người có chiều cao 155 và 160 cm mà chúng ta đã không dùng khi tính toán nghiệm. ``` y1 = w_1*155 + w_0 y2 = w_1*160 + w_0 print( u'Predict weight of person with height 155 cm: %.2f (kg), real number: 52 (kg)'  %(y1) ) print( u'Predict weight of person with height 160 cm: %.2f (kg), real number: 56 (kg)'  %(y2) ) ``` ``` Predict weight of person with height 155 cm: 52.94 (kg), real number: 52 (kg) Predict weight of person with height 160 cm: 55.74 (kg), real number: 56 (kg) ``` Chúng ta thấy rằng kết quả dự đoán khá gần với số liệu thực tế.",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-18",
        "source": "44.main.md",
        "section": "3.4. Nghiệm theo thư viện scikit-learn",
        "content": "Tiếp theo, chúng ta sẽ sử dụng thư viện scikit-learn của Python để tìm nghiệm. ``` from sklearn import datasets, linear_model",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-19",
        "source": "44.main.md",
        "section": "fit the model by Linear Regression",
        "content": "regr = linear_model.LinearRegression(fit_intercept=False) # fit_intercept = False for calculating the bias regr.fit(Xbar, y)",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-20",
        "source": "44.main.md",
        "section": "Compare two results",
        "content": "print( 'Solution found by scikit-learn  : ', regr.coef_ ) print( 'Solution found by (5): ', w.T) ``` ``` Solution found by scikit-learn  :  [[  -33.73541021 0.55920496]] Solution found by (5):  [[  -33.73541021 0.55920496 ]] ``` Chúng ta thấy rằng hai kết quả thu được như nhau! (*Nghĩa là tôi đã không mắc lỗi nào trong cách tìm nghiệm ở phần trên*) [Source code Jupyter Notebook cho bài này.](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/LR/LR.ipynb)",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-21",
        "source": "44.main.md",
        "section": "4.1. Các bài toán có thể giải bằng Linear Regression",
        "content": "Hàm số \\(y \\approx f(\\mathbf{x})= \\mathbf{w}^T\\mathbf{x}\\) là một hàm tuyến tính theo cả \\( \\mathbf{w}\\) và \\(\\mathbf{x}\\). Trên thực tế, Linear Regression có thể áp dụng cho các mô hình chỉ cần tuyến tính theo \\(\\mathbf{w}\\). Ví dụ: \\[ y \\approx w\\_1 x\\_1 + w\\_2 x\\_2 + w\\_3 x\\_1^2 + \\] \\[ +w\\_4 \\sin(x\\_2) + w\\_5 x\\_1x\\_2 + w\\_0 \\] là một hàm tuyến tính theo \\(\\mathbf{w}\\) và vì vậy cũng có thể được giải bằng Linear Regression. Với mỗi dữ liệu đầu vào \\(\\mathbf{x}=[x\\_1; x\\_2] \\), chúng ta tính toán dữ liệu mới \\(\\tilde{\\mathbf{x}} = [x\\_1, x\\_2, x\\_1^2, \\sin(x\\_2), x\\_1x\\_2]\\) (đọc là *x tilde* trong tiếng Anh) rồi áp dụng Linear Regression với dữ liệu mới này. Xem thêm ví dụ về [Quadratic Regression](http://www.varsitytutors.com/hotmath/hotmath_help/topics/quadratic-regression) (Hồi Quy Bậc Hai). ![](http://www.varsitytutors.com/assets/vt-hotmath-legacy/hotmath_help/topics/quadratic-regression/f-qr-1-1.gif)</a> Quadratic Regression (Nguồn:  [Quadratic Regression](http://www.varsitytutors.com/hotmath/hotmath_help/topics/quadratic-regression))",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-22",
        "source": "44.main.md",
        "section": "4.2. Hạn chế của Linear Regression",
        "content": "Hạn chế đầu tiên của Linear Regression là nó rất **nhạy cảm với nhiễu** (sensitive to noise). Trong ví dụ về mối quan hệ giữa chiều cao và cân nặng bên trên, nếu có chỉ một cặp dữ liệu *nhiễu* (150 cm, 90kg) thì kết quả sẽ sai khác đi rất nhiều. Xem hình dưới đây: ![](/assets/LR/output_13_1.png) Vì vậy, trước khi thực hiện Linear Regression, các nhiễu (*outlier*) cần phải được loại bỏ. Bước này được gọi là tiền xử lý (pre-processing). Hạn chế thứ hai của Linear Regression là nó **không biễu diễn được các mô hình phức tạp**. Mặc dù trong phần trên, chúng ta thấy rằng phương pháp này có thể được áp dụng nếu quan hệ giữa *outcome* và *input* không nhất thiết phải là tuyến tính, nhưng mối quan hệ này vẫn đơn giản nhiều so với các mô hình thực tế. Hơn nữa, chúng ta sẽ tự hỏi: làm thế nào để xác định được các hàm \\(x\\_1^2, \\sin(x\\_2), x\\_1x\\_2\\) như ở trên?!",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-23",
        "source": "44.main.md",
        "section": "4.3. Các phương pháp tối ưu",
        "content": "Linear Regression là một mô hình đơn giản, lời giải cho phương trình đạo hàm bằng 0 cũng khá đơn giản. *Trong hầu hết các trường hợp, chúng ta không thể giải được phương trình đạo hàm bằng 0.* Nhưng có một điều chúng ta nên nhớ, **còn tính được đạo hàm là còn có hy vọng**.",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "44.main-24",
        "source": "44.main.md",
        "section": "5. Tài liệu tham khảo",
        "content": "1. [Linear Regression - Wikipedia](https://en.wikipedia.org/wiki/Linear_regression) 2. [Simple Linear Regression Tutorial for Machine Learning](http://machinelearningmastery.com/simple-linear-regression-tutorial-for-machine-learning/) 3. [Least Squares, Pseudo-Inverses, PCA & SVD](http://www.sci.utah.edu/~gerig/CS6640-F2012/Materials/pseudoinverse-cis61009sl10.pdf)",
        "url": "https://machinelearningcoban.com/2016/12/28/linearregression/"
    },
    {
        "id": "19.main-1",
        "source": "19.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Mối quan hệ giữa PCA và SVD](#-moi-quan-he-giua-pca-va-svd) + [1.1. SVD cho bài toán xấp xỉ low-rank tốt nhất](#-svd-cho-bai-toan-xap-xi-low-rank-tot-nhat) + [1.2. Ý tưởng của PCA](#-y-tuong-cua-pca) + [1.3. Quan hệ giữa PCA và SVD](#-quan-he-giua-pca-va-svd) * [2. Làm thế nào để chọn chiều của dữ liệu mới](#-lam-the-nao-de-chon-chieu-cua-du-lieu-moi) * [3. Lưu ý về tính PCA trong các bài toán thực tế](#-luu-y-ve-tinh-pca-trong-cac-bai-toan-thuc-te) + [3.1. Số chiều dữ liệu nhiều hơn số điểm dữ liệu](#-so-chieu-du-lieu-nhieu-hon-so-diem-du-lieu) - [3.2. Chuẩn hoá các vector riêng](#-chuan-hoa-cac-vector-rieng) + [3.3. Với các bài toán large-scale](#-voi-cac-bai-toan-large-scale) * [4. Ví dụ trên Python](#-vi-du-tren-python) + [4.1. Eigenface](#-eigenface) + [4.2. Unsupervised Abnormal Detection](#--unsupervised-abnormal-detection) * [5. Thảo luận](#-thao-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao) Trong [phần 1 của Principal Component Analysis](/2017/06/15/pca/) (PCA), một phương pháp giảm chiều dữ liệu rất quan trọng, chúng ta đã cùng ôn lại một vài kiến thức về Đại số tuyến tính và Thống kê, đồng thời, ý nghĩa toán học và các bước thực hiện PCA cũng đã được trình bày. Trong phần 2 này, chúng ta cùng tìm hiểu thêm một vài tính chất quan trọng của PCA cũng như các ứng dụng nổi bật của PCA trong các bài toán Machine Learning. *Các bạn được khuyến khích đọc [Bài 26](/2017/06/07/svd/) và [Bài 27](/2017/06/15/pca/) trước khi đọc bài này.*",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-2",
        "source": "19.main.md",
        "section": "1. Mối quan hệ giữa PCA và SVD",
        "content": "Giữa PCA và SVD có mỗi quan hệ đặc biệt với nhau. Để nhận ra điều này, tôi xin được nhắc lại hai điểm đã trình bày sau đây:",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-3",
        "source": "19.main.md",
        "section": "1.1. SVD cho bài toán xấp xỉ low-rank tốt nhất",
        "content": "Nghiệm \\(\\mathbf{A}\\) của bài toán xấp xỉ một ma trận bởi một ma trận khác có rank không vượt quá \\(k\\): \\[ \\begin{eqnarray} \\min\\_{\\mathbf{A}} &&||\\mathbf{X} - \\mathbf{A}||\\_F ~~~~~~~~~~~~~~ (1)\\newline \\text{s.t.} && \\text{rank}(\\mathbf{A}) = K \\end{eqnarray} \\] chính là [Truncated SVD](https://machinelearningcoban.com/2017/06/07/svd/#-truncated-svd) của \\(\\mathbf{A}\\). Cụ thể, nếu SVD của \\(\\mathbf{X} \\in\\mathbb{R}^{D\\times N}\\) là: \\[ \\mathbf{X} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^T \\] với \\(\\mathbf{U} \\in \\mathbb{R}^{D \\times D}\\) và \\(\\mathbf{V}\\in \\mathbb{R}^{N\\times N}\\) là các ma trận trực giao, và \\(\\mathbf{\\Sigma} \\in \\mathbb{R}^{D \\times N}\\) là ma trận đường chéo (không nhất thiết vuông) với các phần tử trên đường chéo không âm giảm dần, thì nghiệm của bài toán \\((1)\\) chính là: \\[ \\mathbf{A} = \\mathbf{U}\\_K \\mathbf{\\Sigma}\\_K \\mathbf{V}\\_K^T ~~~ (2) \\] với \\(\\mathbf{U} \\in \\mathbb{R}^{D \\times K}\\) và \\(\\mathbf{V}\\in \\mathbb{R}^{N\\times K}\\) là các ma trận tạo bởi \\(K\\) cột đầu tiên của \\(\\mathbf{U}\\) và \\(\\mathbf{V}\\), và \\(\\mathbf{\\Sigma}\\_K \\in \\mathbb{R}^{K \\times K}\\) là ma trận đường chéo con ứng với \\(K\\) hàng đầu tiên và \\(K\\) cột đầu tiên của \\(\\mathbf{\\Sigma}\\).",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-4",
        "source": "19.main.md",
        "section": "1.2. Ý tưởng của PCA",
        "content": "Trong PCA, như đã chứng minh ở [biểu thức \\((10)\\) trong Bài 27](/2017/06/15/pca/#eqn10), PCA là bài toán đi tìm ma trận trực giao \\(\\mathbf{U}\\) và ma trận mô tả dữ liệu ở không gian thấp chiều \\(\\mathbf{Z}\\) sao cho việc xấp xỉ sau đây là tốt nhất: \\[ \\mathbf{X} \\approx \\tilde{\\mathbf{X}} = \\mathbf{U}\\_K \\mathbf{Z} + \\bar{\\mathbf{U}}\\_K \\bar{\\mathbf{U}}\\_K^T\\bar{\\mathbf{x}}\\mathbf{1}^T ~~~ (3) \\] với \\(\\mathbf{U}\\_K, \\bar{\\mathbf{U}}\\_K\\) lần lượt là các ma trận được tạo bởi \\(K\\) cột đầu tiên và \\(D-K\\) cột cuối cùng của ma trận trực giao \\(\\mathbf{U}\\), và \\(\\bar{\\mathbf{x}}\\) là vector kỳ vọng của dữ liệu. **Giả sử rằng vector kỳ vọng \\(\\bar{\\mathbf{x}} = \\mathbf{0}\\)**. Khi đó, \\((3)\\) tương đương với: \\[ \\mathbf{X} \\approx \\tilde{\\mathbf{X}} = \\mathbf{U}\\_K \\mathbf{Z}~~~ (4) \\] Bài toán tối ưu của PCA sẽ trở thành: \\[ \\begin{eqnarray} \\mathbf{U}\\_K, \\mathbf{Z} &=& \\min\\_{\\mathbf{U}\\_K, \\mathbf{Z} } ||\\mathbf{X} - \\mathbf{U}\\_K \\mathbf{Z}||\\_F& (5)\\newline \\text{s.t.:}&& \\mathbf{U}\\_K^T \\mathbf{U}\\_K = \\mathbf{I}\\_K & \\end{eqnarray} \\] với \\(\\mathbf{I}\\_K \\in \\mathbb{R}^{K\\times K}\\) là ma trận đơn vị trong không gian \\(K\\) chiều, và điều kiện ràng buộc là để đảm bảo các cột của \\(\\mathbf{U}\\_K\\) tạo thành một hệ trực chuẩn.",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-5",
        "source": "19.main.md",
        "section": "1.3. Quan hệ giữa PCA và SVD",
        "content": "Bạn có nhận ra điểm tương đồng giữa hai bài toán tối ưu \\((1)\\) và \\((5)\\) với nghiệm của bài toán đầu tiên được cho trong \\((2)\\)? Bạn có thể nhận ra ngay nghiệm của bài toán \\((5)\\) chính là: \\[ \\begin{eqnarray} \\mathbf{U}\\_K \\quad \\text{in}\\quad (5) &=& \\mathbf{U}\\_K\\quad \\text{in} \\quad(2) \\newline \\mathbf{Z} \\quad\\text{in}\\quad (5) &=& \\mathbf{\\Sigma}\\_K \\mathbf{V}\\_K^T \\quad \\text{in} \\quad (2) \\end{eqnarray} \\] Như vậy, nếu các điểm dữ liệu được biễu diễn bởi các cột của một ma trận, và trung bình cộng của mỗi hàng của ma trận đó bằng 0 (để cho vector kỳ vọng bằng 0), thì nghiệm của bài toán PCA được rút ra trực tiếp từ Truncated SVD của ma trận đó. Nói cách khác, nghiệm của PCA chính là một trường hợp đặc biệt của bài toán Matrix Factorization giải bằng SVD.",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-6",
        "source": "19.main.md",
        "section": "2. Làm thế nào để chọn chiều của dữ liệu mới",
        "content": "Một câu hỏi được đặt ra là, làm thế nào để chọn ra giá trị \\(K\\) - chiều của dữ liệu mới - với từng loại dữ liệu khác nhau? Có một cách xác định \\(K\\) là dựa trên việc *lượng thông tin muốn giữ lại*. Như đã trình bày, PCA còn được gọi là phương pháp tối đa *tổng phương sai được giữ lại*. Vậy ta có thể coi tổng các phương sai được giữ lại là lượng thông tin được giữ lại. Với phương sai càng lớn, tức dữ liệu có độ phân tán cao, thể hiện lượng thông tin càng lớn. Nhắc lại rằng trong mọi hệ trục toạ độ, tổng phương sai của dữ liệu là như nhau và bằng tổng các trị riêng của ma trận hiệp phương sai \\(\\sum\\_{i=1}^D \\lambda\\_i\\). Thêm nữa, PCA giúp giữ lại lượng thông tin (tổng các phương sai) là: \\(\\sum\\_{i=1}^K \\lambda\\_i\\). Vậy ta có thể coi biểu thức: \\[ r\\_K = \\frac{\\sum\\_{i=1}^K \\lambda\\_i}{\\sum\\_{j=1}^D \\lambda\\_j} \\quad \\quad (6) \\] là lượng thông tin được giữ lại khi số chiều dữ liệu mới sau PCA là \\(K\\). Như vậy, giả sử ta muốn giữ lại 99% dữ liệu, ta chỉ cần chọn \\(K\\) là số tự nhiên nhỏ nhất sao cho \\(r\\_K \\geq 0.99\\). Khi dữ liệu phân bố quanh một không gian con, các giá trị phương sai lớn nhất ứng với các \\(\\lambda\\_i\\) đầu tiên lớn hơn nhiều so với các phương sai còn lại. Khi đó, ta có thể chọn được \\(K\\) khá nhỏ để đạt được \\(r\\_K \\geq 0.99\\).",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-7",
        "source": "19.main.md",
        "section": "3. Lưu ý về tính PCA trong các bài toán thực tế",
        "content": "Có hai trường hợp trong thực tế mà chúng ta cần lưu ý về PCA. Trường hợp thứ nhất là lượng dữ liệu có được nhỏ hơn rất nhiều so với số chiều dữ liệu. Trường hợp thứ hai là khi lượng dữ liệu trong tập training là rất lớn, có thể lên tới cả triệu. Việc tính toán ma trận hiệp phương sai và trị riêng đôi khi trở nên bất khả thi. Có những hướng giải quyết hiệu quả cho các trường hợp này. **Trong mục này, ta sẽ coi như dữ liệu đã được chuẩn hoá, tức đã được trừ đi vector kỳ vọng. Khi đó, ma trận hiệp phương sai sẽ là \\(\\mathbf{S} = \\frac{1}{N}\\mathbf{X}\\mathbf{X}^T\\).**",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-8",
        "source": "19.main.md",
        "section": "3.1. Số chiều dữ liệu nhiều hơn số điểm dữ liệu",
        "content": "Đó là trường hợp \\(D > N\\), tức ma trận dữ liệu \\(\\mathbf{X}\\) là một ‘ma trận cao’. Khi đó, số trị riêng khác không của ma trận hiệp phương sai \\(\\mathbf{S}\\) sẽ không vượt quá rank của nó, tức không vượt quá \\(N\\). Vậy ta cần chọn \\(K \\leq N\\) vì không thể chọn ra được \\(K > N\\) trị riêng khác 0 của một ma trận có rank bằng \\(N\\). Việc tính toán các trị riêng và vector riêng cũng có thể được thực hiện một cách hiệu quả dựa trên các tính chất sau đây: **Tính chất 1:** Trị riêng của \\(\\mathbf{A}\\) cũng là trị riêng của \\(k\\mathbf{A}\\) với \\(k \\neq 0\\) bất kỳ. Điều này có thể được suy ra trực tiếp từ định nghĩa của trị riêng và vector riêng. **Tính chât 2:** Trị riêng của \\(\\mathbf{AB}\\) cũng là trị riêng của \\(\\mathbf{BA}\\) với \\(\\mathbf{A} \\in \\mathbb{R}^{d\\_1 \\times d\\_2}, \\mathbf{B} \\in \\mathbb{R} ^{d\\_2 \\times d\\_1}\\) là các ma trận bất kỳ và \\(d\\_1, d\\_2\\) là các số tự nhiên khác không bất kỳ. Tôi xin không chứng minh quan sát này. Như vậy, thay vì tìm trị riêng của ma trận hiệp phương sai \\(\\mathbf{S} \\in \\mathbb{R}^{D\\times D}\\), ta đi tìm trị riêng của ma trận \\(\\mathbf{T} = \\mathbf{X}^T \\mathbf{X} \\in \\mathbb{R}^{N \\times N}\\) có số chiều nhỏ hơn (vì \\(N < D\\)). **Tính chất 3:** Giả sử \\((\\lambda, \\mathbf{u})\\) là một cặp trị riêng - vector riêng của \\(\\mathbf{T}\\), thế thì \\((\\lambda, \\mathbf{Xu})\\) là một cặp trị riêng - vector riêng của \\(\\mathbf{S}\\). Thật vậy: \\[ \\begin{eqnarray} \\mathbf{X}^T \\mathbf{Xu} &=& \\lambda \\mathbf{u}& \\quad (7) \\newline \\Rightarrow (\\mathbf{X}\\mathbf{X}^T)(\\mathbf{Xu}) &=& \\lambda \\mathbf{Xu} & \\quad (8) \\end{eqnarray} \\] Biểu thức \\((7)\\) là theo định nghĩa của trị riêng và vector riêng. Biểu thức \\((8)\\) thu được từ \\((7)\\) bằng cách nhân bên trái cả hai vế với ma trận \\(\\mathbf{X}\\). Từ \\((8)\\) ta suy ra **Quan sát 3**. Như vậy, ta có thể hoàn toàn tính được trị riêng và vector riêng của ma trận hiệp phương sai dựa trên một ma trận nhỏ hơn.",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-9",
        "source": "19.main.md",
        "section": "3.2. Chuẩn hoá các vector riêng",
        "content": "*Nhắc lại định nghĩa không gian riêng: Không gian riêng ứng với trị riêng của một ma trận là không gian sinh (span subspace) tạo bởi toàn bộ các vector riêng ứng với trị riêng đó.* Việc cuối cùng phải làm là chuẩn hoá các vector riêng tìm được sao cho chúng tạo thành một hệ trực chuẩn. Việc này có thể dựa trên hai điểm sau đây: **Thứ nhất**, nếu \\(\\mathbf{A}\\) là một ma trận đối xứng, \\((\\lambda\\_1, \\mathbf{x}\\_1), (\\lambda\\_2, \\mathbf{x}\\_2)\\) là các căp trị riêng - vector riêng của \\(\\mathbf{A}\\) với \\(\\lambda\\_1 \\neq \\lambda\\_2\\), thế thì \\(\\mathbf{x}\\_1^T\\mathbf{x}\\_2 = 0\\). Nói cách khác, hai vector bất kỳ trong hai không gian riêng khác nhau của một ma trận đối xứng thì trực giao với nhau. Chứng minh cho tính chất này có thể được thấy trong một dòng dưới đây: \\[ \\begin{eqnarray} \\mathbf{x}\\_2^T \\mathbf{Ax}\\_1 = \\mathbf{x}\\_1^T \\mathbf{Ax}\\_2 = \\lambda\\_1 \\mathbf{x}\\_2^T \\mathbf{x}\\_1 = \\lambda\\_2 \\mathbf{x}\\_1^T \\mathbf{x}\\_2 \\Rightarrow \\mathbf{x}\\_1^T \\mathbf{x}\\_2 = 0 \\end{eqnarray} \\] Dấu bằng cuối cùng xảy ra vì \\(\\lambda\\_1 \\neq \\lambda\\_2\\). **Thứ hai**, với các trị riêng độc lập tìm được trong một không gian riêng, ta có thể dùng Gram-Schmit process để chuẩn hoá chúng về một hệ trực chuẩn. Kết hợp hai điểm trên, ta có thể thu được các vector riêng tạo thành một hệ trực chuẩn, chính là ma trận \\(\\mathbf{U}\\_K\\) trong PCA.",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "19.main-10",
        "source": "19.main.md",
        "section": "3.3. Với các bài toán large-scale",
        "content": "Trong rất nhiều bài toán, cả \\(D\\) và \\(N\\) đều là các số rất lớn, đồng nghĩa với việc ta phải tìm trị riêng cho một ma trận rất lớn. Ví dụ, có 1 triệu bức ảnh 1000 \\(\\times\\) 1000 pixel, như vậy \\(D = N = 10^6\\) là một số rất lớn, việc trực tiếp tính toán trị riêng và vector riêng cho ma trận hiệp phương sai là không khả thi. Tuy nhiên, có một phương pháp cho phép tính xấp xỉ các giá trị này một cách nhanh hơn. Phương pháp đó có tên là [Power Method](http://www.cs.huji.ac.il/~csip/tirgul2.pdf). Phương pháp này nói rằng, nếu thực hiện quy trình sau, ta sẽ tìm được cặp trị riêng và vector đầu tiên của một ma trận nửa xác định dương: --- **Phương pháp Power tìm trị riêng và vector riêng của một ma trận nửa xác định dương \\(\\mathbf{A} \\in \\mathbb{R}^{n \\times n}\\)**: 1. Chọn một vector \\(\\mathbf{q}^{(0)} \\in \\mathbb{R}^n, ||\\mathbf{q}^{(0)}||\\_2 = 1\\) bất kỳ. 2. Với \\(k = 1, 2, \\dots\\), tính: \\(\\mathbf{z} = \\mathbf{Aq}^{(k-1)}\\). 3. Chuẩn hoá: \\(\\mathbf{q}^{(k)} = \\mathbf{z} / ||\\mathbf{z}||\\_2\\). 4. Nếu \\(||\\mathbf{q}^{(k)} - \\mathbf{q}^{(k-1)}||\\_2\\) đủ nhỏ thì dừng lại. Nếu không, \\(k := k + 1\\) rồi quay lại Bước 2. 5. \\(\\mathbf{q}^{(k)}\\) chính là vector riêng ứng với trị riêng lớn nhất \\(\\lambda\\_1 = (\\mathbf{q}^{(k)})^T\\mathbf{A}\\mathbf{q}^{(k)}\\). ---",
        "url": "https://machinelearningcoban.com/2017/06/21/pca2/"
    },
    {
        "id": "3.main-1",
        "source": "3.main.md",
        "section": "Introduction",
        "content": "*Bài viết này được thực hiện với sự đóng góp của Nguyễn Tiến Cường, Cao Thanh Hà, Đinh Duy Khánh, và Nguyễn Văn Tài. Các bạn này cũng sẽ giúp tôi trong các bài về deep learning tiếp theo.* Trong trang này: * [1. Giới thiệu](#-gioi-thieu) * [2. Linear regression và logistic regression với Keras](#-linear-regression-va-logistic-regression-voi-keras) + [2.1. Keras với linear regression](#-keras-voi-linear-regression) + [2.1. Keras với logistic regression](#-keras-voi-logistic-regression) * [3. Keras cho multi-layer perceptron](#-keras-cho-multi-layer-perceptron) + [3.1. Giới thiệu về Fashion-MNIST](#-gioi-thieu-ve-fashion-mnist) + [3.2. Xây dựng một multi-layer perceptron để giải quyết bài toán](#-xay-dung-mot-multi-layer-perceptron-de-giai-quyet-bai-toan) + [3.3. Nhận xét](#-nhan-xet) * [4. Kết luận](#-ket-luan) * [5. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2018/07/06/deeplearning/"
    },
    {
        "id": "3.main-2",
        "source": "3.main.md",
        "section": "1. Giới thiệu",
        "content": "Kể từ 2012 khi [deep learning có bước đột phá lớn](/2018/06/22/deeplearning/#dot-pha-), hàng loạt các thư viện hỗ trợ deep learning ra đời. Cùng với đó, ngày càng nhiều kiến trúc deep learning ra đời, khiến cho số lượng ứng dụng và các bài báo liên quan tới deep learning tăng lên chóng mặt. Các thư viện deep learning thường được ‘chống lưng’ bởi những hãng công nghệ lớn: Google (Keras, TensorFlow), Facebook (Caffe2, Pytorch), Microsoft (CNTK), Amazon (Mxnet), Microsoft và Amazon cũng đang bắt tay xây dựng Gluon (phiên bản tương tự như Keras). (Các hãng này đều có các dịch vụ cloud computing và muốn thu hút người dùng). --- ![](/assets/36_keras/dlp0.png) Các thư viện deep learning và các hãng công nghệ lớn. (Nguồn: [Battle of the Deep Learning frameworks — Part I: 2017, even more frameworks and interfaces](https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750)) ---",
        "url": "https://machinelearningcoban.com/2018/07/06/deeplearning/"
    },
    {
        "id": "10.main-1",
        "source": "10.main.md",
        "section": "Introduction",
        "content": "**Tất cả các bài tập trong bài viết này có thể được thực hiện trực tiếp trên trình duyện qua trang web [FundaML](https://fundaml.com)** * [0. Giới thiệu về Numpy](#-gioi-thieu-ve-numpy) + [0.1. Cài đặt Numpy](#-cai-dat-numpy) * [1.1 Khởi tạo mảng 1 chiều](#-khoi-tao-mang--chieu) + [1.1.1. Khai báo vector](#-khai-bao-vector) * [1.2. Kiểu dữ liệu của mảng](#-kieu-du-lieu-cua-mang) + [1.2.1. Kiểu dữ liệu](#-kieu-du-lieu) * [1.3. Khởi tạo các mảng một chiều đặc biệt](#-khoi-tao-cac-mang-mot-chieu-dac-biet) + [1.3.1. Mảng toàn giá trị 0 hoặc 1](#-mang-toan-gia-tri--hoac-) + [1.3.2. Cấp số cộng](#-cap-so-cong) * [1.4. Truy cập mảng một chiều](#-truy-cap-mang-mot-chieu) + [1.4.1. Kích thước của mảng](#-kich-thuoc-cua-mang) + [1.4.2. Chỉ số](#-chi-so) + [1.4.3. Đọc từng phần tử của vector](#-doc-tung-phan-tu-cua-vector) + [1.4.4. Chỉ số ngược](#-chi-so-nguoc) + [1.4.5. Thay đổi giá trị một phần tử của mảng](#-thay-doi-gia-tri-mot-phan-tu-cua-mang) * [1.5. Truy cập nhiều phần tử của mảng một chiều](#-truy-cap-nhieu-phan-tu-cua-mang-mot-chieu) + [1.5.1. Đọc](#-doc) + [1.5.2. Ghi](#-ghi) + [1.5.3. Đọc thêm](#-doc-them) * [1.6. Tính toán giữa các mảng một chiều và số vô hướng](#-tinh-toan-giua-cac-mang-mot-chieu-va-so-vo-huong) + [1.6.1. Phép toán giữa mảng một chiều với một số vô hướng.](#-phep-toan-giua-mang-mot-chieu-voi-mot-so-vo-huong) + [1.6.2. Phép toán giữa hai mảng một chiều](#-phep-toan-giua-hai-mang-mot-chieu) + [1.6.3. Các hàm toán học](#-cac-ham-toan-hoc) * [1.7. Norm 1](#-norm-) * [1.8. Hàm Softmax cho mảng một chiều](#-ham-softmax-cho-mang-mot-chieu) * [1.9. Tích vô hướng của hai vectors - Norm 2](#-tich-vo-huong-cua-hai-vectors---norm-) * [1.10. min, max, armin, argmax của mảng một chiều](#-min-max-armin-argmax-cua-mang-mot-chieu) + [1.10.1. min, max](#-min-max) + [1.10.2. argmin, argmax](#-argmin-argmax) * [Softmax II - Phiên bản ổn định](#softmax-ii---phien-ban-on-dinh)",
        "url": "https://machinelearningcoban.com/2017/10/12/fundaml_vectors/"
    },
    {
        "id": "10.main-2",
        "source": "10.main.md",
        "section": "0. Giới thiệu về Numpy",
        "content": "Mặc dù các bài học trong khoá này có thể được thực hiện trực tiếp trên trình duyệt, tôi vẫn khuyến khích các bạn cài đặt Python và Numpy vào trong máy tính cá nhân để việc lập trình được thuận tiện hơn. Tôi giả sử các bạn đã từng sử dụng Python và có kiến thức cơ bản về Python. Nếu bạn chưa học Python bao giờ, dưới đây là một vài khoá học và trang web mà tôi thấy có chất lượng tốt: 1. [Introduction to Computer Science and Programming Using Python](https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x-10) 2. [learnpython.org](https://www.learnpython.org/) **Chú ý rằng phiên bản Python được sử dụng ở đây là Python 3.**",
        "url": "https://machinelearningcoban.com/2017/10/12/fundaml_vectors/"
    },
    {
        "id": "10.main-3",
        "source": "10.main.md",
        "section": "0.1. Cài đặt Numpy",
        "content": "Numpy là một thư viện của Python hỗ trợ cho việc tính toán các mảng nhiều chiều, có kích thước lớn với các hàm số đã được tối ưu áp dụng lên các mảng nhiều chiều đó. Numpy đặc biệt hữu ích khi thực hiện các hàm số liên quan tới Đại Số Tuyến Tính. *Bạn đọc có thể tham khảo [tài liệu về numpy.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiJpuTO-NTVAhWCUBQKHdmqDJ0QFggoMAA&url=http%3A%2F%2Fwww.numpy.org%2F&usg=AFQjCNEN-XKZnvvnUV0ZkdbbQbR-GHVEzg)* Để cài đặt Numpy và các thư viện thường dùng trong Machine Learning, bạn có thể tham khảo các bài hướng dẫn bằng Tiếng Việt dưới đây: * [Hướng dẫn cài đặt python và các thư viện trên MacOS và Linux](https://machinelearningcoban.com/faqs/#-huong-dan-cai-dat-python-va-cac-thu-vien-tren-macos) * [Hướng dẫn cài đặt python và các thư viện trên Windows](https://machinelearningcoban.com/faqs/#-huong-dan-cai-dat-python-va-cac-thu-vien-tren-windows) Sau khi cài đặt xong, trong Python, chúng ta cần khai báo: ``` import numpy ``` để có thể bắt đầu sử dụng các hàm số của numpy. Vì numpy là thư viện được sử dụng thường xuyên nên nó thường được khai báo gọn lại thành `np`: ``` import numpy as np ``` `np` có thể thay bằng các từ khác (không phải từ khoá), tuy nhiên, bạn được khuyến khích đặt là `np` vì các tài liệu hướng dẫn đều ngầm quy ước với nhau như thế. **Có một điểm đặc biệt cần lưu ý: biến numpy là các biến *mutable*. Bạn cần phân biệt rõ biến [mutable và immutable trong Python](https://en.wikibooks.org/wiki/Python_Programming/Data_Types#Mutable_vs_Immutable_Objects).** Tiếp theo, chúng ta sẽ làm quen với cách sử dụng numpy từ đơn giản tới ít đơn giản hơn. Các bạn có thể di chuyển giữa các bài học thông qua nút “Lesson Outline” và hai nút điều hướng ở đầu trang [FundaML](https://fundaml.com).",
        "url": "https://machinelearningcoban.com/2017/10/12/fundaml_vectors/"
    },
    {
        "id": "10.main-4",
        "source": "10.main.md",
        "section": "1.1.1. Khai báo vector",
        "content": "Trong Numpy, vector được hiểu là một mảng 1 chiều. Ví dụ: để có một vector `x = [1, 2, 3]`, chúng ta thực hiện như sau: ``` >>> x = np.array([1, 2, 3]) >>> x array([1, 2, 3]) ``` **Chúng ta ngầm hiểu rằng thư viện numpy đã được khai báo bởi:** `import numpy as np`. Các dòng *không* bắt đầu với `>>>` là các dòng hiển thị đầu ra. Xin nhắc lại, Numpy không quy ước vector hàng hay vector cột mà chỉ coi một vector là một mảng một chiều. Nếu bạn thực sự muốn có một vector cột, bạn cần phải coi nó là một ma trận có số chiều thứ hai bằng 1, và khi đó phải khai báo với numpy rằng đó là một mảng hai chiều. Chúng ta sẽ quay lại vấn đề này trong bài Ma trận. Để hiểu thêm về hàm`np.array`, bạn có thể xem thêm [numpy.array](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html), hoặc gõ trực tiếp vào cửa sổ dòng lệnh: ``` >>> help(np.array) ``` Cú pháp `help(func)` khi được thực hiện trên cửa sổ dòng lệnh (terminal), với `func` là tên hàm số, sẽ hiển thị hướng dẫn sử dụng hàm số đó. --- > **Bài tập**: Khởi tạo một vector `x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`. Chú ý chỉ sửa code giữa các dòng bắt đầu bởi `# TODO:` và `# -- end TODO --`. ---",
        "url": "https://machinelearningcoban.com/2017/10/12/fundaml_vectors/"
    },
    {
        "id": "2.main-1",
        "source": "2.main.md",
        "section": "Introduction",
        "content": "Chào các bạn, Sau một khảo sát nhỏ trên Facebook Group ‘Forum Machine Learning cơ bản’, tôi thấy nhiều ý kiến cho rằng nên chọn một nền tảng thảo luận khác tốt hơn Facebook. Nền tảng này nên hỗ trợ việc trình bày các ý tưởng một cách chuyêu sâu và sắp xếp các câu hỏi/hướng dẫn theo đề mục. Tôi và một vài người bạn đã quyết định tạo [Diễn đàn Machine Learning cơ bản](https://forum.machinelearningcoban.com) cho cộng đồng. Về lâu dài, đây sẽ là một nền tảng tốt cho việc thảo luận. Hiện đã có trên 1000 thành viên đăng ký và nhiều chủ để thú vị. Mời các bạn tham gia chia sẻ ý kiến và đặt các câu hỏi. Chúc một ngày tốt lành",
        "url": "https://machinelearningcoban.com/2018/09/11/forum/"
    },
    {
        "id": "11.main-1",
        "source": "11.main.md",
        "section": "Introduction",
        "content": "Giới thiệu trang web [FundaML.com](https://fundaml.com). Tôi vẫn thường nói rằng: Đại Số Tuyến Tính, Xác Suất Thống Kê và lập trình là ba vấn đề quan trọng nhất các bạn cần nắm vững nếu muốn đi sâu vào Machine Learning. Về lập trình, hiện có rất nhiều ngôn ngữ khác nhau có các thư viện hỗ trợ Machine Learning. Tuy nhiên, dựa trên kinh nghiệm cá nhân, tôi thấy rằng Python là ngôn ngữ được sử dụng phổ biến nhất vì có nhiều thư viện hỗ trợ rất tốt cho Machine Learning và Data Science: * scipy, numpy cho tính toán khoa học với mảng nhiều chiều * sklearn cho các thuật toán Machine Learning cơ bản * tensorflow, pytorch, keras, theano, … cho các thuật toán Deep Learning * pandas cho xử lý dữ liệu dạng bảng * … Đó cũng là lý do mà các bài viết trong blog machinelearningcoban.com đều sử dụng các ví dụ được viết bằng Python. Theo dõi comment của các bạn trên cả blog, page và forum, tôi nhận thấy rằng rất nhiều bạn còn gặp khó khăn trong Đại Số Tuyến Tính và lập trình Python. Việc này thôi thúc tôi tạo một trang web giúp các bạn làm quen dần với lập trình Python cho Machine Learning thông qua việc thực hành các bài tập nhỏ trực tiếp trên trình duyệt. Ban đầu, tôi xin bắt đầu với thư viện Numpy của Python. Đây là một thư viện quan trọng, được sử dụng rất nhiều cho việc xử lý các mảng dữ liệu nhiều chiều. Trong đây tôi cũng nhắc lại nhiều vấn đề của Đại Số Tuyến Tính thường được sử dụng trong Machine Learning. Hiện tại, tôi đã xây dựng được những bài học đầu tiên và sẽ tiếp tục thêm các bài trong thời gian tới. Rất hy vọng các bạn có thể vào học thử và đánh giá nội dung cũng như trang web. Tôi hy vọng trang web ngày một hoàn thiện và giúp đỡ được nhiều sinh viên, kỹ sư Việt Nam khác. FundaML.com cũng nằm trong dự án viết [ebook Machine Learning cơ bản](https://machinelearningcoban.com/ebook/) của tôi. Một phần kinh phí trong dự án đã được dùng để xây dựng và duy trì trang web mới này. Tôi xin chân thành cảm ơn Huy Hoàng, Linh Nguyễn (Đại học Waterloo - Canada) đã nhiệt tình giúp đỡ xây dựng FundaML.com để nó được ra mắt ngày hôm nay. Chúc các bạn cuối tuần vui vẻ.",
        "url": "https://machinelearningcoban.com/2017/09/24/fundaml/"
    },
    {
        "id": "37.main-1",
        "source": "37.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [1. Giới thiệu](#-gioi-thieu) + [Nhắc lại hai mô hình tuyến tính](#nhac-lai-hai-mo-hinh-tuyen-tinh) + [Một ví dụ nhỏ](#mot-vi-du-nho) + [Mô hình Logistic Regression](#mo-hinh-logistic-regression) + [Sigmoid function](#sigmoid-function) * [2. Hàm mất mát và phương pháp tối ưu](#-ham-mat-mat-va-phuong-phap-toi-uu) + [Xây dựng hàm mất mát](#xay-dung-ham-mat-mat) + [Tối ưu hàm mất mát](#toi-uu-ham-mat-mat) + [Công thức cập nhật cho logistic sigmoid regression](#cong-thuc-cap-nhat-cho-logistic-sigmoid-regression) * [3. Ví dụ với Python](#-vi-du-voi-python) + [Ví dụ với dữ liệu 1 chiều](#vi-du-voi-du-lieu--chieu) + [Các hàm cần thiết cho logistic sigmoid regression](#cac-ham-can-thiet-cho-logistic-sigmoid-regression) + [Ví dụ với dữ liệu 2 chiều](#vi-du-voi-du-lieu--chieu-1) * [4. Một vài tính chất của Logistic Regression](#-mot-vai-tinh-chat-cua-logistic-regression) + [Logistic Regression thực ra được sử dụng nhiều trong các bài toán Classification.](#logistic-regression-thuc-ra-duoc-su-dung-nhieu-trong-cac-bai-toan-classification) + [Boundary tạo bởi Logistic Regression có dạng tuyến tính](#boundary-tao-boi-logistic-regression-co-dang-tuyen-tinh) * [5. Thảo luận](#-thao-luan) * [6. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-2",
        "source": "37.main.md",
        "section": "Nhắc lại hai mô hình tuyến tính",
        "content": "Hai mô hình tuyến tính (linear models) [Linear Regression](/2016/12/28/linearregression/) và [Perceptron Learning Algorithm](/2017/01/21/perceptron/) (PLA) chúng ta đã biết đều có chung một dạng: \\[ y = f(\\mathbf{w}^T\\mathbf{x}) \\] trong đó \\(f()\\) được gọi là *activation function*, và \\(\\mathbf{x}\\) được hiểu là dữ liệu mở rộng với \\(x\\_0 = 1\\) được thêm vào để thuận tiện cho việc tính toán. Với linear regression thì \\(f(s) = s\\), với PLA thì \\(f(s) = \\text{sgn}(s)\\). Trong linear regression, tích vô hướng \\(\\mathbf{w}^T\\mathbf{x}\\) được trực tiếp sử dụng để dự đoán output \\(y\\), loại này phù hợp nếu chúng ta cần dự đoán một giá trị thực của đầu ra không bị chặn trên và dưới. Trong PLA, đầu ra chỉ nhận một trong hai giá trị \\(1\\) hoặc \\(-1 \\), phù hợp với các bài toán *binary classification*. Trong bài này, tôi sẽ giới thiệu mô hình thứ ba với một activation khác, được sử dụng cho các bài toán *flexible* hơn. Trong dạng này, đầu ra có thể được thể hiện dưới dạng xác suất (probability). Ví dụ: xác suất thi đỗ nếu biết thời gian ôn thi, xác suất ngày mai có mưa dựa trên những thông tin đo được trong ngày hôm nay,… Mô hình mới này của chúng ta có tên là *logistic regression*. Mô hình này giống với linear regression ở khía cạnh đầu ra là số thực, và giống với PLA ở việc đầu ra bị chặn (trong đoạn \\([0, 1]\\)). Mặc dù trong tên có chứa từ *regression*, logistic regression thường được sử dụng nhiều hơn cho các bài toán classification.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-3",
        "source": "37.main.md",
        "section": "Một ví dụ nhỏ",
        "content": "Tôi xin được sử dụng [một ví dụ trên Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression): > Một nhóm 20 sinh viên dành thời gian trong khoảng từ 0 đến 6 giờ cho việc ôn thi. Thời gian ôn thi này ảnh hưởng đến xác suất sinh viên vượt qua kỳ thi như thế nào? Kết quả thu được như sau: | Hours | Pass | Hours | Pass | | --- | --- | --- | --- | | .5 | 0 | 2.75 | 1 | | .75 | 0 | 3 | 0 | | 1 | 0 | 3.25 | 1 | | 1.25 | 0 | 3.5 | 0 | | 1.5 | 0 | 4 | 1 | | 1.75 | 0 | 4.25 | 1 | | 1.75 | 1 | 4.5 | 1 | | 2 | 0 | 4.75 | 1 | | 2.25 | 1 | 5 | 1 | | 2.5 | 0 | 5.5 | 1 | Mặc dù có một chút *bất công* khi học 3.5 giờ thì trượt, còn học 1.75 giờ thì lại đỗ, nhìn chung, học càng nhiều thì khả năng đỗ càng cao. PLA không thể áp dụng được cho bài toán này vì không thể nói một người học bao nhiêu giờ thì 100% trượt hay đỗ, và thực tế là dữ liệu này cũng không *linearly separable* (điệu kiện để PLA có thể làm việc). Chú ý rằng các điểm màu đỏ và xanh được vẽ ở hai tung độ khác nhau để tiện cho việc minh họa. Các điểm này được vẽ dùng cả dữ liệu đầu vào \\(\\mathbf{x}\\) và đầu ra \\(y). Khi ta nói *linearly seperable* là khi ta chỉ dùng dữ liệu đầu vào \\(\\mathbf{x}\\). Chúng ta biểu diễn các điểm này trên đồ thị để thấy rõ hơn: ![](\\assets\\LogisticRegression\\ex1.png) Hình 1: Ví dụ về kết quả thi dựa trên số giờ ôn tập. Nhận thấy rằng cả linear regression và PLA đều không phù hợp với bài toán này, chúng ta cần một mô hình *flexible* hơn.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-4",
        "source": "37.main.md",
        "section": "Mô hình Logistic Regression",
        "content": "Đầu ra dự đoán của: * Linear Regression: \\[ f(\\mathbf{x}) = \\mathbf{w}^T \\mathbf{x} \\] * PLA: \\[ f(\\mathbf{x}) = \\text{sgn}(\\mathbf{w}^T\\mathbf{x}) \\] Đầu ra dự đoán của logistic regression thường được viết chung dưới dạng: \\[ f(\\mathbf{x}) = \\theta(\\mathbf{w}^T\\mathbf{x}) \\] Trong đó \\(\\theta\\) được gọi là logistic function. Một số activation cho mô hình tuyến tính được cho trong hình dưới đây: ![](\\assets\\LogisticRegression\\activation.png) Hình 2: Các activation function khác nhau. * Đường màu vàng biểu diễn linear regression. Đường này không bị chặn nên không phù hợp cho bài toán này. Có một *trick* nhỏ để đưa nó về dạng bị chặn: *cắt* phần nhỏ hơn 0 bằng cách cho chúng bằng 0, *cắt* các phần lớn hơn 1 bằng cách cho chúng bằng 1. Sau đó lấy điểm trên đường thẳng này có tung độ bằng 0.5 làm điểm phân chia hai *class*, đây cũng không phải là một lựa chọn tốt. Giả sử có thêm vài bạn *sinh viên tiêu biểu* ôn tập đến 20 giờ và, tất nhiên, thi đỗ. Khi áp dụng mô hình linear regression như hình dưới đây và lấy mốc 0.5 để phân lớp, toàn bộ sinh viên thi trượt vẫn được dự đoán là trượt, nhưng rất nhiều sinh viên thi đỗ cũng được dự đoán là trượt (nếu ta coi điểm x màu xanh lục là *ngưỡng cứng* để đưa ra kết luận). Rõ ràng đây là một mô hình không tốt. Anh chàng sinh viên tiêu biểu này đã *kéo theo* rất nhiều bạn khác bị trượt. ![](\\assets\\LogisticRegression\\ex1_lr.png) Hình 3: Tại sao Linear Regression không phù hợp? * Đường màu đỏ (chỉ khác với activation function của PLA ở chỗ hai class là 0 và 1 thay vì -1 và 1) cũng thuộc dạng *ngưỡng cứng* (hard threshold). PLA không hoạt động trong bài toán này vì dữ liệu đã cho không *linearly separable*. * Các đường màu xanh lam và xanh lục phù hợp với bài toán của chúng ta hơn. Chúng có một vài tính chất quan trọng sau: + Là hàm số liên tục nhận giá trị thực, bị chặn trong khoảng \\((0, 1)\\). + Nếu coi điểm có tung độ là 1/2 làm điểm phân chia thì các điểm càng xa điểm này về phía bên trái có giá trị càng gần 0. Ngược lại, các điểm càng xa điểm này về phía phải có giá trị càng gần 1. Điều này *khớp* với nhận xét rằng học càng nhiều thì xác suất đỗ càng cao và ngược lại. + *Mượt* (smooth) nên có đạo hàm mọi nơi, có thể được lợi trong việc tối ưu.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-5",
        "source": "37.main.md",
        "section": "Sigmoid function",
        "content": "Trong số các hàm số có 3 tính chất nói trên thì hàm *sigmoid*: \\[ f(s) = \\frac{1}{1 + e^{-s}} \\triangleq \\sigma(s) \\] được sử dụng nhiều nhất, vì nó bị chặn trong khoảng \\((0, 1)\\). Thêm nữa: \\[ \\lim\\_{s \\rightarrow -\\infty}\\sigma(s) = 0; ~~ \\lim\\_{s \\rightarrow +\\infty}\\sigma(s) = 1 \\] Đặc biệt hơn nữa: \\[ \\begin{eqnarray} \\sigma’(s) &=& \\frac{e^{-s}}{(1 + e^{-s})^2} \\newline &=& \\frac{1}{1 + e^{-s}} \\frac{e^{-s}}{1 + e^{-s}} \\newline &=& \\sigma(s)(1 - \\sigma(s)) \\end{eqnarray} \\] Công thức đạo hàm đơn giản thế này giúp hàm số này được sử dụng rộng rãi. Ở phần sau, tôi sẽ lý giải việc *người ta đã tìm ra hàm số đặc biệt này như thế nào*. Ngoài ra, hàm *tanh* cũng hay được sử dụng: \\[ \\text{tanh}(s) = \\frac{e^{s} - e^{-s}}{e^s + e^{-s}} \\] Hàm số này nhận giá trị trong khoảng \\((-1, 1)\\) nhưng có thể dễ dàng đưa nó về khoảng \\((0, 1)\\). Bạn đọc có thể chứng minh được: \\[ \\text{tanh}(s) = 2\\sigma(2s) - 1 \\]",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-6",
        "source": "37.main.md",
        "section": "Xây dựng hàm mất mát",
        "content": "Với mô hình như trên (các activation màu xanh lam và lục), ta có thể giả sử rằng xác suất để một điểm dữ liệu \\(\\mathbf{x}\\) rơi vào class 1 là \\(f(\\mathbf{w}^T\\mathbf{x})\\) và rơi vào class 0 là \\(1 - f(\\mathbf{w}^T\\mathbf{x})\\). Với mô hình được giả sử như vậy, với các điểm dữ liệu training (đã biết đầu ra \\(y\\)), ta có thể viết như sau: \\[ \\begin{eqnarray} P(y\\_i = 1 | \\mathbf{x}\\_i; \\mathbf{w}) &=& &f(\\mathbf{w}^T\\mathbf{x}\\_i) ~~(1) \\newline P(y\\_i = 0 | \\mathbf{x}\\_i; \\mathbf{w}) &=& 1 - &f(\\mathbf{w}^T\\mathbf{x}\\_i) ~~(2) \\newline \\end{eqnarray} \\] trong đó \\( P(y\\_i = 1 | \\mathbf{x}\\_i; \\mathbf{w})\\) được hiểu là xác suất xảy ra sự kiện đầu ra \\(y\\_i = 1\\) khi biết tham số mô hình \\(\\mathbf{w}\\) và dữ liệu đầu vào \\(\\mathbf{x}\\_i\\). Bạn đọc có thể đọc thêm [Xác suất có điều kiện](https://vi.wikipedia.org/wiki/Xác_suất_có_điều_kiện). Mục đích của chúng ta là tìm các hệ số \\(\\mathbf{w}\\) sao cho \\(f(\\mathbf{w}^T\\mathbf{x}\\_i)\\) càng gần với 1 càng tốt với các điểm dữ liệu thuộc class 1 và càng gần với 0 càng tốt với những điểm thuộc class 0. Ký hiệu \\(z\\_i = f(\\mathbf{w}^T\\mathbf{x}\\_i)\\) và viết gộp lại hai biểu thức bên trên ta có: \\[ P(y\\_i| \\mathbf{x}\\_i; \\mathbf{w}) = z\\_i^{y\\_i}(1 - z\\_i)^{1- y\\_i} \\] Biểu thức này là tương đương với hai biểu thức \\((1)\\) và \\((2)\\) ở trên vì khi \\(y\\_i=1\\), phần thứ hai của vế phải sẽ triệt tiêu, khi \\(y\\_i = 0\\), phần thứ nhất sẽ bị triệt tiêu! Chúng ta muốn mô hình gần với dữ liệu đã cho nhất, tức xác suất này đạt giá trị cao nhất. Xét toàn bộ training set với \\(\\mathbf{X} = [\\mathbf{x}\\_1,\\mathbf{x}\\_2, \\dots, \\mathbf{x}\\_N] \\in \\mathbb{R}^{d \\times N}\\) và \\(\\mathbf{y} = [y\\_1, y\\_2, \\dots, y\\_N]\\), chúng ta cần tìm \\(\\mathbf{w}\\) để biểu thức sau đây đạt giá trị lớn nhất: \\[ P(\\mathbf{y}|\\mathbf{X}; \\mathbf{w}) \\] ở đây, ta cũng ký hiệu \\(\\mathbf{X, y}\\) như các [biến ngẫu nhiên](https://vi.wikipedia.org/wiki/Biến_ngẫu_nhiên) (random variables). Nói cách khác: \\[ \\mathbf{w} = \\arg\\max\\_{\\mathbf{w}} P(\\mathbf{y}|\\mathbf{X}; \\mathbf{w}) \\] Bài toán tìm tham số để mô hình gần với dữ liệu nhất trên đây có tên gọi chung là bài toán [*maximum likelihood estimation*](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) với hàm số phía sau \\(\\arg\\max\\) được gọi là *likelihood function*. Khi làm việc với các bài toán Machine Learning sử dụng các mô hình xác suất thống kê, chúng ta sẽ gặp lại các bài toán thuộc dạng này, hoặc [*maximum a posteriori estimation*](https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation), rất nhiều. Tôi sẽ dành 1 bài khác để nói về hai dạng bài toán này. Giả sử thêm rằng các điểm dữ liệu được sinh ra một cách ngẫu nhiên độc lập với nhau (independent), ta có thể viết: \\[ \\begin{eqnarray} P(\\mathbf{y}|\\mathbf{X}; \\mathbf{w}) &=& \\prod\\_{i=1}^N P(y\\_i| \\mathbf{x}\\_i; \\mathbf{w}) \\newline &=& \\prod\\_{i=1}^N z\\_i^{y\\_i}(1 - z\\_i)^{1- y\\_i} \\end{eqnarray} \\] với \\(\\prod\\) là ký hiệu của tích. Bạn đọc có thể muốn đọc thêm về [Độc lập thống kê](https://vi.wikipedia.org/wiki/Độc_lập_thống_kê). Trực tiếp tối ưu hàm số này theo \\(\\mathbf{w}\\) nhìn qua không đơn giản! Hơn nữa, khi \\(N\\) lớn, tích của \\(N\\) số nhỏ hơn 1 có thể dẫn tới sai số trong tính toán (numerial error) vì tích là một số quá nhỏ. Một phương pháp thường được sử dụng đó là lấy logarit tự nhiên (cơ số \\(e\\)) của *likelihood function* biến phép nhân thành phép cộng và để tránh việc số quá nhỏ. Sau đó lấy ngược dấu để được một hàm và coi nó là hàm mất mát. Lúc này bài toán tìm giá trị lớn nhất (maximum likelihood) trở thành bài toán tìm giá trị nhỏ nhất của hàm mất mát (hàm này còn được gọi là negative log likelihood): \\[ \\begin{eqnarray} J(\\mathbf{w}) = -\\log P(\\mathbf{y}|\\mathbf{X}; \\mathbf{w}) \\newline = -\\sum\\_{i=1}^N(y\\_i \\log {z}\\_i + (1-y\\_i) \\log (1 - {z}\\_i)) \\end{eqnarray} \\] với chú ý rằng \\(z\\_i\\) là một hàm số của \\(\\mathbf{w}\\). Bạn đọc tạm nhớ biểu thức vế phải có tên gọi là *cross entropy*, thường được sử dụng để đo *khoảng cách* giữa hai phân phối (distributions). Trong bài toán đang xét, một phân phối là dữ liệu được cho, với xác suất chỉ là 0 hoặc 1; phân phối còn lại được tính theo mô hình logistic regression. *Khoảng cách* giữa hai phân phối nhỏ đồng nghĩa với việc (*có vẻ hiển nhiên là*) hai phân phối đó rất gần nhau. Tính chất cụ thể của hàm số này sẽ được đề cập trong một bài khác mà tầm quan trọng của khoảng cách giữa hai phân phối là lớn hơn. **Chú ý:** Trong machine learning, logarit thập phân ít được dùng, vì vậy \\(\\log\\) thường được dùng để ký hiệu logarit tự nhiên.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-7",
        "source": "37.main.md",
        "section": "Tối ưu hàm mất mát",
        "content": "Chúng ta lại sử dụng phương pháp [Stochastic Gradient Descent](/2017/01/16/gradientdescent2/#-stochastic-gradient-descent) (SGD) ở đây (*Bạn đọc được khuyến khích đọc SGD trước khi đọc phần này*) . Hàm mất mát với chỉ một điểm dữ liệu \\((\\mathbf{x}\\_i, y\\_i)\\) là: \\[ J(\\mathbf{w}; \\mathbf{x}\\_i, y\\_i) = -(y\\_i \\log {z}\\_i + (1-y\\_i) \\log (1 - {z}\\_i)) \\] Với đạo hàm: \\[ \\begin{eqnarray} \\frac{\\partial J(\\mathbf{w}; \\mathbf{x}\\_i, y\\_i)}{\\partial \\mathbf{w}} &=& -(\\frac{y\\_i}{z\\_i} - \\frac{1- y\\_i}{1 - z\\_i} ) \\frac{\\partial z\\_i}{\\partial \\mathbf{w}} \\newline &=& \\frac{z\\_i - y\\_i}{z\\_i(1 - z\\_i)} \\frac{\\partial z\\_i}{\\partial \\mathbf{w}} ~~~~~~ (3) \\end{eqnarray} \\] Để cho biểu thức này trở nên *gọn* và *đẹp* hơn, chúng ta sẽ tìm hàm \\(z = f(\\mathbf{w}^T\\mathbf{x})\\) sao cho mẫu số bị triệt tiêu. Nếu đặt \\(s = \\mathbf{w}^T\\mathbf{x}\\), chúng ta sẽ có: \\[ \\frac{\\partial z\\_i}{\\partial \\mathbf{w}} = \\frac{\\partial z\\_i}{\\partial s} \\frac{\\partial s}{\\partial \\mathbf{w}} = \\frac{\\partial z\\_i}{\\partial s} \\mathbf{x} \\] Một cách trực quan nhất, ta sẽ tìm hàm số \\(z = f(s)\\) sao cho: \\[ \\frac{\\partial z}{\\partial s} = z(1 - z) ~~ (4) \\] để triệt tiêu mẫu số trong biểu thức \\((3)\\). Chúng ta cùng khởi động một chút với phương trình vi phân đơn giản này. Phương trình \\((4)\\) tương đương với: \\[ \\begin{eqnarray} &\\frac{\\partial z}{z(1-z)} &=& \\partial s \\newline \\Leftrightarrow & (\\frac{1}{z} + \\frac{1}{1 - z})\\partial z &=&\\partial s \\newline \\Leftrightarrow & \\log z - \\log(1 - z) &=& s \\newline \\Leftrightarrow & \\log \\frac{z}{1 - z} &=& s \\newline \\Leftrightarrow & \\frac{z}{1 - z} &=& e^s \\newline \\Leftrightarrow & z &=& e^s (1 - z) \\newline \\Leftrightarrow & z = \\frac{e^s}{1 +e^s} &=&\\frac{1}{1 + e^{-s}} = \\sigma(s) \\end{eqnarray} \\] Đến đây, tôi hy vọng các bạn đã hiểu hàm số *sigmoid* được tạo ra như thế nào. *Chú ý: Trong việc giải phương trình vi phân ở trên, tôi đã bỏ qua hằng số khi lấy nguyên hàm hai vế. Tuy vậy, việc này không ảnh hưởng nhiều tới kết quả.*",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-8",
        "source": "37.main.md",
        "section": "Công thức cập nhật cho logistic sigmoid regression",
        "content": "Tới đây, bạn đọc có thể kiểm tra rằng: \\[ \\frac{\\partial J(\\mathbf{w}; \\mathbf{x}\\_i, y\\_i)}{\\partial \\mathbf{w}} = (z\\_i - y\\_i)\\mathbf{x}\\_i \\] Qúa đẹp! Và công thức cập nhật (theo thuật toán [SGD](/2017/01/16/gradientdescent2/#-stochastic-gradient-descent)) cho logistic regression là: \\[ \\mathbf{w} = \\mathbf{w} + \\eta(y\\_i - z\\_i)\\mathbf{x}\\_i \\] Khá đơn giản! Và, như thường lệ, chúng ta sẽ có vài ví dụ với Python.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-9",
        "source": "37.main.md",
        "section": "Ví dụ với dữ liệu 1 chiều",
        "content": "Quay trở lại với ví dụ nêu ở phần Giới thiệu. Trước tiên ta cần khai báo vài thư viện và dữ liệu: ```",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-10",
        "source": "37.main.md",
        "section": "To support both python 2 and python 3",
        "content": "from __future__ import division, print_function, unicode_literals import numpy as np import matplotlib.pyplot as plt np.random.seed(2) X = np.array([[0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50]]) y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-11",
        "source": "37.main.md",
        "section": "extended data",
        "content": "X = np.concatenate((np.ones((1, X.shape[1])), X), axis = 0) ```",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-12",
        "source": "37.main.md",
        "section": "Các hàm cần thiết cho logistic sigmoid regression",
        "content": "``` def sigmoid(s): return 1/(1 + np.exp(-s)) def logistic_sigmoid_regression(X, y, w_init, eta, tol = 1e-4, max_count = 10000): w = [w_init] it = 0 N = X.shape[1] d = X.shape[0] count = 0 check_w_after = 20 while count < max_count:",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-13",
        "source": "37.main.md",
        "section": "mix data",
        "content": "mix_id = np.random.permutation(N) for i in mix_id: xi = X[:, i].reshape(d, 1) yi = y[i] zi = sigmoid(np.dot(w[-1].T, xi)) w_new = w[-1] + eta*(yi - zi)*xi count += 1",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-14",
        "source": "37.main.md",
        "section": "stopping criteria",
        "content": "if count%check_w_after == 0: if np.linalg.norm(w_new - w[-check_w_after]) < tol: return w w.append(w_new) return w eta = .05 d = X.shape[0] w_init = np.random.randn(d, 1) w = logistic_sigmoid_regression(X, y, w_init, eta) print(w[-1]) ``` ``` [[-4.092695  ] [ 1.55277242]] ``` Với kết quả tìm được, đầu ra \\(y\\) có thể được dự đoán theo công thức: `y = sigmoid(-4.1 + 1.55*x)`. Với dữ liệu trong tập training, kết quả là: ``` print(sigmoid(np.dot(w[-1].T, X))) ``` ``` [[ 0.03281144  0.04694533  0.06674738  0.09407764  0.13102736  0.17961209 0.17961209  0.24121129  0.31580406  0.40126557  0.49318368  0.58556493 0.67229611  0.74866712  0.86263755  0.90117058  0.92977426  0.95055357 0.96541314  0.98329067]] ``` Biểu diễn kết quả này trên đồ thị ta có: ``` X0 = X[1, np.where(y == 0)][0] y0 = y[np.where(y == 0)] X1 = X[1, np.where(y == 1)][0] y1 = y[np.where(y == 1)] plt.plot(X0, y0, 'ro', markersize = 8) plt.plot(X1, y1, 'bs', markersize = 8) xx = np.linspace(0, 6, 1000) w0 = w[-1][0][0] w1 = w[-1][1][0] threshold = -w0/w1 yy = sigmoid(w0 + w1*xx) plt.axis([-2, 8, -1, 2]) plt.plot(xx, yy, 'g-', linewidth = 2) plt.plot(threshold, .5, 'y^', markersize = 8) plt.xlabel('studying hours') plt.ylabel('predicted probability of pass') plt.show() ``` ![](\\assets\\LogisticRegression\\lg_results.png) Hình 4: Dữ liệu và hàm sigmoid tìm được. Nếu như chỉ có hai output là ‘fail’ hoặc ‘pass’, điểm trên đồ thị của hàm sigmoid tương ứng với xác suất 0.5 được chọn làm *hard threshold* (ngưỡng cứng). Việc này có thể chứng minh khá dễ dàng (tôi sẽ bàn ở phần dưới).",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-15",
        "source": "37.main.md",
        "section": "Ví dụ với dữ liệu 2 chiều",
        "content": "Chúng ta xét thêm một ví dụ nhỏ nữa trong không gian hai chiều. Giả sử chúng ta có hai class xanh-đỏ với dữ liệu được phân bố như hình dưới. ![](\\assets\\LogisticRegression\\logistic_2d.png) Hình 5: Hai class với dữ liệu hai chiều. Với dữ liệu đầu vào nằm trong không gian hai chiều, hàm sigmoid có dạng như thác nước dưới đây: ![](http://galaxy.agh.edu.pl/~vlsi/AI/bias/img/plaszczyzna.gif) Hình 6: Hàm sigmoid với dữ liệu có chiều là 2. (Nguồn: [Biased and non biased neurons](http://galaxy.agh.edu.pl/~vlsi/AI/bias/bias_eng.html)) Kết quả tìm được khi áp dụng mô hình logistic regression được minh họa như hình dưới với màu nền khác nhau thể hiện xác suất điểm đó thuộc class đỏ. Đỏ hơn tức gần 1 hơn, xanh hơn tức gần 0 hơn. ![](\\assets\\LogisticRegression\\logistic_2d_2.png) Hình 7: Logistic Regression với dữ liệu hai chiều. Nếu phải lựa chọn một *ngưỡng cứng* (chứ không chấp nhận xác suất) để phân chia hai class, chúng ta quan sát thấy đường thẳng nằm nằm trong khu vực xanh lục là một lựa chọn hợp lý. Tôi sẽ chứng minh ở phần dưới rằng, đường phân chia giữa hai class tìm được bởi logistic regression có dạng một đường phẳng, tức vẫn là linear.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-16",
        "source": "37.main.md",
        "section": "Logistic Regression thực ra được sử dụng nhiều trong các bài toán Classification.",
        "content": "Mặc dù có tên là Regression, tức một mô hình cho fitting, Logistic Regression lại được sử dụng nhiều trong các bài toán Classification. Sau khi tìm được mô hình, việc xác định class \\(y\\) cho một điểm dữ liệu \\(\\mathbf{x}\\) được xác định bằng việc so sánh hai biểu thức xác suất: \\[ P(y = 1| \\mathbf{x}; \\mathbf{w}); ~~ P(y = 0| \\mathbf{x}; \\mathbf{w}) \\] Nếu biểu thức thứ nhất lớn hơn thì ta kết luận điểm dữ liệu thuộc class 1, ngược lại thì nó thuộc class 0. Vì tổng hai biểu thức này luôn bằng 1 nên một cách gọn hơn, ta chỉ cần xác định xem \\(P(y = 1| \\mathbf{x}; \\mathbf{w})\\) lớn hơn 0.5 hay không. Nếu có, class 1. Nếu không, class 0.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-17",
        "source": "37.main.md",
        "section": "Boundary tạo bởi Logistic Regression có dạng tuyến tính",
        "content": "Thật vậy, theo lập luận ở phần trên thì chúng ta cần kiểm tra: \\[ \\begin{eqnarray} P(y = 1| \\mathbf{x}; \\mathbf{w}) &>& 0.5 \\newline \\Leftrightarrow \\frac{1}{1 + e^{-\\mathbf{w}^T\\mathbf{x}}} &>& 0.5 \\newline \\Leftrightarrow e^{-\\mathbf{w}^T\\mathbf{x}} &<& 1 \\newline \\Leftrightarrow \\mathbf{w}^T\\mathbf{x} &>& 0 \\end{eqnarray} \\] Nói cách khác, boundary giữa hai class là đường có phương trình \\(\\mathbf{w}^T\\mathbf{x}\\). Đây chính là phương trình của một siêu mặt phẳng. Vậy Logistic Regression tạo ra boundary có dạng tuyến tính.",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-18",
        "source": "37.main.md",
        "section": "5. Thảo luận",
        "content": "* Một điểm cộng cho Logistic Regression so với PLA là nó không cần có giả thiết dữ liệu hai class là linearly separable. Tuy nhiên, boundary tìm được vẫn có dạng tuyến tính. Vậy nên mô hình này chỉ phù hợp với loại dữ liệu mà hai class là gần với linearly separable. Một kiểu dữ liệu mà Logistic Regression không làm việc được là dữ liệu mà một class chứa các điểm nằm trong 1 vòng tròn, class kia chứa các điểm bên ngoài đường tròn đó. Kiểu dữ liệu này được gọi là phi tuyến (non-linear). Sau một vài bài nữa, tôi sẽ giới thiệu với các bạn các mô hình khác phù hợp hơn với loại dữ liệu này hơn. * Một hạn chế nữa của Logistic Regression là nó yêu cầu các điểm dữ liệu được tạo ra một cách *độc lập* với nhau. Trên thực tế, các điểm dữ liệu có thể bị *ảnh hưởng* bởi nhau. Ví dụ: có một nhóm ôn tập với nhau trong 4 giờ, cả nhóm đều thi đỗ (giả sử các bạn này học rất tập trung), nhưng có một sinh viên học một mình cũng trong 4 giờ thì xác suất thi đỗ thấp hơn. Mặc dù vậy, để cho đơn giản, khi xây dựng mô hình, người ta vẫn thường giả sử các điểm dữ liệu là độc lập với nhau. * Khi biểu diễn theo Neural Networks, Linear Regression, PLA, và Logistic Regression có dạng như sau: ![](\\assets\\LogisticRegression\\3models.png) Hình 8: Biểu diễn Linear Regression, PLA, và Logistic Regression theo Neural network. * Nếu hàm mất mát của Logistic Regression được viết dưới dạng: \\[ J(\\mathbf{w}) = \\sum\\_{i=1}^N (y\\_i - z\\_i)^2 \\] thì khó khăn gì sẽ xảy ra? Các bạn hãy coi đây như một bài tập nhỏ. * Source code cho các ví dụ trong bài này có thể [tìm thấy ở đây](https://github.com/tiepvupsu/tiepvupsu.github.io/blob/master/assets/LogisticRegression/LogisticRegression_post.ipynb).",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "37.main-19",
        "source": "37.main.md",
        "section": "6. Tài liệu tham khảo",
        "content": "[1] Cox, David R. “The regression analysis of binary sequences.” Journal of the Royal Statistical Society. Series B (Methodological) (1958): 215-242. [2] Cramer, Jan Salomon. “The origins of logistic regression.” (2002). [3] Abu-Mostafa, Yaser S., Malik Magdon-Ismail, and Hsuan-Tien Lin. Learning from data. Vol. 4. New York, NY, USA:: AMLBook, 2012. ([link to course](http://work.caltech.edu/telecourse.html)) [4] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer (2006). ([book](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)) [5] Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern classification. John Wiley & Sons, 2012. [6] Andrer Ng. CS229 Lecture notes. [Part II: Classification and logistic regression](https://datajobs.com/data-science-repo/Generalized-Linear-Models-[Andrew-Ng].pdf) [7] Jerome H. Friedman, Robert Tibshirani, and Trevor Hastie. [The Elements of Statistical Learning](https://statweb.stanford.edu/~tibs/).",
        "url": "https://machinelearningcoban.com/2017/01/27/logisticregression/"
    },
    {
        "id": "27.main-1",
        "source": "27.main.md",
        "section": "Introduction",
        "content": "* [1. Giới thiệu](#-gioi-thieu) * [2. Phân tích toán học](#-phan-tich-toan-hoc) * [3. Bài toán đối ngẫu Lagrange](#-bai-toan-doi-ngau-lagrange) + [3.1. Kiểm tra tiêu chuẩn Slater](#-kiem-tra-tieu-chuan-slater) + [3.2. Lagrangian của bài toán Soft-margin SVM](#-lagrangian-cua-bai-toan-soft-margin-svm) + [3.3. Bài toán đối ngẫu](#-bai-toan-doi-ngau) + [3.4. Hệ điều kiện KKT](#-he-dieu-kien-kkt) * [4. Bài toán tối ưu không ràng buộc cho Soft Margin SVM](#-bai-toan-toi-uu-khong-rang-buoc-cho-soft-margin-svm) + [4.1. Bài toán tối ưu không ràng buộc tương đương](#-bai-toan-toi-uu-khong-rang-buoc-tuong-duong) + [4.2. Hinge loss](#-hinge-loss) + [4.3. Xây dựng hàm mất mát](#-xay-dung-ham-mat-mat) + [4.4. Tối ưu hàm mất mát](#-toi-uu-ham-mat-mat) * [5. Kiểm chứng bằng lập trình](#-kiem-chung-bang-lap-trinh) + [5.1. Giải bài toán Soft Margin bằng 3 cách khác nhau](#-giai-bai-toan-soft-margin-bang--cach-khac-nhau) - [5.1.1. Khai báo thư viện và tạo dữ liệu giả](#-khai-bao-thu-vien-va-tao-du-lieu-gia) - [5.1.2. Giải bài toán bằng thư viện sklearn](#-giai-bai-toan-bang-thu-vien-sklearn) - [5.1.3. Tìm nghiệm bằng giải bài toán đối ngẫu](#-tim-nghiem-bang-giai-bai-toan-doi-ngau) - [5.1.4. Tìm nghiệm bằng giải bài toán không ràng buộc](#-tim-nghiem-bang-giai-bai-toan-khong-rang-buoc) + [5.2. Ảnh hưởng của \\(C\\) lên nghiệm](#-anh-huong-cua-\\\\c\\\\-len-nghiem) * [6. Tóm tắt và thảo luận](#-tom-tat-va-thao-luan) * [7. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2017/04/13/softmarginsmv/"
    },
    {
        "id": "27.main-2",
        "source": "27.main.md",
        "section": "1. Giới thiệu",
        "content": "Giống như [Perceptron Learning Algorithm (PLA)](/2017/01/21/perceptron/), [Support Vector Machine (SVM) *thuần*](/2017/04/09/smv/) chỉ làm việc khi dữ liệu của 2 classes là [*linearly separable*](/2017/01/21/perceptron/#bai-toan-perceptron). Một cách tự nhiên, chúng ta cũng mong muốn rằng SVM có thể làm việc với dữ liệu *gần linearly separable* giống như [Logistic Regression](/2017/01/27/logisticregression/) đã làm được. *Bạn được khuyến khích đọc bài [Support Vector Machine]((/2017/04/09/smv/)) trước khi đọc bài này.* Xét 2 ví dụ trong Hình 1 dưới đây: --- |  |  | | --- | --- | | a) | b) | Hình 1: Soft margin SVM. Khi a) có nhiễu hoặc b) dữ liệu gần linearly separable, SVM thuần sẽ không hoạt động hiệu quả. ---",
        "url": "https://machinelearningcoban.com/2017/04/13/softmarginsmv/"
    },
    {
        "id": "45.main-1",
        "source": "45.main.md",
        "section": "Introduction",
        "content": "Có hai cách phổ biến phân nhóm các thuật toán Machine learning. Một là dựa trên phương thức học (learning style), hai là dựa trên chức năng (function) (của mỗi thuật toán). **Trong trang này:** * [1. Phân nhóm dựa trên phương thức học](#-phan-nhom-dua-tren-phuong-thuc-hoc) + [Supervised Learning (Học có giám sát)](#supervised-learning-hoc-co-giam-sat) - [Classification (Phân loại)](#classification-phan-loai) - [Regression (Hồi quy)](#regression-hoi-quy) + [Unsupervised Learning (Học không giám sát)](#unsupervised-learning-hoc-khong-giam-sat) - [Clustering (phân nhóm)](#clustering-phan-nhom) - [Association](#association) + [Semi-Supervised Learning (Học bán giám sát)](#semi-supervised-learning-hoc-ban-giam-sat) + [Reinforcement Learning (Học Củng Cố)](#reinforcement-learning-hoc-cung-co) * [2. Phân nhóm dựa trên chức năng](#-phan-nhom-dua-tren-chuc-nang) + [Regression Algorithms](#regression-algorithms) + [Classification Algorithms](#classification-algorithms) + [Instance-based Algorithms](#instance-based-algorithms) + [Regularization Algorithms](#regularization-algorithms) + [Bayesian Algorithms](#bayesian-algorithms) + [Clustering Algorithms](#clustering-algorithms) + [Artificial Neural Network Algorithms](#artificial-neural-network-algorithms) + [Dimensionality Reduction Algorithms](#dimensionality-reduction-algorithms) + [Ensemble Algorithms](#ensemble-algorithms) * [3. Tài liệu tham khảo](#-tai-lieu-tham-khao)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-2",
        "source": "45.main.md",
        "section": "1. Phân nhóm dựa trên phương thức học",
        "content": "Theo phương thức học, các thuật toán Machine Learning thường được chia làm 4 nhóm: Supervised learning, Unsupervised learning, Semi-supervised learning và Reinforcement learning. *Có một số cách phân nhóm không có Semi-supervised learning hoặc Reinforcement learning.*",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-3",
        "source": "45.main.md",
        "section": "Supervised Learning (Học có giám sát)",
        "content": "Supervised learning là thuật toán dự đoán đầu ra (outcome) của một dữ liệu mới (new input) dựa trên các cặp (*input, outcome*) đã biết từ trước. Cặp dữ liệu này còn được gọi là (*data, label*), tức (*dữ liệu, nhãn*). Supervised learning là nhóm phổ biến nhất trong các thuật toán Machine Learning. Một cách toán học, Supervised learning là khi chúng ra có một tập hợp biến đầu vào \\( \\mathcal{X} = \\{\\mathbf{x}\\_1, \\mathbf{x}\\_2, \\dots, \\mathbf{x}\\_N\\} \\) và một tập hợp nhãn tương ứng \\( \\mathcal{Y} = \\{\\mathbf{y}\\_1, \\mathbf{y}\\_2, \\dots, \\mathbf{y}\\_N\\} \\), trong đó \\( \\mathbf{x}\\_i, \\mathbf{y}\\_i \\) là các vector. Các cặp dữ liệu biết trước \\( (\\mathbf{x}\\_i, \\mathbf{y}\\_i) \\in \\mathcal{X} \\times \\mathcal{Y} \\) được gọi là tập *training data* (dữ liệu huấn luyện). Từ tập training data này, chúng ta cần tạo ra một hàm số ánh xạ mỗi phần tử từ tập \\(\\mathcal{X}\\) sang một phần tử (xấp xỉ) tương ứng của tập \\(\\mathcal{Y}\\): \\[ \\mathbf{y}\\_i \\approx f(\\mathbf{x}\\_i), ~~ \\forall i = 1, 2, \\dots, N\\] Mục đích là xấp xỉ hàm số \\(f\\) thật tốt để khi có một dữ liệu \\(\\mathbf{x}\\) mới, chúng ta có thể tính được nhãn tương ứng của nó \\( \\mathbf{y} = f(\\mathbf{x}) \\). **Ví dụ 1:** trong nhận dạng chữ viết tay, ta có ảnh của hàng nghìn ví dụ của mỗi chữ số được viết bởi nhiều người khác nhau. Chúng ta đưa các bức ảnh này vào trong một thuật toán và chỉ cho nó biết mỗi bức ảnh tương ứng với chữ số nào. Sau khi thuật toán tạo ra một mô hình, tức một hàm số mà đầu vào là một bức ảnh và đầu ra là một chữ số, khi nhận được một bức ảnh mới mà mô hình **chưa nhìn thấy bao giờ**, nó sẽ dự đoán bức ảnh đó chứa chữ số nào. ![](http://www.rubylab.io/img/mnist.png) [MNIST](http://yann.lecun.com/exdb/mnist/): bộ cơ sở dữ liệu của chữ số viết tay. (Nguồn: [Simple Neural Network implementation in Ruby)](http://www.rubylab.io/2015/03/18/simple-neural-network-implenentation-in-ruby/) Ví dụ này khá giống với cách học của con người khi còn nhỏ. Ta đưa bảng chữ cái cho một đứa trẻ và chỉ cho chúng đây là chữ A, đây là chữ B. Sau một vài lần được dạy thì trẻ có thể nhận biết được đâu là chữ A, đâu là chữ B trong một cuốn sách mà chúng chưa nhìn thấy bao giờ. **Ví dụ 2:** Thuật toán dò các khuôn mặt trong một bức ảnh đã được phát triển từ rất lâu. Thời gian đầu, facebook sử dụng thuật toán này để chỉ ra các khuôn mặt trong một bức ảnh và yêu cầu người dùng *tag friends* - tức gán nhãn cho mỗi khuôn mặt. Số lượng cặp dữ liệu (*khuôn mặt, tên người*) càng lớn, độ chính xác ở những lần tự động *tag* tiếp theo sẽ càng lớn. **Ví dụ 3:** Bản thân thuật toán dò tìm các khuôn mặt trong 1 bức ảnh cũng là một thuật toán Supervised learning với training data (dữ liệu học) là hàng ngàn cặp (*ảnh, mặt người*) và (*ảnh, không phải mặt người*) được đưa vào. Chú ý là dữ liệu này chỉ phân biệt *mặt người* và *không phải mặt người* mà không phân biệt khuôn mặt của những người khác nhau. Thuật toán supervised learning còn được tiếp tục chia nhỏ ra thành hai loại chính:",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-4",
        "source": "45.main.md",
        "section": "Classification (Phân loại)",
        "content": "Một bài toán được gọi là *classification* nếu các *label* của *input data* được chia thành một số hữu hạn nhóm. Ví dụ: Gmail xác định xem một email có phải là spam hay không; các hãng tín dụng xác định xem một khách hàng có khả năng thanh toán nợ hay không. Ba ví dụ phía trên được chia vào loại này.",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-5",
        "source": "45.main.md",
        "section": "Regression (Hồi quy)",
        "content": "(tiếng Việt dịch là *Hồi quy*, tôi không thích cách dịch này vì bản thân không hiểu nó nghĩa là gì) Nếu *label* không được chia thành các nhóm mà là một giá trị thực cụ thể. Ví dụ: một căn nhà rộng \\(x ~ \\text{m}^2\\), có \\(y\\) phòng ngủ và cách trung tâm thành phố \\(z~ \\text{km}\\) sẽ có giá là bao nhiêu? Gần đây [Microsoft có một ứng dụng dự đoán giới tính và tuổi dựa trên khuôn mặt](http://how-old.net/). Phần dự đoán giới tính có thể coi là thuật toán **Classification**, phần dự đoán tuổi có thể coi là thuật toán **Regression**. *Chú ý rằng phần dự đoán tuổi cũng có thể coi là **Classification** nếu ta coi tuổi là một số nguyên dương không lớn hơn 150, chúng ta sẽ có 150 class (lớp) khác nhau.*",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-6",
        "source": "45.main.md",
        "section": "Unsupervised Learning (Học không giám sát)",
        "content": "Trong thuật toán này, chúng ta không biết được *outcome* hay *nhãn* mà chỉ có dữ liệu đầu vào. Thuật toán unsupervised learning sẽ dựa vào cấu trúc của dữ liệu để thực hiện một công việc nào đó, ví dụ như phân nhóm (clustering) hoặc giảm số chiều của dữ liệu (dimension reduction) để thuận tiện trong việc lưu trữ và tính toán. Một cách toán học, Unsupervised learning là khi chúng ta chỉ có dữ liệu vào \\(\\mathcal{X} \\) mà không biết *nhãn* \\(\\mathcal{Y}\\) tương ứng. Những thuật toán loại này được gọi là Unsupervised learning vì không giống như Supervised learning, chúng ta không biết câu trả lời chính xác cho mỗi dữ liệu đầu vào. Giống như khi ta học, không có thầy cô giáo nào chỉ cho ta biết đó là chữ A hay chữ B. Cụm *không giám sát* được đặt tên theo nghĩa này. Các bài toán Unsupervised learning được tiếp tục chia nhỏ thành hai loại:",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-7",
        "source": "45.main.md",
        "section": "Clustering (phân nhóm)",
        "content": "Một bài toán phân nhóm toàn bộ dữ liệu \\(\\mathcal{X}\\) thành các nhóm nhỏ dựa trên sự liên quan giữa các dữ liệu trong mỗi nhóm. Ví dụ: phân nhóm khách hàng dựa trên hành vi mua hàng. Điều này cũng giống như việc ta đưa cho một đứa trẻ rất nhiều mảnh ghép với các hình thù và màu sắc khác nhau, ví dụ tam giác, vuông, tròn với màu xanh và đỏ, sau đó yêu cầu trẻ phân chúng thành từng nhóm. Mặc dù không cho trẻ biết mảnh nào tương ứng với hình nào hoặc màu nào, nhiều khả năng chúng vẫn có thể phân loại các mảnh ghép theo màu hoặc hình dạng.",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-8",
        "source": "45.main.md",
        "section": "Association",
        "content": "Là bài toán khi chúng ta muốn khám phá ra một quy luật dựa trên nhiều dữ liệu cho trước. Ví dụ: những khách hàng nam mua quần áo thường có xu hướng mua thêm đồng hồ hoặc thắt lưng; những khán giả xem phim Spider Man thường có xu hướng xem thêm phim Bat Man, dựa vào đó tạo ra một hệ thống gợi ý khách hàng (Recommendation System), thúc đẩy nhu cầu mua sắm.",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-9",
        "source": "45.main.md",
        "section": "Semi-Supervised Learning (Học bán giám sát)",
        "content": "Các bài toán khi chúng ta có một lượng lớn dữ liệu \\(\\mathcal{X}\\) nhưng chỉ một phần trong chúng được gán nhãn được gọi là Semi-Supervised Learning. Những bài toán thuộc nhóm này nằm giữa hai nhóm được nêu bên trên. Một ví dụ điển hình của nhóm này là chỉ có một phần ảnh hoặc văn bản được gán nhãn (ví dụ bức ảnh về người, động vật hoặc các văn bản khoa học, chính trị) và phần lớn các bức ảnh/văn bản khác chưa được gán nhãn được thu thập từ internet. Thực tế cho thấy rất nhiều các bài toán Machine Learning thuộc vào nhóm này vì việc thu thập dữ liệu có nhãn tốn rất nhiều thời gian và có chi phí cao. Rất nhiều loại dữ liệu thậm chí cần phải có chuyên gia mới gán nhãn được (ảnh y học chẳng hạn). Ngược lại, dữ liệu chưa có nhãn có thể được thu thập với chi phí thấp từ internet.",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-10",
        "source": "45.main.md",
        "section": "Reinforcement Learning (Học Củng Cố)",
        "content": "Reinforcement learning là các bài toán giúp cho một hệ thống tự động xác định hành vi dựa trên hoàn cảnh để đạt được lợi ích cao nhất (maximizing the performance). Hiện tại, Reinforcement learning chủ yếu được áp dụng vào Lý Thuyết Trò Chơi (Game Theory), các thuật toán cần xác định nước đi tiếp theo để đạt được điểm số cao nhất. [![](/assets/categories/alphago.jpeg)](/2016/12/27/categories/) AlphaGo chơi cờ vây với Lee Sedol. AlphaGo là một ví dụ của Reinforcement learning. (Nguồn: [AlphaGo AI Defeats Sedol Again, With 'Near Perfect Game')](http://www.tomshardware.com/news/alphago-defeats-sedol-second-time,31377.html) **Ví dụ 1:** [AlphaGo gần đây nổi tiếng với việc chơi cờ vây thắng cả con người](https://gogameguru.com/tag/deepmind-alphago-lee-sedol/). [Cờ vây được xem là có độ phức tạp cực kỳ cao](https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/) với tổng số nước đi là xấp xỉ \\(10^{761} \\), so với cờ vua là \\(10^{120} \\) và tổng số nguyên tử trong toàn vũ trụ là khoảng \\(10^{80}\\)!! Vì vậy, thuật toán phải chọn ra 1 nước đi tối ưu trong số hàng nhiều tỉ tỉ lựa chọn, và tất nhiên, không thể áp dụng thuật toán tương tự như [IBM Deep Blue](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)) (IBM Deep Blue đã thắng con người trong môn cờ vua 20 năm trước). Về cơ bản, AlphaGo bao gồm các thuật toán thuộc cả Supervised learning và Reinforcement learning. Trong phần Supervised learning, dữ liệu từ các ván cờ do con người chơi với nhau được đưa vào để huấn luyện. Tuy nhiên, mục đích cuối cùng của AlphaGo không phải là chơi như con người mà phải thậm chí thắng cả con người. Vì vậy, sau khi *học* xong các ván cờ của con người, AlphaGo tự chơi với chính nó với hàng triệu ván chơi để tìm ra các nước đi mới tối ưu hơn. Thuật toán trong phần tự chơi này được xếp vào loại Reinforcement learning. (Xem thêm tại [Google DeepMind’s AlphaGo: How it works](https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/)). **Ví dụ 2:** [Huấn luyện cho máy tính chơi game Mario](https://www.youtube.com/watch?v=qv6UVOQ0F44). Đây là một chương trình thú vị dạy máy tính chơi game Mario. Game này đơn giản hơn cờ vây vì tại một thời điểm, người chơi chỉ phải bấm một số lượng nhỏ các nút (di chuyển, nhảy, bắn đạn) hoặc không cần bấm nút nào. Đồng thời, phản ứng của máy cũng đơn giản hơn và lặp lại ở mỗi lần chơi (tại thời điểm cụ thể sẽ xuất hiện một chướng ngại vật cố định ở một vị trí cố định). Đầu vào của thuật toán là sơ đồ của màn hình tại thời điểm hiện tại, nhiệm vụ của thuật toán là với đầu vào đó, tổ hợp phím nào nên được bấm. Việc huấn luyện này được dựa trên điểm số cho việc di chuyển được bao xa trong thời gian bao lâu trong game, càng xa và càng nhanh thì được điểm thưởng càng cao (điểm thưởng này không phải là điểm của trò chơi mà là điểm do chính người lập trình tạo ra). Thông qua huấn luyện, thuật toán sẽ tìm ra một cách tối ưu để tối đa số điểm trên, qua đó đạt được mục đích cuối cùng là cứu công chúa. Huấn luyện cho máy tính chơi game Mario",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-11",
        "source": "45.main.md",
        "section": "2. Phân nhóm dựa trên chức năng",
        "content": "Có một cách phân nhóm thứ hai dựa trên chức năng của các thuật toán. Trong phần này, tôi xin chỉ liệt kê các thuật toán. Thông tin cụ thể sẽ được trình bày trong các bài viết khác tại blog này. Trong quá trình viết, tôi có thể sẽ thêm bớt một số thuật toán.",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-12",
        "source": "45.main.md",
        "section": "Regression Algorithms",
        "content": "1. [Linear Regression](/2016/12/28/linearregression/) 2. [Logistic Regression](/2017/01/27/logisticregression/#sigmoid-function) 3. Stepwise Regression",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-13",
        "source": "45.main.md",
        "section": "Classification Algorithms",
        "content": "1. Linear Classifier 2. [Support Vector Machine (SVM)](https://machinelearningcoban.com/2017/04/09/smv/) 3. [Kernel SVM](https://machinelearningcoban.com/2017/04/22/kernelsmv/) 4. Sparse Representation-based classification (SRC)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-14",
        "source": "45.main.md",
        "section": "Instance-based Algorithms",
        "content": "1. [k-Nearest Neighbor (kNN)](/2017/01/08/knn/) 2. Learning Vector Quantization (LVQ)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-15",
        "source": "45.main.md",
        "section": "Regularization Algorithms",
        "content": "1. Ridge Regression 2. Least Absolute Shrinkage and Selection Operator (LASSO) 3. Least-Angle Regression (LARS)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-16",
        "source": "45.main.md",
        "section": "Bayesian Algorithms",
        "content": "1. Naive Bayes 2. Gaussian Naive Bayes",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-17",
        "source": "45.main.md",
        "section": "Clustering Algorithms",
        "content": "1. [k-Means clustering](/2017/01/01/kmeans/) 2. k-Medians 3. Expectation Maximization (EM)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-18",
        "source": "45.main.md",
        "section": "Artificial Neural Network Algorithms",
        "content": "1. [Perceptron](/2017/01/21/perceptron/) 2. [Softmax Regression](/2017/02/17/softmax/) 3. [Multi-layer Perceptron](/2017/02/24/mlp/) 4. [Back-Propagation](/2017/02/24/mlp/#-backpropagation)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-19",
        "source": "45.main.md",
        "section": "Dimensionality Reduction Algorithms",
        "content": "1. [Principal Component Analysis (PCA)](https://machinelearningcoban.com/2017/06/15/pca/) 2. [Linear Discriminant Analysis (LDA)](https://machinelearningcoban.com/2017/06/30/lda/)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-20",
        "source": "45.main.md",
        "section": "Ensemble Algorithms",
        "content": "1. Boosting 2. AdaBoost 3. Random Forest Và còn rất nhiều các thuật toán khác.",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "45.main-21",
        "source": "45.main.md",
        "section": "3. Tài liệu tham khảo",
        "content": "1. [A Tour of Machine Learning Algorithms](http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/) 2. [Điểm qua các thuật toán Machine Learning hiện đại](https://ongxuanhong.wordpress.com/2015/10/22/diem-qua-cac-thuat-toan-machine-learning-hien-dai/)",
        "url": "https://machinelearningcoban.com/2016/12/27/categories/"
    },
    {
        "id": "18.main-1",
        "source": "18.main.md",
        "section": "Introduction",
        "content": "**Trong trang này:** * [6. Imbalanced data trong bài toán classification](#-imbalanced-data-trong-bai-toan-classification) * [5. Similarity search](#-similarity-search) * [4. Binary Hashing cho bài toán Information Retrieval](#-binary-hashing-cho-bai-toan-information-retrieval) * [3. Bạn có cần học Machine Learning cơ bản?](#-ban-co-can-hoc-machine-learning-co-ban) * [2. CAPTCHA](#-captcha) * [1. word2vec](#-wordvec) Post ngắn tổng hợp các ‘ghi chú nhanh’ nhận được nhiều quan tâm trên [Facebook page Machine Learning cơ bản](https://www.facebook.com/machinelearningbasicvn/). Lưu ý: các phần ghi chú nhanh này không có toán và hình, chỉ gồm ngôn ngữ thông thường để các bạn có một cái nhìn nhanh về các vấn đề.",
        "url": "https://machinelearningcoban.com/2017/06/22/qns1/"
    },
    {
        "id": "18.main-2",
        "source": "18.main.md",
        "section": "6. Imbalanced data trong bài toán classification",
        "content": "[Link gốc](https://www.facebook.com/machinelearningbasicvn/posts/449220955437741). Trong bài toán Classification, phải làm như thế nào khi dữ liệu giữa các class quá chênh lệch? Đường link dưới đây có thể mang lại nhiều thông tin có ích cho bạn: [In depth skewed data classification - Kaggle Kernel](https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now) Tôi xin được tóm tắt vài điểm như sau. Trong nhiều bài toán thực tế, việc dữ liệu chênh lệch (imbalanced data) xảy ra rất thường xuyên. Bài toán trong link phía trên là bài toán ‘Credit Card Fraud Detection’, tức xác định các giao dịch lừa đảo trong credit card. Dữ liệu training bao gồm rất nhiều các giao dịch trong lịch sử và nhãn của chúng: ‘Normal’ hoặc ‘Fraud’. Tỉ lệ ‘Fraud’ thường là rất nhỏ so với ‘Normal’, giả sử là 1%. Như vậy hai class này là cực kỳ chênh lệch. Vậy có điểm gì đáng chú ý trong bài toán này: Trước tiên, chúng ta cần đi xác định một Phương pháp đánh giá hiệu quả cho mô hình. Khi đánh giá các thuật toán Classification thông thường, ta thường sử dụng ‘độ chính xác’ như là tỉ lệ giữa các dữ liệu được phân loại đúng trên toàn bộ dữ liệu. Cách làm này không phù hợp trong bài toán của chúng ta vì nếu mô hình dự đoán toàn bộ các giao dịch là ‘Normal’ thì độ chính xác cũng đã là 99%?? Như vậy ta cần phải tìm một phép đo khác. Các phép đo thường được sử dụng với dữ liệu chênh lệch là: Precision, Recall, F1 score, ROC curves, etc. Trong đó, theo kinh nghiệm của tôi, Precision và Recall được sử dụng nhiều, bạn đọc có thể theo link dưới đây để hiểu thế nào là [Precision và Recall - Wiki](https://en.wikipedia.org/wiki/Precision_and_recall). Điều thứ hai cần lưu ý là các thuật toán Classification thông thường thường hoạt động tốt nếu các class có lượng dữ liệu training tương đối như nhau. Nếu không, hiện tượng overfitting rất dễ xảy ra vì mô hình cố gắng ‘fit’ dữ liệu ở class trội hơn. Về Overfitting, bạn có thể đọc [Bài 15: Overfitting](/2017/03/04/overfitting/). Có một hướng tiếp cận được gọi là ‘Resampling’ để hai classes có lượng dữ liệu tương đối như nhau. Cách thứ nhất là UNDER-sampling, tức chỉ chọn ra vài phần tử của class trội hơn và kết hợp với class còn lại để làm dữ liệu training. Cách thứ hai là OVER-sampling, tức có thể lặp lại dữ liệu, hoặc tìm cách kết hợp để tạo ra dữ liệu mới, của class ít hơn, và kết hợp với class còn lại để làm dữ liệu training. Như trong bài viết, cách UNDER-sampling khá hiệu quả. Đây là một bài toán binary classification, hướng tiếp cận đầu tiên bạn có thể nghĩ đến là dùng Logistic Regression. Trong Logistic Regression, dữ liệu đầu ra sẽ là một số dương nằm trong khoảng (0, 1) thể hiện xác suất để đầu ra bằng 1. Khi đó, ta có thể coi ‘1’ là ‘Fraud’, ‘0’ là ‘Normal’. Việc xác định ‘Fraud’ hay ‘Normal’ được xác định dựa trên một ngưỡng nào đó, ví dụ 0.5; các giá trị lớn hơn 0.5 được coi là 1 và ngược lại. Tuy nhiên, ta có thể thay đổi ngưỡng này cho phù hợp với bài toán. Chẳng hạn, nếu việc ‘miss’ các giao dịch ‘Fraud’ là nghiêm trọng thì ta cần hạ thấp ngưỡng xuống mức thấp hơn, ví dụ 0.3 để tỉ lệ ‘miss’ thấp xuống. Tuy nhiên, lúc này ta cần lưu ý về việc rất nhiều giao dịch ‘Normal’ bị biến thành ‘Fraud’. Với bài toán này, tác giả đã chỉ ra rằng Logistic Regression hoạt động rất hiệu quả. Bạn có thể muốn đọc lại [Logistic Regression](/2017/01/27/logisticregression/). Với bài toán có nhiều classes, bạn có thể đọc thuật toán mở rộng của Logistic Regression, có tên là [Softmax Regression](/2017/02/17/softmax/). Cảm ơn và chúc các bạn buổi tối vui vẻ, Tiệp Vũ",
        "url": "https://machinelearningcoban.com/2017/06/22/qns1/"
    },
    {
        "id": "18.main-3",
        "source": "18.main.md",
        "section": "5. Similarity search",
        "content": "[Link gốc](https://www.facebook.com/machinelearningbasicvn/posts/448109285548908). Similarity Search là một chủ đề đang được quan tâm nhiều gần đây. Chủ đề này khá gần với Information Retrieval. Tôi cũng đã có một bài viết ngắn nói về vấn đề Information Retrieval, đặc biệt là Image Retrieval trong link dưới đây: [Chia sẻ về bài toán Image Retrieval](https://www.facebook.com/machinelearningbasicvn/posts/436628436696993) Ở link trên, tôi đã đề cập đến những khó khăn của việc tìm kiếm khi mà lượng ảnh trong cơ sở dữ liệu ngày một lớn trong khi việc tìm kiếm yêu cầu trả về kết quả gần như tức thì. Các phương pháp tôi đề cập trong đó dựa trên Binary Hashing, tức tìm một mô hình tạo ra một binary vector ngắn cho mỗi bức ảnh để thuận tiện lưu trữ và tính toán. Trong post này, tôi xin giới thiệu một kỹ thuật khác mà tôi tìm thấy trong bài viết thú vị về cách thức tìm kiếm các ảnh giống nhau của Flickr - Một trang chia sẻ ảnh và video: [Introducing Similarity Search at Flickr](http://code.flickr.net/2017/03/07/introducing-similarity-search-at-flickr/) Trong Flickr, việc tìm kiếm các ảnh giống với một ảnh cho trước là một việc mấu chốt được thực hiện nhiều lần và kết quả tìm kiếm cho thấy thuật toán hoạt động rất hiệu quả. Ý tưởng rất cơ bản xuất phát từ k-means clustering. Việc tìm kiếm dựa trên rất nhiều, giả sử 1 tỉ, bức ảnh tốn khá nhiều thời gian. Thay vào đó, ta có thể cluster các bức ảnh thành khoảng 1 triệu clusters, mỗi clusters được biểu diễn bởi một centroid. Khi tìm kiếm các ảnh gần giống với một bức ảnh (gọi là query), ta thực hiện 2 bước. Ở bước thứ nhất, centroid gần nhất với query sẽ được chọn. Ở bước thứ hai, các bức ảnh trong cluster ứng với centroid đó sẽ được chọn để so sánh với ảnh query. Đây chính là kỹ thuật xấp xỉ mỗi vector bằng 1 vector khác, trong trường hợp này là centroid, tên tiếng Anh là Vector Quantization (VQ). (Tôi xin bỏ qua phần [feature engineering](/general/2017/02/06/featureengineering/) cho mỗi bức ảnh mà coi như các feature vectors đã được cho trước.) Tuy nhiên, việc clustering từ 1 tỉ bức ảnh ra 1 triệu clusters (training process) và so sánh 1 query với từng cluster (test process) vẫn tốn rất nhiều thời gian. Một kỹ thuật đơn giản nhưng hiệu quả giúp vẫn tạo ra 1 triệu clusters nhưng cả training và test được thực hiện rất nhanh được gọi là Product Quantization (PQ). Trong PQ, mỗi vector được chia đôi thành 2 vectors con. Như vậy ta sẽ có 2 nhóm, mỗi nhóm có 1 tỉ vectors con. Ta thực hiện k-means clustering trên mỗi nhóm này với k = 1000. Như vậy, với mỗi nhóm, ta có 1000 centroids, tổng cộng là 2000 centroids, tạm gọi là các sub-centroids. Với mỗi sub-centroid thuộc nhóm 1 và 1 sub-centroid thuộc nhóm 2, ta sẽ có 1 full-centroid. Vậy tổng cộng ta vẫn có 1000x1000 = 1 triệu cluster nhưng việc training đã giảm đi rất nhiều. Khi test, ta cũng chia query vector thành 2 phần và tìm centroid gần nhất ứng với mỗi phần. Vector ghép bởi 2 sub-centroids này chính là full-centroid gần nhất ứng với query đó. Vì có tổng cộng chỉ 2000 sub-centroids nên việc tính toán đã nhanh hơn rất nhiều. PQ chỉ là ý tưởng ban đầu, nó có nhiều hạn chế. Và Flickr dùng một kỹ thuật khác dựa trên PQ, được gọi là LOPQ, bạn đọc có thể đọc thêm trong bài. Bạn đọc có thể thấy bài viết về [K-means clustering](/2017/01/01/kmeans/) có ích. Chúc các bạn một buổi tối vui vẻ. Tiệp Vũ",
        "url": "https://machinelearningcoban.com/2017/06/22/qns1/"
    },
    {
        "id": "18.main-4",
        "source": "18.main.md",
        "section": "4. Binary Hashing cho bài toán Information Retrieval",
        "content": "[Link gốc](https://www.facebook.com/machinelearningbasicvn/posts/436628436696993). Chia sẻ về Information Retrieval. Information Retrieval hiểu một cách cơ bản là tìm những items trong cơ sở dữ liệu có liên quan đến query, thường là chưa có trong cơ sở dữ liệu. Ví dụ như Google Search và Google Search Image. Bài toán đặt ra là cho một query, bạn phải sắp xếp, hoặc ít nhất là tìm kiếm, những items có liên quan trong cơ sở dữ liệu. Khi cơ sở dữ liệu là các hình ảnh thì nhánh này được gọi là Image Retrieval. Phần sau của post này sẽ chủ yếu nói về Image Retrieval. Có hai hướng tiếp cận trong Image Retrieval : Concept-based và Content-based Image Retrieval. 1. Concept-based IR là việc tìm kiếm dựa trên các thông tin liên quan đến một bức ảnh như caption, labels, tag và phần text xung quanh. Khi bạn search Google hình ảnh bằng 1 text query thì, theo tôi hiểu, chính là Concept-based IR. Cách này phụ thuộc nhiều vào phần thông tin text liên quan đến ảnh mà không phụ thuộc trực tiếp vào nội dung ảnh. 2. Content-based IR là việc tìm kiếm dựa trên nội dung của ảnh (giá trị các pixel trong ảnh). Ví dụ của việc này chính là Google Hình ảnh nhưng query là 1 bức ảnh. Bạn có thể upload bức ảnh hoặc link tới 1 bức ảnh trên internet, Google sẽ trả về các bức ảnh có nội dung tương tự. Image Retrieval khác với Image Classification ở điểm nào? Trong các bài toán Image classification, mỗi bức ảnh sẽ được phân loại vào 1 hoặc một vài class. Ví dụ, bức ảnh có một chú chó thì có thể được phân loại vào ‘dog’, ‘pet’, hay ‘animal’. Việc xác định một bức ảnh thuộc nhóm nào thường trả về các class mà bức ảnh đó có thể thuộc về, tức kết quả là một vài words. Image Retrieval thì khác, kết quả trả về là các bức ảnh, và khi query là 1 bức ảnh thì kết quả trả về có thể là các bức ảnh thuộc class khác. Ví dụ, nếu bức ảnh là 1 con chó cưng thì các ảnh trả về sẽ là các con chó cưng hoặc thậm chí là mèo cưng. Nhưng nếu bức ảnh là 1 con chó chăn cừu thì kết quả trả về có thể là các bức ảnh có cừu và thảo nguyên. Đây là một thách thức (challenge) của Image Retrieval so với Image Classification. Phương pháp phổ biến nhất trong Image Retrieval là dùng Similarity Search. Tức là đi tìm độ giống nhau giữa bức ảnh query và các bức ảnh khác trong dataset, sau đó trả về kết quả dựa trên sự giống nhau từ cao đến thấp. Khó khăn thứ nhất là phải tìm được một cách ‘biểu diễn’ (representation) ảnh tốt dưới dạng các vector để có thể ‘đong đếm’ được sự giống nhau giữa các bức ảnh. Phần này được gọi là Feature Extraction. Nhưng khó khăn lớn hơn là với cả triệu bức ảnh trong dataset, việc tính toán độ giống nhau giữa bức ảnh query và toàn bộ các bức ảnh khác là rất mất thời gian. Về khó khắn thứ nhất, hướng tiếp cận phổ biến nhất hiện nay là dùng Deep Learning. Cụ thể là sử dụng các mô hình Convolutional Neural Networks cho Image Classification nổi tiếng, tức đã được trained với các cơ sở dữ liệu lớn và đạt kết quả cao, để tạo ra các feature vector có độ dài như nhau cho mỗi bức ảnh. Cụ thể hơn, đầu ra của layer gần cuối cùng (trước softmax hoặc svm layer) được dùng như là 1 feature tốt (bạn nào quan tâm có thể đọc thêm về Transfer Learning). Những feature này thường có độ dài khoảng vài nghìn, nếu lưu trữ và tính toán trực tiếp trên feature này thì có thể là bất khả thi, đây là khó khăn thứ hai tôi nêu ở trên. Về khó khăn thứ hai, hướng tiếp cận tôi thấy được sử dụng nhiều là Binary Hashing, tức tiếp tục ‘map’ các feature trên thành 1 vector nhị phân có độ dài nhỏ (32, 64, 128, …). Vector này được gọi là ‘hash code’. Chú ý rằng 2^64 đã là 1 số rất lớn, có thể nhiều hơn toàn bộ số bức ảnh mà con người đã tạo ra. Vì vậy, trong trường hợp lý tưởng, sẽ không có hai bức ảnh khác nhau nào có hash code là như nhau. Sau khi có một mô hình giúp tìm hash code cho từng bức ảnh, việc tính toán similarity trở nên đơn giản hơn vì số chiều thấp hơn và chỉ phải làm việc với các toán tử logic nhị phân đơn giản. Để đọc tài liệu về những gì tôi đã đề cập, chúng ta có thể bắt đầu tìm kiếm “Deep Binary Hashing for Image Retrieval”.",
        "url": "https://machinelearningcoban.com/2017/06/22/qns1/"
    },
    {
        "id": "18.main-5",
        "source": "18.main.md",
        "section": "3. Bạn có cần học Machine Learning cơ bản?",
        "content": "[Link gốc](https://www.facebook.com/machinelearningbasicvn/posts/428787870814383) Về việc có cần học cơ bản Machine Learning (hay bất cứ lĩnh vực nào khác) hay không, nếu có thì sâu đến mức nào, có cần bằng cấp để học Machine Learning hay không, tôi xin đưa ra quan điểm cá nhân như sau: 1. Thật khó để biết mức độ hiểu sâu về một vấn đề nào đó. Cũng không có công thức cụ thể là với background như thế này, mục đích như thế này thì cần hiểu sâu đến đâu. (Trừ khi bạn tìm ra được một mô hình regression cho bạn tính toán được việc này :D). Với tôi thì làm gì cũng vậy, bắt đầu từ việc hiểu bài toán, tìm một mô hình đơn giản nhất giúp giải quyết bài toán, mô hình đó không nhất thiệt phải hiệu quả, cứ chạy là được. Sau đó sẽ hiểu dần dần rồi đào sâu vào các hướng cái thiện. Khi làm càng sâu thì sẽ càng cần đọc lại kiến thức cơ bản. 2. Kiến thức cơ bản không phải chỉ để đọc 1 lần rồi hiểu luôn. Bạn chỉ cần đọc và biết rằng nó ở đó, khi nào gặp khúc mắc thì sẽ biết tìm lại nó ở đâu. Có khi phải đọc lại vài lần rồi mới hiểu, hoặc làm vài project rồi mới hiểu. Nghiên cứu của tôi ở một nhánh khác, không phải Neural Networks, cũng không phải SVMs. Nhưng đây vẫn là những thứ đầu tiên tôi học khi bắt đầu làm Machine Learning. Đến một mức độ nào đó chúng ta sẽ thấy các mô hình Machine Learning đều có những điểm cốt lõi chung, cần phải nắm rõ cái cốt lõi đó. Đây cũng là mục đích chính của tôi trước khi tạo dựng blog này - hệ thống lại kiến thức. Sự thật là khi viết lại những thứ cơ bản này tôi mới thực sự hiểu hơn về Machine Learning và học thêm được nhiều thứ. 3. Cũng chính vì xác định rằng đây sẽ là một nguồn tham khảo quan trọng và lâu dài cho chính bản thân mình nếu muốn gắn bó với Machine Learning, tôi quyết định viết càng cơ bản càng tốt, các hình vẽ càng chi tiết càng tốt, các công thức càng thống nhất (consistent) càng tốt. Tốt cho tôi và tốt cho cả bạn đọc của tôi. Nếu bạn đọc của tôi thấy hứng thú, tôi cũng có hứng thú để duy trì việc viết. Win-win. 4. Một lần nữa, với các bạn muốn làm Machine Learning, việc đầu tiên là chọn cho mình một bài toán mà mình thấy hứng thú (cái này thì chính các bạn phải trả lời được). Rồi học dần dần để hiểu thêm. Qua thời gian nó sẽ ngấm dần. Cũng đừng quan tâm đến việc mình phải hiểu đến đâu trước khi bắt đầu làm. Không bắt tay vào làm thì bạn không hiểu được đâu. Mỗi người có một background khác nhau, có mục tiêu khác nhau, phải bắt tay vào làm thì mới biết mình hiểu gì và mình cần làm gì, và cũng để hiểu mình đam mê gì. 5. Với những bạn không muốn đi sâu vào cơ bản mà muốn bắt đầu từ các mô hình hiệu quả có sẵn. Hãy cứ làm thế, không có gì sai cả. Quan trọng là sau khi sử dụng các mô hình có sẵn đó, bạn muốn làm gì tiếp. Lúc đó bạn tự đặt ra câu hỏi cho mình rồi google dần dần. Rồi cũng sẽ đến lúc bạn nhận ra là mình cần đọc lại kiến thức cơ bản về phần đó. Chỉ là thứ tự học của mỗi người là khác nhau thôi. 6. Có cần có Master degree hay PhD degree để làm Machine Learning không? Tôi xin trả lời là không. Bằng cấp chỉ là một tờ giấy. Học cao học không phải là một điều đảm bảo cho việc bạn có hợp với Machine Learning hay không. Sự khác nhau chính có lẽ nằm ở việc bạn có bị ngừời khác thúc ép bạn làm hay không mà thôi. Ngoài ra, những kiến thức quan trọng cho Machine Learning đều có sẵn online với lượng tutorial vô cùng dồi dào - và tốt hơn những gì tôi được dạy ở chương trình cao học. Điều quan trọng là bạn có đủ đam mê để duy trì việc tự học tập (có thể là suốt đời) hay không. Ngày càng nhiều người làm Machine Learning, nhưng điều đó không có nghĩa là ai cũng có thể học và làm Machine Learning. Niềm đam mê, sự kiên trì, không phải bằng cấp, là những nhân tố quan trọng khi bạn muốn theo đuổi một mục tiêu. Ở bất cứ lĩnh vực nào cũng thế thôi. Lời kết: Mỗi ngừời có một background khác nhau và có một mục tiêu khác nhau. Cách tốt nhất là đặt ra mục tiêu, bắt tay vào làm rồi bạn sẽ biết cần phải học thêm những gì. Khi đã bắt tay vào làm rồi, bạn sẽ hiểu thêm và có thể điều chỉnh lại mục tiêu ban đầu của mình cho phù hợp. Một khi làm đã đủ nhiều, bạn sẽ nhận ra là những kiến thức cơ bản là quan trọng, dù mức độ quan trọng với từng ngừời là khác nhau. Bản thân từ ‘cơ bản’ cũng tự nó mang thông tin là ‘cần thiết’ rồi. Thế giới thay đổi rất nhanh, chỉ có liên tục học tập và làm việc mới giúp mình không bị bỏ lại phía sau. Và đừng bao giờ nói rằng toán là không quan trọng khi làm Machine Learning.",
        "url": "https://machinelearningcoban.com/2017/06/22/qns1/"
    },
    {
        "id": "18.main-6",
        "source": "18.main.md",
        "section": "2. CAPTCHA",
        "content": "[Link gốc](https://www.facebook.com/machinelearningbasicvn/posts/417247405301763). CAPTCHA - công cụ tránh spam và cũng là công cụ thu thập nhãn cho dữ liệu. Hẳn các bạn đều đã trải qua những bài test nhỏ tương tự như các hình dưới đây. Mục đích chính của nó là để phân biệt ‘human’ và ‘bot’ (tức người và máy), để tránh hiện tượng spam trong các website. Lý dó đơn giản là có những việc con người làm được nhưng ‘bot’ vẫn chưa thể làm được. Ví dụ: Gõ lại các từ trong một bức ảnh mà chữ đã bị làm méo mó; đọc số nhà trong một bức ảnh thật; tìm các ảnh tương ứng trong rất nhiều ảnh; hoặc xác định những ô vuông nhỏ trong một ảnh lớn có chứa một vật thể nào đó. Những bức ảnh này sẽ ngày một khó hơn, tương ứng với các bài toán thực tế khó hơn, vì các con ‘bot’ ngày một thông minh hơn nhờ vào Machine Learning. Không chỉ giúp phân biệt người/máy, CAPTCHA còn được sử dụng với một mục đích rất thú vị khác: thu thập nhãn cho dữ liệu chưa có nhãn. Chúng ta biết rằng có hàng tỉ bức ảnh trên internet nhưng phần lớn không có “nhãn”, tức chưa được máy tính nhận ra nội dung trong đó là gì. Các thuật toán nhận dạng, muốn đạt kết quả cao, cần rất nhiều dữ liệu cho tập huấn luyện (training). Và đây chính là một lợi ích khác của CAPTCHA. Chính người dùng đã giúp các công ty tương tự như CAPTCHA thu thập nhãn cho dữ liệu! Câu hỏi đặt ra là: Nếu chưa biết nhãn của dữ liệu, làm thế nào để biết một kết quả nhập vào là chính xác? Có một cách đơn giản là cho người dùng làm nhiều bài test khác nhau, trong đó có những bài đã có đáp án (nhãn). Sau đó, nếu những kết quả nhận được ở những bài đã có đáp án là chính xác thì khả năng cao đó chính là con người. Vậy thì các kết quả còn lại cũng có độ tin cậy cao. Và để cho độ chính xác cao hơn, một bức ảnh sẽ được dùng cho nhiều bài test. Nếu nó nhận được kết quả giống nhau ở những trường hợp có khả năng cao là con người thì kết quả đó được cho là nhãn của bức ảnh đó. Quick thought: sử dụng phương pháp tương tự cho việc thu thập nhãn cho các loại dữ liệu không-phải-là-ảnh, ví dụ như tiếng Việt. Những trang web tiếng Việt, thay vì sử dụng CAPTCHA, có thể sử dụng một đoạn văn ngắn và trắc nghiệm ngừời dùng về sắc thái/nội dung của đoạn đó. Đoạn văn này có thể là các posts/comments trên mạng xã hội. Qua đó, các công ty có thể thu được một lượng dữ liệu lớn về hành vi người dùng với nhãn cụ thể. Hoặc là dùng chính người dùng làm “classifier” luôn. Khá là tin cậy. Bài viết được soạn nhanh, chủ yếu dựa trên suy luận cá nhân. Mong bạn đọc cùng thảo luận.",
        "url": "https://machinelearningcoban.com/2017/06/22/qns1/"
    },
    {
        "id": "18.main-7",
        "source": "18.main.md",
        "section": "1. word2vec",
        "content": "[Natural Language Processing - NLP] Trong Xử lý ngôn ngữ tự nhiên, việc biểu diễn một từ (word) dưới dạng 1 vector đóng vai trò cực kỳ quan trọng. Nó giúp ích rất nhiều trong việc tìm từ gần nghĩa, trái nghĩa, mô phỏng câu, thâm chí là tìm các câu có nghĩa tương đồng. Trong các thuật toán biến một từ thành một vector của các số thực, word2vec là một trong các phương pháp đơn giản và quan trọng để hiểu nhất. Đây cũng là nội dung chính trong bài thứ hai của loạt bài giảng về NLP của Stanford mà tôi chia sẻ ngày hôm qua. Một cách đơn giản nhất để biểu diễn 1 từ bằng 1 vector là dùng one-hot vector. Trong đó, mỗi vector sẽ có độ dài bằng với số từ trong từ điển, và mỗi vector chỉ có 1 phần tử khác không, và bằng 1, tại vị trí tương ứng với vị trí của từ đó trong từ điển. Mô hình này có rất nhiều nhược điểm: i) độ dài của một vector là quá lớn (bằng độ dài của từ điển, có thể lên đến cả triêu ), ii), không xác định được sự tương quan giữa các từ vì tích vô hướng của hai từ nào cũng bằng 0. word2vec giúp biến 1 từ ở dạng one-hot vector thành một vector có số chiều nhỏ hơn rất nhiều (300 đến 1000), và có thể tính được sự tương quan giữa hai từ dựa vào tích vô hướng giữa hai vector biểu diễn hai từ đó. Tôi mới tìm được một post giải thích cực kỳ dễ hiểu về thuật toán này. Về cơ bản, đó là một mạng neural với 1 hidden layer, không có activation function, và layer cuối là một softmax regression. [Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) Nếu bạn chưa rõ về softmax regression và mạng neural nhiều lớp, bạn có thể tìm được những điều lý thú trong hai bài viết này: [Bài 13: Softmax Regression](/2017/02/17/softmax/) [Bài 14: Multi-layer Perceptron và Backpropagation](/2017/02/24/mlp/)",
        "url": "https://machinelearningcoban.com/2017/06/22/qns1/"
    }
]